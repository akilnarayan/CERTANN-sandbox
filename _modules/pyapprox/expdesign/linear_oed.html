<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyapprox.expdesign.linear_oed &mdash; PyApprox 1.0.2 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            PyApprox
              <img src="../../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Software Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pyapprox.expdesign.linear_oed</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyapprox.expdesign.linear_oed</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">solve_triangular</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Bounds</span><span class="p">,</span> <span class="n">minimize</span><span class="p">,</span> <span class="n">LinearConstraint</span><span class="p">,</span> <span class="n">NonlinearConstraint</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.risk</span> <span class="kn">import</span> <span class="n">conditional_value_at_risk</span>

<span class="kn">from</span> <span class="nn">pyapprox.optimization.cvar_regression</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">conditional_value_at_risk_subgradient</span><span class="p">,</span>
    <span class="n">smooth_conditional_value_at_risk_split</span><span class="p">,</span>
    <span class="n">smooth_conditional_value_at_risk_gradient_split</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_prediction_variance</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">pred_factors</span><span class="p">,</span>
                                <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">):</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">M0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M0u</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">M0u</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">u</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">variances</span>


<span class="k">def</span> <span class="nf">compute_homoscedastic_outer_products</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute</span>

<span class="sd">    .. math:: f(x_i)f(x_i)^T\quad \forall i=0,\ldots,M</span>

<span class="sd">    at a set of design pts :math:`x_i`.</span>

<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------</span>
<span class="sd">    factors : np.ndarray (M,N)</span>
<span class="sd">        The N factors F of the linear model evaluated at the M design pts</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    homoscedastic_outer_products : np.ndarray (N,N,M)</span>
<span class="sd">       The outer products of each row of F with itself, i.e.</span>
<span class="sd">       :math:`f(x_i)f(x_i)^T`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_factors</span> <span class="o">=</span> <span class="n">factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">homoscedastic_outer_products</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="p">(</span><span class="n">num_factors</span><span class="p">,</span> <span class="n">num_factors</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
        <span class="n">homoscedastic_outer_products</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span>
            <span class="n">factors</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">factors</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">return</span> <span class="n">homoscedastic_outer_products</span>


<span class="k">def</span> <span class="nf">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the matrices :math:`M_0` and :math:`M_1` used to compute the</span>
<span class="sd">    asymptotic covariance matrix :math:`C(\mu) = M_1^{-1} M_0 M^{-1}` of the</span>
<span class="sd">    linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    For least squares</span>

<span class="sd">    .. math:: M_0 = \sum_{i=1}^M\eta(x_i)^2f(x_i)f(x_i)^Tr_i</span>

<span class="sd">    .. math:: M_1 = \sum_{i=1}^Mf(x_i)f(x_i)^Tr_i</span>

<span class="sd">    and for quantile regression</span>

<span class="sd">    .. math:: M_0 = \sum_{i=1}^M\frac{1}{\eta(x_i)}f(x_i)f(x_i)^Tr_i</span>

<span class="sd">    .. math:: M_1 = \sum_{i=1}^Mf(x_i)f(x_i)^Tr_i</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray(num_factors,num_factors,num_design_pts)</span>
<span class="sd">        The outer products :math:`f(x_i)f(x_i)^T` for each design point</span>
<span class="sd">        :math:`x_i`</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">        The weights :math:`r_i` for each design point</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    M0 : np.ndarray (num_factors,num_factors)</span>
<span class="sd">        The matrix :math:`M_0`</span>

<span class="sd">    M1 : np.ndarray (num_factors,num_factors)</span>
<span class="sd">        The matrix :math:`M_1`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M1</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">M1</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
        <span class="n">M0</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="o">*</span><span class="n">noise_multiplier</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">M1</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
        <span class="n">M0</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="p">)</span>
        <span class="n">M1</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_prob_measure</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;regression type </span><span class="si">{</span><span class="n">regression_type</span><span class="si">}</span><span class="s1"> not supported&#39;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span>


<span class="k">def</span> <span class="nf">ioptimality_criterion</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">pred_factors</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
                          <span class="n">pred_prob_measure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the I-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math::  \int_\Xi g(\xi) C(\mu) g(\xi) d\nu(\xi)</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The outer_products :math:`f(x_i)f(x_i)^T` for each design point</span>
<span class="sd">       :math:`x_i`</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    pred_factors : np.ndarray (num_pred_pts,num_pred_factors)</span>
<span class="sd">       The prediction factors :math:`g` evaluated at each of the prediction</span>
<span class="sd">       points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    pred_prob_measure : np.ndarray (num_pred_pts)</span>
<span class="sd">        The prob measure :math:`\nu` on the prediction points. If none then</span>
<span class="sd">        assumes samples are random and</span>
<span class="sd">        pred_prob_measure[ii] =  1/num_pred_factors for all uu</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : float</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># import time</span>
    <span class="c1"># t0=time.time()</span>
    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">num_pred_pts</span><span class="p">,</span>   <span class="n">num_pred_factors</span> <span class="o">=</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">pred_prob_measure</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_pred_pts</span>

    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">M0u</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="c1"># value = np.sum(u*M0u) / num_pred_pts</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="o">*</span><span class="n">M0u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0u</span><span class="p">)))</span>
            <span class="n">Fu</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">Fu</span>
            <span class="n">Fgamma</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
                <span class="c1"># gradient = 2*np.sum(Fu*Fgamma, axis=1) + np.sum(t**2, axis=1)</span>
                <span class="c1"># gradient /= num_pred_pts</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span>\
                    <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
                <span class="c1"># gradient = 2*np.sum(</span>
                <span class="c1">#    Fu*Fgamma/noise_multiplier[:, np.newaxis], axis=1) + \</span>
                <span class="c1">#    np.sum(Fu**2, axis=1)</span>
                <span class="c1"># gradient /= num_pred_pts</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span>
                    <span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">Fu</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># print(&#39;that took&#39;,time.time()-t0)</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># import time</span>
        <span class="c1"># t0=time.time()</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># Value</span>
        <span class="c1"># We want to sum the variances, i.e. the enties of the diagonal of</span>
        <span class="c1"># pred_factors.dot(M1.dot(pred_factors.T))</span>
        <span class="c1"># We know that diag(A.T.dot(B)) = (A*B).axis=0)</span>
        <span class="c1"># The following sums over all entries of A*B we get the mean of the</span>
        <span class="c1"># variance</span>
        <span class="c1"># value = np.sum(pred_factors*u.T) / num_pred_pts</span>
        <span class="c1"># print(pred_prob_measure)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">*</span><span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="c1"># Gradient</span>
        <span class="c1"># F_M1_inv_P = design_factors.dot(u)</span>
        <span class="c1"># gradient = -np.sum(F_M1_inv_P**2, axis=1) / num_pred_pts</span>
        <span class="n">F_M1_inv_P</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F_M1_inv_P</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># print(&#39;That took&#39;, time.time()-t0)</span>
        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">ioptimality_criterion_more_design_pts_than_params</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
        <span class="n">pred_factors</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
        <span class="n">pred_prob_measure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">num_pred_pts</span><span class="p">,</span>   <span class="n">num_pred_factors</span> <span class="o">=</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">pred_prob_measure</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_pred_pts</span>

    <span class="n">pred_outer_prods</span> <span class="o">=</span> <span class="n">compute_homoscedastic_outer_products</span><span class="p">(</span><span class="n">pred_factors</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">pred_outer_prods</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pred_prob_measure</span><span class="p">)</span>
    <span class="n">B</span><span class="p">[</span><span class="n">B</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>

    <span class="c1"># TODO: do not use u_vecs, v_vecs in computations when identity</span>
    <span class="c1"># TODO: do not compute wv_vecs when noise_multiplier is None</span>
    <span class="n">num_unknowns</span> <span class="o">=</span> <span class="n">M1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">u_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_unknowns</span><span class="p">)</span>
    <span class="n">v_vecs</span> <span class="o">=</span> <span class="n">B</span>

    <span class="c1"># print(pred_prob_measure)</span>

    <span class="c1"># solve state equations</span>
    <span class="c1"># wu_vecs = np.linalg.solve(M1, u_vecs)</span>
    <span class="c1"># wv_vecs = np.linalg.solve(M1, v_vecs)</span>
    <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
    <span class="n">wu_vecs</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_vecs</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">wv_vecs</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v_vecs</span><span class="p">))</span>
        <span class="c1"># value = np.trace(wu_vecs.T.dot(M0).dot(wv_vecs))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">wu_vecs</span><span class="o">*</span><span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wv_vecs</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># dont need inv(M).dot(v_vecs) for value but do need it for gradient</span>
        <span class="c1"># see below</span>
        <span class="n">wv_vecs</span> <span class="o">=</span> <span class="n">v_vecs</span>
        <span class="c1"># value = np.trace(wu_vecs.T.dot(wv_vecs))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">wu_vecs</span><span class="o">*</span><span class="n">wv_vecs</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_grad</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">value</span>

    <span class="c1"># solve adjoint equations</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lamu_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="o">-</span><span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wv_vecs</span><span class="p">))</span>
        <span class="n">lamv_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="o">-</span><span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wu_vecs</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lamu_vecs</span> <span class="o">=</span> <span class="o">-</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v_vecs</span><span class="p">))</span>
        <span class="n">lamv_vecs</span> <span class="o">=</span> <span class="o">-</span><span class="n">wu_vecs</span>

    <span class="c1"># compute gradient</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
        <span class="n">M0_grad_ii</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ii</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">M0_grad_ii</span> <span class="o">*=</span> <span class="n">noise_multiplier</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">M1_grad_ii</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ii</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_unknowns</span><span class="p">):</span>
            <span class="n">gradient</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
                <span class="n">wu_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0_grad_ii</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wv_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]))</span> <span class="o">+</span>
                <span class="n">lamu_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_grad_ii</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wu_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">])</span> <span class="o">+</span>
                <span class="n">lamv_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_grad_ii</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wv_vecs</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span>


<span class="k">def</span> <span class="nf">coptimality_criterion</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the C-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math:: c^T C(\mu) c</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    for some vector :math:`c`. Here we assume without loss of genearlity</span>
<span class="sd">    :math:`c=(1,1,...,1)^T`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The hessian M_1 of the error for each design point</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : float</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_design_factors</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">regression_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="n">M0u</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0u</span><span class="p">)))</span>
            <span class="n">Fu</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">Fu</span>
            <span class="n">Fgamma</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span> <span class="o">+</span> <span class="n">t</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="n">Fu</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="c1"># Gradient</span>
        <span class="n">F_M1_inv_c</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="n">F_M1_inv_c</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">doptimality_criterion</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
                          <span class="n">use_cholesky</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">return_hessian</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the D-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math:: \log \mathrm{determinant} [ C(\mu) ]</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The outer_products :math:`f(x_i)f(x_i)^T` for each design point</span>
<span class="sd">       :math:`x_i`</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : float</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">return_hessian</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">return_grad</span>
    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="c1"># M1 = homog_outer_prods.dot(design_prob_measure)</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="n">M1_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">M0_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">M0</span><span class="p">)</span>
            <span class="c1"># ident = np.eye(gamma.shape[0])</span>
            <span class="c1"># kappa  = M1.dot(M0_inv)</span>
            <span class="c1"># gradient = np.zeros(num_design_pts)</span>
            <span class="c1"># for ii in range(num_design_pts):</span>
            <span class="c1">#     if regression_type==&#39;lstsq&#39;:</span>
            <span class="c1">#         gradient[ii] = np.sum(</span>
            <span class="c1">#              kappa.dot(homog_outer_prods[:,:,ii])*(</span>
            <span class="c1">#             -2*gamma.T+noise_multiplier[ii]**2*ident).dot(M1_inv))</span>
            <span class="c1">#     elif regression_type==&#39;quantile&#39;:</span>
            <span class="c1">#         gradient[ii] = np.sum(</span>
            <span class="c1">#            kappa.dot(homog_outer_prods[:,:,ii])*(</span>
            <span class="c1">#                -2/noise_multiplier[:,np.newaxis][ii]*gamma.T+</span>
            <span class="c1">#                ident).dot(M1_inv))</span>
            <span class="c1"># return value, gradient</span>

            <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
                <span class="c1"># computing diagonal elements with trace is more efficient than</span>
                <span class="c1"># extracting diagonal (below) and looping through each element</span>
                <span class="c1"># (above)</span>
                <span class="c1"># gradient = -2*np.diag(design_factors.dot(M1_inv.dot(design_factors.T)))+np.diag(noise_multiplier[:,np.newaxis]*design_factors.dot(M0_inv.dot((noise_multiplier[:,np.newaxis]*design_factors).T)))</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="p">(</span><span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">design_factors</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="p">(</span><span class="n">M0_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">design_factors</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="p">(</span><span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">design_factors</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="p">(</span><span class="n">M0_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_cholesky</span><span class="p">:</span>
            <span class="n">chol_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">chol_factor</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">))</span>
        <span class="c1"># Gradient</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_grad</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">use_cholesky</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">solve_triangular</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span>
                    <span class="n">chol_factor</span><span class="p">,</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">temp</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>  <span class="c1"># precompute for hessian</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">return_hessian</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">hessian</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">hessian</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>


<span class="k">def</span> <span class="nf">aoptimality_criterion</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the A-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math:: \mathrm{trace}[ C(\mu) ]</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The hessian M_1 of the error for each design point</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : float</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># [:,:,0] just changes shape from (N,N,1) to (N,N)</span>
    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="n">M1_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_grad</span><span class="p">):</span>
            <span class="n">ident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
                    <span class="n">gradient</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
                        <span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ii</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                            <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">gamma</span><span class="o">.</span><span class="n">T</span><span class="o">+</span><span class="n">noise_multiplier</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">ident</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                                <span class="n">M1_inv</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
                    <span class="n">gradient</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
                        <span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ii</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                            <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">gamma</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">][</span><span class="n">ii</span><span class="p">]</span> <span class="o">+</span>
                            <span class="n">ident</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">)</span>
        <span class="c1"># Gradient</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_grad</span><span class="p">):</span>
            <span class="c1"># gradient = -np.array([(M1_inv*homog_outer_prods[:,:,ii].dot(M1_inv)).sum() for ii in range(homog_outer_prods.shape[2])])</span>
            <span class="c1"># below is faster than above</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="n">M1_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1_inv</span><span class="p">)</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span>
                               <span class="p">(</span><span class="n">temp</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design_factors</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>


<span class="k">def</span> <span class="nf">roptimality_criterion</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">pred_factors</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
                          <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the R-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math:: \mathrm{CVaR}\left[\sigma^2f(x)^T\left(F(\mathcal{X})^TF(\mathcal{X})\right)^{-1}f(x)\right]</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    beta : float</span>
<span class="sd">       The confidence level of CVAR</span>

<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The hessian M_1 of the error for each design point</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    pred_factors : np.ndarray (num_pred_pts,num_pred_factors)</span>
<span class="sd">       The prediction factors :math:`g` evaluated at each of the prediction</span>
<span class="sd">       points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    eps : float</span>
<span class="sd">        Hyper-parameter controlling the smoothness of smooth cvar</span>
<span class="sd">        if eps==0 then no smoothing is used.</span>

<span class="sd">    tt : float</span>
<span class="sd">        The current estimate of t used to compute cvar</span>

<span class="sd">    pred_prob_measure : np.ndarray (num_pred_pts)</span>
<span class="sd">        The prob measure :math:`\nu` on the prediction points. If none then</span>
<span class="sd">        assumes samples are random and</span>
<span class="sd">        pred_prob_measure[ii] =  1/num_pred_factors for all uu</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : float</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">eps</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">tt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">tt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If eps&gt;0 tt must both be specified&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">beta</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Beta must be in [0,1)&quot;</span><span class="p">)</span>

    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">num_pred_pts</span><span class="p">,</span>   <span class="n">num_pred_factors</span> <span class="o">=</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">pred_prob_measure</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_pred_pts</span>
    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">M0u</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">M0u</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">conditional_value_at_risk</span><span class="p">(</span>
                <span class="n">variances</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">smooth_conditional_value_at_risk_split</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>

        <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0u</span><span class="p">)))</span>
        <span class="n">Fu</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">Fu</span>
        <span class="n">Fgamma</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cvar_grad</span> <span class="o">=</span> <span class="n">conditional_value_at_risk_subgradient</span><span class="p">(</span>
                <span class="n">variances</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">smooth_conditional_value_at_risk_gradient_split</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
            <span class="n">cvar_grad</span><span class="p">,</span> <span class="n">t_grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">+</span><span class="n">t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span>
                               <span class="n">cvar_grad</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">+</span><span class="n">Fu</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span>
                <span class="n">cvar_grad</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span>

        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">gradient</span><span class="p">,</span> <span class="n">t_grad</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># Value</span>
        <span class="c1"># We want to sum the variances, i.e. the enties of the diagonal of</span>
        <span class="c1"># pred_factors.dot(M1.dot(pred_factors.T))</span>
        <span class="c1"># We know that diag(A.T.dot(B)) = (A*B).axis=0)</span>
        <span class="c1"># The following sums over all entries of A*B we get the diagonal</span>
        <span class="c1"># variances</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">*</span><span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">conditional_value_at_risk</span><span class="p">(</span>
                <span class="n">variances</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">smooth_conditional_value_at_risk_split</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">return_grad</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="c1"># Gradient</span>
        <span class="n">F_M1_inv_P</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cvar_grad</span> <span class="o">=</span> <span class="n">conditional_value_at_risk_subgradient</span><span class="p">(</span>
                <span class="n">variances</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">smooth_conditional_value_at_risk_gradient_split</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
            <span class="n">cvar_grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">t_grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F_M1_inv_P</span><span class="o">.</span><span class="n">T</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">cvar_grad</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span>

        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">gradient</span><span class="p">,</span> <span class="n">t_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">goptimality_criterion</span><span class="p">(</span><span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                          <span class="n">pred_factors</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
                          <span class="n">pred_prob_measure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    valuate the G-optimality criterion for a given design probability measure</span>
<span class="sd">    for the linear model</span>

<span class="sd">    .. math::  y(x) = F(x)\theta+\eta(x)\epsilon.</span>

<span class="sd">    The criteria is</span>

<span class="sd">    .. math:: \max{sup}_{xi\in\Xi_\text{pred}} \sigma^2f(x)^T\left(F(\mathcal{X})^TF(\mathcal{X})\right)^{-1}f(x)</span>

<span class="sd">    where</span>

<span class="sd">    .. math:: C(\mu) = M_1^{-1} M_0 M^{-1}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    homog_outer_prods : np.ndarray (num_design_factors,num_design_factors,</span>
<span class="sd">                                    num_design_pts)</span>
<span class="sd">       The hessian M_1 of the error for each design point</span>

<span class="sd">    design_factors : np.ndarray (num_design_pts,num_design_factors)</span>
<span class="sd">       The design factors evaluated at each of the design points</span>

<span class="sd">    pred_factors : np.ndarray (num_pred_pts,num_pred_factors)</span>
<span class="sd">       The prediction factors g evaluated at each of the prediction points</span>

<span class="sd">    design_prob_measure : np.ndarray (num_design_pts)</span>
<span class="sd">       The prob measure :math:`\mu` on the design points</span>

<span class="sd">    return_grad : boolean</span>
<span class="sd">       True  - return the value and gradient of the criterion</span>
<span class="sd">       False - return only the value of the criterion</span>

<span class="sd">    noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">        The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        Currently supported options are ``lstsq`` and ``quantile``.</span>

<span class="sd">    pred_prob_measure : np.ndarray (num_pred_pts)</span>
<span class="sd">         The prob measure :math:`\nu` on the prediction points. G optimality</span>
<span class="sd">         ignores this</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    value : np.ndarray (num_pred_pts)</span>
<span class="sd">        The value of the objective function</span>

<span class="sd">    grad : np.ndarray (num_pred_pts,num_design_pts)</span>
<span class="sd">        The gradient of the objective function. Only if return_grad is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">num_design_factors</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">num_pred_pts</span><span class="p">,</span>   <span class="n">num_pred_factors</span> <span class="o">=</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">design_prob_measure</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">design_prob_measure</span> <span class="o">=</span> <span class="n">design_prob_measure</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">M0</span><span class="p">,</span> <span class="n">M1</span> <span class="o">=</span> <span class="n">get_M0_and_M1_matrices</span><span class="p">(</span>
        <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_prob_measure</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span>
        <span class="n">regression_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M1</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">M0u</span> <span class="o">=</span> <span class="n">M0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">M0u</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">variances</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_grad</span><span class="p">):</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M0u</span><span class="p">)))</span>
            <span class="n">Fu</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">Fu</span>
            <span class="n">Fgamma</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span> <span class="o">+</span> <span class="n">t</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">elif</span> <span class="n">regression_type</span> <span class="o">==</span> <span class="s1">&#39;quantile&#39;</span><span class="p">:</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">Fu</span><span class="o">*</span><span class="n">Fgamma</span><span class="o">/</span><span class="n">noise_multiplier</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="n">Fu</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span> <span class="n">pred_factors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># Value</span>
        <span class="c1"># We want to sum the variances, i.e. the enties of the diagonal of</span>
        <span class="c1"># pred_factors.dot(M1.dot(pred_factors.T))</span>
        <span class="c1"># We know that diag(A.T.dot(B)) = (A*B).axis=0)00</span>
        <span class="c1"># The following sums over all entries of A*B we get the diagonal</span>
        <span class="c1"># variances</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_factors</span><span class="o">*</span><span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">variances</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">return_grad</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="c1"># Gradient</span>
        <span class="n">F_M1_inv_P</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="o">-</span><span class="n">F_M1_inv_P</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">minimax_oed_objective</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">minimax_oed_objective_jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">vec</span>


<span class="k">def</span> <span class="nf">minimax_oed_constraint_objective</span><span class="p">(</span><span class="n">local_oed_obj</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">local_oed_obj</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>


<span class="k">def</span> <span class="nf">minimax_oed_constraint_jacobian</span><span class="p">(</span><span class="n">local_oed_jac</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="o">-</span><span class="n">local_oed_jac</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">jac</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">jac</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">jac</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">get_minimax_bounds</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Bounds</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_minimax_default_initial_guess</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_design_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">num_design_pts</span>
    <span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x0</span>


<span class="k">def</span> <span class="nf">get_minimax_linear_constraints</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">):</span>
    <span class="n">lb_con</span> <span class="o">=</span> <span class="n">ub_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">A_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">A_con</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">LinearConstraint</span><span class="p">(</span><span class="n">A_con</span><span class="p">,</span> <span class="n">lb_con</span><span class="p">,</span> <span class="n">ub_con</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">extract_minimax_design_from_optimize_result</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>


<span class="k">def</span> <span class="nf">r_oed_objective</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">pred_weights</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">pred_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span><span class="o">*</span><span class="n">u</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pred_weights</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">r_oed_objective_jacobian</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">pred_weights</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">pred_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">vec</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_weights</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vec</span>


<span class="k">def</span> <span class="nf">r_oed_constraint_objective</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="n">local_oed_obj</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">t</span><span class="o">+</span><span class="n">u</span><span class="o">-</span><span class="n">local_oed_obj</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">r_oed_constraint_jacobian</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="n">local_oed_jac</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">)</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="o">-</span><span class="n">local_oed_jac</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">assert</span> <span class="n">jac</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">jac</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">)</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">jac</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">jac</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_pred_pts</span><span class="p">),</span> <span class="n">jac</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">jac</span>


<span class="k">def</span> <span class="nf">r_oed_sparse_constraint_jacobian</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="n">local_oed_jac</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">)</span>
    <span class="n">local_jac</span> <span class="o">=</span> <span class="o">-</span><span class="n">local_oed_jac</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">assert</span> <span class="n">local_jac</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">local_jac</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">)</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="mi">2</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">))</span>
    <span class="n">jac</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">jac</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">local_jac</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">jac</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">jac</span>


<span class="k">def</span> <span class="nf">get_r_oed_bounds</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Bounds</span><span class="p">(</span>
        <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">),</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_r_oed_default_initial_guess</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">):</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_design_pts</span>
    <span class="n">x0</span><span class="p">[:</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x0</span>


<span class="k">def</span> <span class="nf">get_r_oed_linear_constraints</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">):</span>
    <span class="n">lb_con</span> <span class="o">=</span> <span class="n">ub_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">A_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">+</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">))</span>
    <span class="n">A_con</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">LinearConstraint</span><span class="p">(</span><span class="n">A_con</span><span class="p">,</span> <span class="n">lb_con</span><span class="p">,</span> <span class="n">ub_con</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">extract_r_oed_design_from_optimize_result</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="n">res</span><span class="p">):</span>
    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">num_design_pts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">num_pred_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>


<span class="k">def</span> <span class="nf">get_r_oed_jacobian_structure</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">):</span>
    <span class="n">nonlinear_constraint_structure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_pred_pts</span><span class="p">),</span>
         <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_pred_pts</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">))])</span>
    <span class="n">linear_constraint_structure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_pred_pts</span><span class="o">+</span><span class="n">num_design_pts</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">linear_constraint_structure</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">+</span><span class="n">num_pred_pts</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">structure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">linear_constraint_structure</span><span class="p">,</span> <span class="n">nonlinear_constraint_structure</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">structure</span><span class="p">)</span>


<div class="viewcode-block" id="AlphabetOptimalDesign"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AlphabetOptimalDesign.html#pyapprox.expdesign.AlphabetOptimalDesign">[docs]</a><span class="k">class</span> <span class="nc">AlphabetOptimalDesign</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct optimal experimental designs using functions of the fisher</span>
<span class="sd">    information matrix</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Even though scipy.optimize.minimize may print the warning</span>
<span class="sd">    &quot;UserWarning: delta_grad == 0.0. Check if the approximated function is</span>
<span class="sd">    linear. If the function is linear better results can be obtained by</span>
<span class="sd">    defining the Hessian as zero instead of using quasi-Newton</span>
<span class="sd">    approximations&quot;</span>
<span class="sd">    the Hessian is not zero so do not make this change</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        criteria : string</span>
<span class="sd">            The name of the optimality criteria</span>

<span class="sd">        design_factors : np.ndarray (num_design_pts, num_design_factors)</span>
<span class="sd">            The design factors evaluated at each of the design points</span>

<span class="sd">        noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">            The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">        opts : dict</span>
<span class="sd">            Options passed to the non-linear optimizer which solves</span>
<span class="sd">            the  OED problem</span>

<span class="sd">        regression_type : string</span>
<span class="sd">            The method used to compute the coefficients of the linear model.</span>
<span class="sd">            Currently supported options are ``lstsq`` and ``quantile``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">=</span> <span class="n">criteria</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span> <span class="o">=</span> <span class="n">noise_multiplier</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span> <span class="o">=</span> <span class="n">design_factors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span> <span class="o">=</span> <span class="n">regression_type</span>

        <span class="n">homog_outer_prods</span> <span class="o">=</span> <span class="n">compute_homoscedastic_outer_products</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_constraints</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">)</span>

<div class="viewcode-block" id="AlphabetOptimalDesign.objective"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AlphabetOptimalDesign.html#pyapprox.expdesign.AlphabetOptimalDesign.objective">[docs]</a>    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xx</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># kwargs needed for smooth version of r-optimality</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__objective</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="AlphabetOptimalDesign.constraint"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AlphabetOptimalDesign.html#pyapprox.expdesign.AlphabetOptimalDesign.constraint">[docs]</a>    <span class="k">def</span> <span class="nf">constraint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xx</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">xx</span><span class="p">)</span></div>

<div class="viewcode-block" id="AlphabetOptimalDesign.setup_objective"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AlphabetOptimalDesign.html#pyapprox.expdesign.AlphabetOptimalDesign.setup_objective">[docs]</a>    <span class="k">def</span> <span class="nf">setup_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                        <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="n">pred_criteria</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">]</span>
        <span class="n">other_criteria</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="ow">in</span> <span class="n">pred_criteria</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_pred_objective</span><span class="p">(</span>
                <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="ow">in</span> <span class="n">other_criteria</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_other_objective</span><span class="p">(</span>
                <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Optimality criteria: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="si">}</span><span class="s1"> is not supported. &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;Supported criteria are:</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">pred_criteria</span><span class="o">+</span><span class="n">other_criteria</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">R</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__setup_pred_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                               <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="n">pred_factors</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span>
        <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pred_prob_measure&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;I&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">ioptimality_criterion</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                <span class="n">design_factors</span><span class="p">,</span>
                <span class="n">pred_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span>
                <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span><span class="p">,</span>
                <span class="n">pred_prob_measure</span><span class="o">=</span><span class="n">pred_prob_measure</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span><span class="p">:</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">eps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="k">lambda</span> <span class="n">xx</span><span class="p">:</span> <span class="n">roptimality_criterion</span><span class="p">(</span>
                    <span class="n">beta</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                    <span class="n">design_factors</span><span class="p">,</span> <span class="n">pred_factors</span><span class="p">,</span> <span class="n">xx</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">regression_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                    <span class="n">pred_prob_measure</span><span class="o">=</span><span class="n">pred_prob_measure</span><span class="p">,</span> <span class="n">tt</span><span class="o">=</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">pred_prob_measure</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_pred_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_pred_pts</span>
                <span class="n">r_obj</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">r_oed_objective</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
                <span class="n">r_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">r_oed_objective_jacobian</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">pred_prob_measure</span><span class="p">)</span>
                <span class="k">return</span> <span class="k">lambda</span> <span class="n">xx</span><span class="p">:</span> <span class="p">(</span><span class="n">r_obj</span><span class="p">(</span><span class="n">xx</span><span class="p">),</span> <span class="n">r_jac</span><span class="p">(</span><span class="n">xx</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
            <span class="c1"># pred_prob_measure is not used here because we are looking</span>
            <span class="c1"># for worst case</span>
            <span class="k">return</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">goptimality_criterion</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                <span class="n">design_factors</span><span class="p">,</span>
                <span class="n">pred_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span>
                <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setup_other_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                                <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="n">other_criteria_funcs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">aoptimality_criterion</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">coptimality_criterion</span><span class="p">,</span>
            <span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="n">doptimality_criterion</span><span class="p">}</span>
        <span class="n">criteria_fun</span> <span class="o">=</span> <span class="n">other_criteria_funcs</span><span class="p">[</span><span class="n">criteria</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">criteria_fun</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
            <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">regression_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setup_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                            <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span> <span class="ow">and</span> <span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
                <span class="s2">&quot;G&quot;</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">xx</span><span class="p">):</span> <span class="k">return</span> <span class="n">objective</span><span class="p">(</span><span class="n">xx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">def</span> <span class="nf">jac</span><span class="p">(</span><span class="n">xx</span><span class="p">):</span> <span class="k">return</span> <span class="n">objective</span><span class="p">(</span><span class="n">xx</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">constraint_obj</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">r_oed_constraint_objective</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">fun</span><span class="p">)</span>
            <span class="n">constraint_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">r_oed_constraint_jacobian</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">jac</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">NonlinearConstraint</span><span class="p">(</span>
                <span class="n">constraint_obj</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">constraint_jac</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
                <span class="s2">&quot;G&quot;</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
            <span class="n">constraint_obj</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">minimax_oed_constraint_objective</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">obj_from_obj_plus_jac_fun</span><span class="p">,</span> <span class="n">objective</span><span class="p">))</span>
            <span class="n">constraint_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">minimax_oed_constraint_jacobian</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">jac_from_obj_plus_jac_fun</span><span class="p">,</span> <span class="n">objective</span><span class="p">))</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">NonlinearConstraint</span><span class="p">(</span>
                <span class="n">constraint_obj</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">constraint_jac</span><span class="p">)]</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">options</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;solver&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">method</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># method=&#39;trust-constr&#39;</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;slsqp&#39;</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ipopt&#39;</span><span class="p">:</span>
            <span class="c1"># when printing results of derivative_test The first floating point</span>
            <span class="c1"># number is the value given by the user code, and the second number</span>
            <span class="c1"># (after &quot;~&quot;) is the finite differences estimation. Finally, the</span>
            <span class="c1"># number in square brackets is the relative difference between</span>
            <span class="c1"># these two numbers.</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">]</span> <span class="k">for</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">lb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">ub</span><span class="p">)]</span>
            <span class="kn">from</span> <span class="nn">scipy.optimize._constraints</span> <span class="kn">import</span> <span class="n">new_constraint_to_old</span>
            <span class="n">con</span> <span class="o">=</span> <span class="n">new_constraint_to_old</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
            <span class="kn">from</span> <span class="nn">ipopt</span> <span class="kn">import</span> <span class="n">minimize_ipopt</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">minimize_ipopt</span><span class="p">(</span>
                <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">con</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
                <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span><span class="p">],</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">__setup_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Define the bounds of the optimization variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># smoothed roptimaility must solve for design and variable tt which</span>
            <span class="c1"># estimates the quantile used in cvar so make bounds correct size</span>
            <span class="k">return</span> <span class="n">Bounds</span><span class="p">(</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="o">+</span><span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="o">+</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Bounds</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setup_linear_constraint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enforce the constraint that the sum of the design probability masses</span>
<span class="sd">        sum to one</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">lb_con</span> <span class="o">=</span> <span class="n">ub_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># smoothed roptimaility must solve for design and variable tt which</span>
            <span class="c1"># estimates the quantile used in cvar so make constraint correct</span>
            <span class="c1"># size</span>
            <span class="n">A_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">A_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">LinearConstraint</span><span class="p">(</span><span class="n">A_con</span><span class="p">,</span> <span class="n">lb_con</span><span class="p">,</span> <span class="n">ub_con</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setup_initial_guess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_design</span><span class="p">):</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># smoothed roptimaility must solve for design and variable tt which</span>
            <span class="c1"># estimates the quantile used in cvar so add initial guess of 1</span>
            <span class="k">if</span> <span class="n">init_design</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">init_design</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">init_design</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_design_pts</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">init_design</span>

    <span class="k">def</span> <span class="nf">__generic_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Some criteria can be solved in exactly the same way, that is using</span>
<span class="sd">        the workflow in this function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_bounds</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_linear_constraint</span><span class="p">()</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup_initial_guess</span><span class="p">(</span><span class="n">init_design</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__minimize</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_full</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span>

        <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">__roptimality_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__roptimality_solve_slack</span><span class="p">(</span>
                <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__roptimality_solve_smooth</span><span class="p">(</span>
            <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__roptimality_solve_slack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solve exact reformulation of roptimality by adding slack variables.</span>
<span class="sd">        This adds a lot of constraints and so can be computationally demanding</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_pred_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_minimax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">return_full</span><span class="p">,</span>
            <span class="n">init_design</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">get_bounds</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">get_r_oed_bounds</span><span class="p">,</span> <span class="n">num_pred_pts</span><span class="p">),</span>
            <span class="n">get_init_guess</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                <span class="n">get_r_oed_default_initial_guess</span><span class="p">,</span> <span class="n">num_pred_pts</span><span class="p">),</span>
            <span class="n">get_linear_constraint</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                <span class="n">get_r_oed_linear_constraints</span><span class="p">,</span> <span class="n">num_pred_pts</span><span class="p">),</span>
            <span class="n">extract_design_from_optimize_result</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                <span class="n">extract_r_oed_design_from_optimize_result</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__roptimality_solve_smooth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solve the smoothed version of roptimality. The smoothed version</span>
<span class="sd">        introduces a small error but is much more computationaly efficient</span>
<span class="sd">        than the slack variable baed reformulation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__generic_solve</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span>

        <span class="c1"># smoothed roptimaility must solve for design and variable tt which</span>
        <span class="c1"># estimates the quantile used in cvar so subtract off tt from design</span>
        <span class="c1"># returned</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_full</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">weights</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">__goptimality_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">):</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_minimax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">return_full</span><span class="p">,</span>
            <span class="n">init_design</span><span class="p">)</span>

<div class="viewcode-block" id="AlphabetOptimalDesign.solve"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AlphabetOptimalDesign.html#pyapprox.expdesign.AlphabetOptimalDesign.solve">[docs]</a>    <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_design</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__generic_solve</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__roptimality_solve</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">==</span> <span class="s1">&#39;G&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__goptimality_solve</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">init_design</span><span class="p">,</span> <span class="n">return_full</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_solve_minimax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nonlinear_constraints</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span>
                       <span class="n">return_full</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="n">minimax_oed_objective</span><span class="p">,</span>
                       <span class="n">jac</span><span class="o">=</span><span class="n">minimax_oed_objective_jacobian</span><span class="p">,</span>
                       <span class="n">get_bounds</span><span class="o">=</span><span class="n">get_minimax_bounds</span><span class="p">,</span>
                       <span class="n">get_init_guess</span><span class="o">=</span><span class="n">get_minimax_default_initial_guess</span><span class="p">,</span>
                       <span class="n">get_linear_constraint</span><span class="o">=</span><span class="n">get_minimax_linear_constraints</span><span class="p">,</span>
                       <span class="n">extract_design_from_optimize_result</span><span class="o">=</span><span class="n">extract_minimax_design_from_optimize_result</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span> <span class="o">=</span> <span class="n">get_linear_constraint</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span><span class="p">]</span>
        <span class="n">constraints</span> <span class="o">+=</span> <span class="n">nonlinear_constraints</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">get_bounds</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x0</span> <span class="o">=</span> <span class="n">get_init_guess</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span>

        <span class="k">if</span> <span class="s1">&#39;solver&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
            <span class="n">method</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># method=&#39;trust-constr&#39;</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;slsqp&#39;</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ipopt&#39;</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="p">[[</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">]</span>
                      <span class="k">for</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">lb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">ub</span><span class="p">)]</span>
            <span class="kn">from</span> <span class="nn">scipy.optimize._constraints</span> <span class="kn">import</span> <span class="n">new_constraint_to_old</span>
            <span class="n">constraints</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">new_constraint_to_old</span><span class="p">(</span><span class="n">con</span><span class="p">,</span> <span class="n">x0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="n">constraints</span><span class="p">]</span>
            <span class="kn">from</span> <span class="nn">ipopt</span> <span class="kn">import</span> <span class="n">minimize_ipopt</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># if version of ipopt supports it pass in jacobian structure</span>
                <span class="n">options</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">constraint_jacobianstructure</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;constraint_jacobianstructure&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="s1">&#39;constraint_jacobianstructure&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;constraint_jacobianstructure&#39;</span><span class="p">]</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">minimize_ipopt</span><span class="p">(</span>
                    <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                    <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                    <span class="n">constraint_jacobianstructure</span><span class="o">=</span><span class="n">constraint_jacobianstructure</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">minimize_ipopt</span><span class="p">(</span>
                    <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
                <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">extract_design_from_optimize_result</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_full</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">res</span></div>


<span class="k">def</span> <span class="nf">obj_from_obj_plus_jac_fun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">xx</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">fun</span><span class="p">(</span><span class="n">xx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">jac_from_obj_plus_jac_fun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">xx</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">fun</span><span class="p">(</span><span class="n">xx</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>


<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign">[docs]</a><span class="k">class</span> <span class="nc">NonLinearAlphabetOptimalDesign</span><span class="p">(</span><span class="n">AlphabetOptimalDesign</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct minimax optimal experimental designs of non-linear models</span>
<span class="sd">    by sampling fisher information matrix at multiple uncertain parameter</span>
<span class="sd">    realizations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span> <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        criteria : string</span>
<span class="sd">            The name of the optimality criteria</span>

<span class="sd">        design_factors : np.ndarray (num_design_pts, num_design_factors)</span>
<span class="sd">            The design factors evaluated at each of the design points</span>

<span class="sd">        noise_multiplier : np.ndarray (num_design_pts)</span>
<span class="sd">            The design dependent noise function :math:`\eta(x)`</span>

<span class="sd">        opts : dict</span>
<span class="sd">            Options passed to the non-linear optimizer which solves</span>
<span class="sd">            the  OED problem</span>

<span class="sd">        regression_type : string</span>
<span class="sd">            The method used to compute the coefficients of the linear model.</span>
<span class="sd">            Currently supported options are ``lstsq`` and ``quantile``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">design_factors</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;design_factors must be a function that returns local&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot; design factors for a given estimate of the unknown&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;model parameters&quot;</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span> <span class="o">=</span> <span class="n">criteria</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span> <span class="o">=</span> <span class="n">noise_multiplier</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span> <span class="o">=</span> <span class="n">design_factors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span> <span class="o">=</span> <span class="n">regression_type</span>

<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign.setup_minimax_nonlinear_constraints"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign.setup_minimax_nonlinear_constraints">[docs]</a>    <span class="k">def</span> <span class="nf">setup_minimax_nonlinear_constraints</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">parameter_samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">):</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameter_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">design_factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">(</span>
                <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">design_samples</span><span class="p">)</span>
            <span class="n">homog_outer_prods</span> <span class="o">=</span> <span class="n">compute_homoscedastic_outer_products</span><span class="p">(</span>
                <span class="n">design_factors</span><span class="p">)</span>
            <span class="n">opts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">opts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;pred_factors&#39;</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
                <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">](</span>
                    <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_samples&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">noise_multiplier</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">noise_multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span><span class="p">(</span>
                    <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">design_samples</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="k">assert</span> <span class="n">noise_multiplier</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="k">assert</span> <span class="n">noise_multiplier</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">design_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1">#obj, jac = self.get_objective_and_jacobian(</span>
            <span class="c1">#    design_factors.copy(), homog_outer_prods.copy(),</span>
            <span class="c1">#    noise_multiplier, copy.deepcopy(opts))</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">opts</span><span class="p">))</span>
            <span class="n">constraint_obj</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">minimax_oed_constraint_objective</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">obj_from_obj_plus_jac_fun</span><span class="p">,</span> <span class="n">objective</span><span class="p">))</span>
            <span class="n">constraint_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">minimax_oed_constraint_jacobian</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">jac_from_obj_plus_jac_fun</span><span class="p">,</span> <span class="n">objective</span><span class="p">))</span>
            <span class="n">constraint</span> <span class="o">=</span> <span class="n">NonlinearConstraint</span><span class="p">(</span>
                <span class="n">constraint_obj</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">constraint_jac</span><span class="p">)</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">constraints</span></div>

<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign.setup_objective"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign.setup_objective">[docs]</a>    <span class="k">def</span> <span class="nf">setup_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
                        <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">criteria</span> <span class="o">==</span> <span class="s2">&quot;R&quot;</span><span class="p">:</span>
            <span class="n">pred_factors</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span>
            <span class="n">pred_prob_measure</span> <span class="o">=</span> <span class="n">opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pred_prob_measure&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># just assume cvar is differentiable and</span>
            <span class="c1"># use subgradients to compute design. This may not always work</span>
            <span class="c1"># but has worked for all examples I have testsed</span>
            <span class="c1"># we can introduce slack variables to make sure problem is</span>
            <span class="c1"># differentiable everywhere but this will be computationally</span>
            <span class="c1"># expensive</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
            <span class="k">return</span> <span class="k">lambda</span> <span class="n">xx</span><span class="p">:</span> <span class="n">roptimality_criterion</span><span class="p">(</span>
                <span class="n">beta</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span>
                <span class="n">design_factors</span><span class="p">,</span> <span class="n">pred_factors</span><span class="p">,</span> <span class="n">xx</span><span class="p">,</span>
                <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">regression_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regression_type</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                <span class="n">pred_prob_measure</span><span class="o">=</span><span class="n">pred_prob_measure</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
            <span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span>
            <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span></div>

<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign.solve_nonlinear_minimax"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign.solve_nonlinear_minimax">[docs]</a>    <span class="k">def</span> <span class="nf">solve_nonlinear_minimax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">,</span>
                                <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_minimax_nonlinear_constraints</span><span class="p">(</span>
            <span class="n">parameter_samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">)</span>
        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="n">design_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_minimax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_constraints</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">return_full</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span></div>

<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign.bayesian_objective_jacobian_components"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign.bayesian_objective_jacobian_components">[docs]</a>    <span class="k">def</span> <span class="nf">bayesian_objective_jacobian_components</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">parameter_samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">):</span>
        <span class="n">objs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameter_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">design_factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">(</span>
                <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">design_samples</span><span class="p">)</span>
            <span class="n">homog_outer_prods</span> <span class="o">=</span> <span class="n">compute_homoscedastic_outer_products</span><span class="p">(</span>
                <span class="n">design_factors</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">noise_multiplier</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">noise_multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_multiplier</span><span class="p">(</span>
                    <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">design_samples</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="k">assert</span> <span class="n">noise_multiplier</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="k">assert</span> <span class="n">noise_multiplier</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">design_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">opts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">opts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;pred_factors&#39;</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
                <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">](</span>
                    <span class="n">parameter_samples</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">],</span> <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;pred_samples&#39;</span><span class="p">])</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_objective</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">,</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">design_factors</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">opts</span><span class="p">))</span>
            <span class="n">objs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">objective</span><span class="p">)</span>

        <span class="n">num_design_pts</span> <span class="o">=</span> <span class="n">homog_outer_prods</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">objs</span><span class="p">,</span> <span class="n">num_design_pts</span></div>

<div class="viewcode-block" id="NonLinearAlphabetOptimalDesign.solve_nonlinear_bayesian"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.NonLinearAlphabetOptimalDesign.html#pyapprox.expdesign.NonLinearAlphabetOptimalDesign.solve_nonlinear_bayesian">[docs]</a>    <span class="k">def</span> <span class="nf">solve_nonlinear_bayesian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">,</span>
                                 <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                 <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design_factors</span><span class="p">)</span>
        <span class="n">objs</span><span class="p">,</span> <span class="n">num_design_pts</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">bayesian_objective_jacobian_components</span><span class="p">(</span>
                <span class="n">samples</span><span class="p">,</span> <span class="n">design_samples</span><span class="p">)</span>
        <span class="n">lb_con</span> <span class="o">=</span> <span class="n">ub_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">A_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_design_pts</span><span class="p">))</span>
        <span class="n">linear_constraint</span> <span class="o">=</span> <span class="n">LinearConstraint</span><span class="p">(</span><span class="n">A_con</span><span class="p">,</span> <span class="n">lb_con</span><span class="p">,</span> <span class="n">ub_con</span><span class="p">)</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">[</span><span class="n">linear_constraint</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">sample_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">xx</span><span class="p">):</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">vec</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">obj</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">objs</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">):</span>
                <span class="n">val</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
                <span class="n">objective</span> <span class="o">+=</span> <span class="n">val</span><span class="o">*</span><span class="n">weight</span>
                <span class="n">vec</span> <span class="o">+=</span> <span class="n">grad</span><span class="o">*</span><span class="n">weight</span>
            <span class="k">return</span> <span class="n">objective</span><span class="p">,</span> <span class="n">vec</span>

        <span class="c1"># def jacobian(x):</span>
        <span class="c1">#     vec = 0</span>
        <span class="c1">#     for jac, weight in zip(jacs, sample_weights):</span>
        <span class="c1">#         vec += jac(x)*weight</span>
        <span class="c1">#     return vec</span>

        <span class="n">bounds</span> <span class="o">=</span> <span class="n">Bounds</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_design_pts</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_design_pts</span><span class="p">)</span><span class="o">/</span><span class="n">num_design_pts</span>

        <span class="k">if</span> <span class="s1">&#39;solver&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">method</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">options</span><span class="p">[</span><span class="s1">&#39;solver&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># method=&#39;trust-constr&#39;</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;slsqp&#39;</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ipopt&#39;</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="p">[[</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">]</span>
                      <span class="k">for</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">lb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">ub</span><span class="p">)]</span>
            <span class="kn">from</span> <span class="nn">ipopt</span> <span class="kn">import</span> <span class="n">minimize_ipopt</span>
            <span class="kn">from</span> <span class="nn">scipy.optimize._constraints</span> <span class="kn">import</span> <span class="n">new_constraint_to_old</span>
            <span class="n">con</span> <span class="o">=</span> <span class="n">new_constraint_to_old</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_constraint</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">minimize_ipopt</span><span class="p">(</span>
                <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">con</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
                <span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>

        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;obj_fun&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">objective</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_full</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span>
        
        <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">res</span></div></div>


<div class="viewcode-block" id="optimal_experimental_design"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.optimal_experimental_design.html#pyapprox.expdesign.optimal_experimental_design">[docs]</a><span class="k">def</span> <span class="nf">optimal_experimental_design</span><span class="p">(</span>
        <span class="n">design_pts</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="s1">&#39;lstsq&#39;</span><span class="p">,</span>
        <span class="n">noise_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">solver_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">cvar_tol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute optimal experimental designs for models of the form</span>

<span class="sd">    .. math:: y(\rv)=m(\rv;\theta)+\eta(\rv)\epsilon</span>

<span class="sd">    to be used with estimators, such as least-squares and quantile regression,</span>
<span class="sd">    to find approximate parameters</span>
<span class="sd">    :math:`\hat{\theta}` that are the solutions of</span>

<span class="sd">    .. math:: \mathrm{argmin}_\theta \frac{1}{M}\sum_{i=1}^M e(y_i-m(\rv_i;\theta))</span>

<span class="sd">    for some loss function :math:`e`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    design_pts : np.ndarray (nvars,nsamples)</span>
<span class="sd">        All possible experimental conditions</span>

<span class="sd">    design_factors : callable or np.ndarray</span>
<span class="sd">       The function :math:`m(\rv;\theta)` with the signature</span>

<span class="sd">       `design_factors(z,p)-&gt;np.ndarray`</span>

<span class="sd">       where `z` are the design points and `p` are the unknown</span>
<span class="sd">       parameters of the function which will be estimated</span>
<span class="sd">       from data collected using the optimal design</span>

<span class="sd">       A np.ndarray with shape (nsamples,nfactors) where</span>
<span class="sd">       each column is the jacobian of :math:`m(\rv,\theta)` for</span>
<span class="sd">       some :math:`\theta`</span>

<span class="sd">    criteria : string</span>
<span class="sd">       The optimality criteria. Supported criteria are</span>

<span class="sd">       - ``&#39;A&#39;``</span>
<span class="sd">       - ``&#39;D&#39;``</span>
<span class="sd">       - ``&#39;C&#39;``</span>
<span class="sd">       - ``&#39;I&#39;``</span>
<span class="sd">       - ``&#39;R&#39;``</span>
<span class="sd">       - ``&#39;G&#39;``</span>

<span class="sd">       The criteria I,G and R require pred_factors to be provided. A, C and D</span>
<span class="sd">       optimality do not. R optimality requires cvar_tol to be provided.</span>

<span class="sd">       See [KJHSIAMUQ2020]_ for a definition of these criteria</span>

<span class="sd">    regression_type : string</span>
<span class="sd">        The method used to compute the coefficients of the linear model.</span>
<span class="sd">        This defines the loss function :math:`e`.</span>
<span class="sd">        Currently supported options are</span>

<span class="sd">        - ``&#39;lstsq&#39;``</span>
<span class="sd">        - ``&#39;quantile&#39;``</span>

<span class="sd">        Both these options will produce the same design if noise_multiplier</span>
<span class="sd">        is None</span>

<span class="sd">    noise_multiplier : np.ndarray (nsamples)</span>
<span class="sd">        An array specifying the noise multiplier :math:`\eta` at each</span>
<span class="sd">        design point</span>

<span class="sd">    solver_opts : dict</span>
<span class="sd">        Options passed to the non-linear optimizer which solves</span>
<span class="sd">        the OED problem</span>

<span class="sd">    pred_factors : callable or np.ndarray</span>
<span class="sd">        The function :math:`g(\rv;\theta)` with the signature</span>

<span class="sd">        `design_factors(z,p)-&gt;np.ndarray`</span>

<span class="sd">        where `z` are the prediction points and `p` are the unknown</span>
<span class="sd">        parameters</span>

<span class="sd">        A np.ndarray with shape (nsamples,nfactors) where</span>
<span class="sd">        each column is the jacobian of :math:`g(\rv,\theta)` for</span>
<span class="sd">        some :math:`\theta`</span>

<span class="sd">    cvar_tol : float</span>
<span class="sd">        The :math:`0\le\beta&lt;1` quantile defining the R-optimality criteria.</span>
<span class="sd">        When :math:`\beta=0`, I and R optimal designs will be the same.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    final_design_pts : np.ndarray (nvars,nfinal_design_pts)</span>
<span class="sd">        The design points used in the experimental design</span>

<span class="sd">    nrepetitions : np.ndarray (nfinal_design_pts)</span>
<span class="sd">        The number of times to evaluate the model at each</span>
<span class="sd">        design point</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [KJHSIAMUQ2020] `D.P. Kouri, J.D. Jakeman, G. Huerta, Risk-Adapted Optimal Experimental Design.`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">fun</span><span class="p">):</span>
        <span class="n">design_factors</span> <span class="o">=</span> <span class="n">fun</span>

    <span class="n">opts</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">pred_factors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pred_factors&#39;</span><span class="p">:</span> <span class="n">pred_factors</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">cvar_tol</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cvar_tol</span>

    <span class="n">ncandidate_design_pts</span> <span class="o">=</span> <span class="n">design_pts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">opt_problem</span> <span class="o">=</span> <span class="n">AlphabetOptimalDesign</span><span class="p">(</span>
        <span class="n">criteria</span><span class="p">,</span> <span class="n">design_factors</span><span class="p">,</span> <span class="n">regression_type</span><span class="o">=</span><span class="n">regression_type</span><span class="p">,</span>
        <span class="n">noise_multiplier</span><span class="o">=</span><span class="n">noise_multiplier</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="n">opts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">solver_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">solver_opts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;iprint&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;ftol&#39;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">}</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">opt_problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">solver_opts</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mu</span><span class="o">*</span><span class="n">ncandidate_design_pts</span><span class="p">)</span>
    <span class="n">II</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">design_pts</span><span class="p">[:,</span> <span class="n">II</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="n">II</span><span class="p">]</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>