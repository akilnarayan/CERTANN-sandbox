<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyapprox.expdesign.bayesian_oed &mdash; PyApprox 1.0.2 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            PyApprox
              <img src="../../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Software Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pyapprox.expdesign.bayesian_oed</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyapprox.expdesign.bayesian_oed</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.pya_numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span><span class="p">,</span> <span class="n">RawArray</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="kn">from</span> <span class="nn">pyapprox.util.sys_utilities</span> <span class="kn">import</span> <span class="n">trace_error_with_msg</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.utilities</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_tensor_product_quadrature_rule</span><span class="p">,</span> <span class="n">split_indices</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.risk</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">conditional_value_at_risk</span><span class="p">,</span> <span class="n">conditional_value_at_risk_vectorized</span><span class="p">,</span>
    <span class="n">entropic_risk_measure</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.transforms</span> <span class="kn">import</span> <span class="n">AffineTransform</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.joint</span> <span class="kn">import</span> <span class="n">IndependentMarginalsVariable</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.tensorprod</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_tensor_product_piecewise_polynomial_quadrature_rule</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.polychaos.gpc</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.barycentric_interpolation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_barycentric_weights_1d</span><span class="p">,</span>
    <span class="n">multivariate_barycentric_lagrange_interpolation</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.integrate</span> <span class="kn">import</span> <span class="n">integrate</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_broadcast</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conmpute the log-likelihood values from a set of real and predicted</span>
<span class="sd">    observations</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obs : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The real observations repeated for each sample</span>

<span class="sd">    pred_obs : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The observations predicited by the model for a set of samples</span>

<span class="sd">    noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">        The standard deviation of Gaussian noise added to each observation</span>

<span class="sd">    active_indices : np.ndarray (nobs, 1)</span>
<span class="sd">        The subset of indices of the observations used to compute the</span>
<span class="sd">        likelihood</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    llike : np.ndaray (nsamples, 1)</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This can handle 1d, 2d, 3d arrays but is slower</span>
<span class="sd">    due to broadcasting when computing obs-pred_obs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">and</span>
            <span class="n">noise_std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;noise_std must be provided for each observation&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span>

    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># avoid copy if possible</span>
        <span class="c1"># using special indexing with array e.g array[:, I] where I is an array</span>
        <span class="c1"># makes a copy which is slow</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tmp</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
        <span class="n">llike</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">obs</span><span class="o">-</span><span class="n">pred_obs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">tmp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tmp</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
        <span class="n">llike</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="o">-</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">-</span><span class="n">pred_obs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">tmp</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sq_dists_numba_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the scaled l2-norm distance between two sets of samples</span>
<span class="sd">    E.g. for one point</span>


<span class="sd">    a[ii]*(XX[ii]-YY[ii])+b</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    XX : np.ndarray (LL, 1, NN)</span>
<span class="sd">        The first set of samples</span>

<span class="sd">    YY : np.ndarray (LL, MM, NN)</span>
<span class="sd">        The second set of samples. The 3D arrays are useful when computing</span>
<span class="sd">        squared distances for multiple sets of samples</span>

<span class="sd">    a : float or np.ndarray (NN, 1)</span>
<span class="sd">        scalar multiplying l2 distance</span>

<span class="sd">    b : float</span>
<span class="sd">        scalar added to l2 distance</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ss : np.ndarray (LL, MM)</span>
<span class="sd">        The scaled distances</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Yshape</span> <span class="o">=</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">XX</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span> <span class="o">-</span>
                    <span class="n">YY</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span><span class="o">+</span><span class="n">b</span>
    <span class="k">return</span> <span class="n">ss</span>


<span class="k">def</span> <span class="nf">sq_dists_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyapprox.cython.utilities</span> <span class="kn">import</span> <span class="n">sq_dists_3d_pyx</span>
        <span class="k">return</span> <span class="n">sq_dists_3d_pyx</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">except</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;sq_dists_3d extension failed&#39;</span>
        <span class="n">trace_error_with_msg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sq_dists_numba_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_economial_3D</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pred_obs must be 3D&quot;</span><span class="p">)</span>
    <span class="c1"># cdist has a lot of overhead and cannot be used with active_indices</span>
    <span class="c1"># sq_dists = sq_dists_cdist_3d(obs, pred_obs)</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span>

    <span class="n">tmp1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="n">llike</span> <span class="o">=</span> <span class="n">sq_dists_3d</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">tmp1</span><span class="p">,</span> <span class="n">tmp2</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the scaled l2-norm distance between two sets of samples</span>
<span class="sd">    E.g. for one point</span>


<span class="sd">    a[ii]*(XX[ii]-YY[ii])+b</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    XX : np.ndarray (LL, 1, NN)</span>
<span class="sd">        The first set of samples</span>

<span class="sd">    YY : np.ndarray (LL, MM, NN)</span>
<span class="sd">        The second set of samples. The 3D arrays are useful when computing</span>
<span class="sd">        squared distances for multiple sets of samples</span>

<span class="sd">    a : float or np.ndarray (NN, 1)</span>
<span class="sd">        scalar multiplying l2 distance</span>

<span class="sd">    b : float</span>
<span class="sd">        scalar added to l2 distance</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ss : np.ndarray (LL, MM)</span>
<span class="sd">        The scaled distances</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Yshape</span> <span class="o">=</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">XX</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span> <span class="o">-</span> <span class="n">YY</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span><span class="o">+</span><span class="n">b</span>
    <span class="k">return</span> <span class="n">ss</span>


<span class="k">def</span> <span class="nf">sq_dists_3d_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyapprox.cython.utilities</span> <span class="kn">import</span> <span class="n">sq_dists_3d_prereduced_pyx</span>
        <span class="k">return</span> <span class="n">sq_dists_3d_prereduced_pyx</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">except</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;sq_dists_3d_prereduced extension failed&#39;</span>
        <span class="n">trace_error_with_msg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_3d_prereduced</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span>

    <span class="n">tmp1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="n">llike</span> <span class="o">=</span> <span class="n">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">tmp1</span><span class="p">,</span> <span class="n">tmp2</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="k">def</span> <span class="nf">compute_weighted_sqeuclidian_distance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                                          <span class="n">active_indices</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs and pred_obs must be 2D arrays&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">or</span> <span class="n">noise_std</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;noise_std must be a 2d np.ndarray with one column&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="c1"># avoid copy is possible</span>
        <span class="c1"># using special indexing with array makes a copy which is slow</span>
        <span class="n">weighted_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">*</span><span class="n">weights</span>
        <span class="n">weighted_pred_obs</span> <span class="o">=</span> <span class="n">pred_obs</span><span class="o">*</span><span class="n">weights</span>
        <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">weighted_obs</span><span class="p">,</span> <span class="n">weighted_pred_obs</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sq_dists</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">weighted_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span>
    <span class="n">weighted_pred_obs</span> <span class="o">=</span> <span class="n">pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span>
    <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">weighted_obs</span><span class="p">,</span> <span class="n">weighted_pred_obs</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sq_dists</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_economial_2D</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_std</span>
    <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">compute_weighted_sqeuclidian_distance</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">-</span>
                 <span class="n">sq_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">-</span>
                 <span class="n">sq_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_economial_3D</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_economial_2D</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_broadcast</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_evidences</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">):</span>
    <span class="n">MM</span><span class="p">,</span> <span class="n">NN</span> <span class="o">=</span> <span class="n">inner_log_likelihood_vals</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">MM</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MM</span><span class="p">):</span>
        <span class="n">evidences</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NN</span><span class="p">):</span>
            <span class="n">evidences</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
                <span class="n">inner_log_likelihood_vals</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">nn</span><span class="p">])</span><span class="o">*</span><span class="n">in_weights</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">nn</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">evidences</span>


<span class="k">def</span> <span class="nf">_loglike_fun_from_noiseless_obs</span><span class="p">(</span>
        <span class="n">noiseless_obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_realizations</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">active_indices</span><span class="p">):</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">noiseless_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">obs</span> <span class="o">+=</span> <span class="n">noise_realizations</span><span class="p">[:,</span> <span class="p">:</span><span class="n">nactive_indices</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_3d_prereduced</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gaussian_loglike_fun</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">],</span> <span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">])</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_compute_evidences_repeated_in_samples</span><span class="p">(</span>
        <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
    <span class="n">nout_samples</span> <span class="o">=</span> <span class="n">out_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nin_samples</span> <span class="o">=</span> <span class="n">in_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">const1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nout_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">const2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">const1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nout_samples</span><span class="p">):</span>
        <span class="n">evidences</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">):</span>
            <span class="n">loglike_val</span> <span class="o">=</span> <span class="n">const2</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">loglike_val</span> <span class="o">+=</span> <span class="n">const1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">out_obs</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span> <span class="o">-</span>
                    <span class="n">in_pred_obs</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">evidences</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike_val</span><span class="p">)</span><span class="o">*</span><span class="n">in_weights</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">evidences</span>


<span class="k">def</span> <span class="nf">_compute_evidences</span><span class="p">(</span>
        <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span>
        <span class="n">out_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
    <span class="c1"># warning outerloop_pred_obs has already been reduced down to</span>
    <span class="c1"># the active indices but in_pred_obs has not. The cost of</span>
    <span class="c1"># copying (from special indexing) is too expensive for the</span>
    <span class="c1"># later (and larger) array.</span>

    <span class="n">outer_log_likelihood_vals</span> <span class="o">=</span> <span class="n">_loglike_fun_from_noiseless_obs</span><span class="p">(</span>
        <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span>
        <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>

    <span class="n">out_obs</span> <span class="o">=</span> <span class="n">out_pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">out_obs</span> <span class="o">+=</span> <span class="n">noise_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">_compute_evidences_repeated_in_samples</span><span class="p">(</span>
        <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">outer_log_likelihood_vals</span><span class="p">,</span> <span class="n">evidences</span>


<span class="k">def</span> <span class="nf">_compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
        <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">,</span>
        <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected Kullback–Leibler (KL) divergence.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    log_likelihood_fun : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        `log_likelihood_fun(obs, pred_obs) -&gt; np.ndarray (nsamples, 1)`</span>

<span class="sd">        That returns the log likelihood for a set of observations and</span>
<span class="sd">        predictions.</span>
<span class="sd">        obs : np.ndarray(nsamples, nobs+nnew_obs)</span>
<span class="sd">        pred_obs : np.ndarray(nsamples, nobs+nnew_obs)</span>

<span class="sd">    out_pred_obs : np.ndarray (nout_samples, ncandidates)</span>
<span class="sd">        The noiseless values of out_obs with noise removed</span>

<span class="sd">    in_pred_obs : np.ndarray (nout_samples*nin_samples, ncandidates)</span>
<span class="sd">        The noiseless values of obs_fun at all sets of innerloop samples</span>
<span class="sd">        used for each outerloop iteration. The values are stacked such</span>
<span class="sd">        that np.vstack((inner_loop1_vals, inner_loop2_vals, ...))</span>

<span class="sd">    in_weights  : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">        The quadrature weights associated with each in_pred_obs set</span>
<span class="sd">        used to compute the inner integral.</span>

<span class="sd">    out_weights  : np.ndarray (nout_samples, 1)</span>
<span class="sd">        The quadrature weights associated with each out_pred_obs set</span>
<span class="sd">        used to compute the outer integral.</span>

<span class="sd">    collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">        The indices into the qoi vector associated with new design locations</span>
<span class="sd">        under consideration</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    utility : float</span>
<span class="sd">        The expected utility</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">outer_log_likelihood_vals</span><span class="p">,</span> <span class="n">evidences</span> <span class="o">=</span> <span class="n">_compute_evidences</span><span class="p">(</span>
         <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">,</span>
         <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">)</span>

    <span class="n">divergences</span> <span class="o">=</span> <span class="n">outer_log_likelihood_vals</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">evidences</span><span class="p">)</span>
    <span class="n">utility_val</span> <span class="o">=</span> <span class="n">data_risk_fun</span><span class="p">(</span><span class="n">divergences</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">)</span>
    <span class="c1"># utility_val = np.sum((outer_log_likelihood_vals - np.log(evidences)) *</span>
    <span class="c1">#                      out_weights)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;utility_val&quot;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;utility_val&quot;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">,</span> <span class="s2">&quot;evidences&quot;</span><span class="p">:</span> <span class="n">evidences</span><span class="p">,</span>
              <span class="s2">&quot;divergences&quot;</span><span class="p">:</span> <span class="n">divergences</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">_precompute_out_quadrature_rule</span><span class="p">(</span>
        <span class="n">nvars</span><span class="p">,</span> <span class="n">generate_prior_noise_samples</span><span class="p">,</span> <span class="n">nout_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    generate_outer_prior_samples : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `generate_outer_prior_samples(nsamples) -&gt; np.ndarray(nvars, nsamples)`</span>

<span class="sd">        That returns a set of random samples randomly drawn from the prior</span>
<span class="sd">        These samples are used to draw condition samples of the obsevations</span>
<span class="sd">        which are used to take an expectation with respect to the data space</span>
<span class="sd">        in the outer loop</span>

<span class="sd">    nout_samples : integer</span>
<span class="sd">        The number of Monte Carlo samples used to compute the outer integral</span>
<span class="sd">        over all possible observations</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out_quad_data : tuple(outerquad_x, outerquad_w)</span>
<span class="sd">        Tuple containing the points and weights of the outer quadrature rule</span>
<span class="sd">        with respect to the joint density of the prior and noise.</span>
<span class="sd">        outerquad_x is np.ndarray(nprior_vars, nquad)</span>
<span class="sd">        outerquad_w is np.ndarray(nquad, 1)</span>

<span class="sd">    out_noise_samples : np.ndarray (max_ncollected_obs, nquad)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out_samples</span><span class="p">,</span> <span class="n">out_weights</span> <span class="o">=</span> \
        <span class="n">generate_prior_noise_samples</span><span class="p">(</span><span class="n">nout_samples</span><span class="p">)</span>
    <span class="n">out_prior_samples</span> <span class="o">=</span> <span class="n">out_samples</span><span class="p">[:</span><span class="n">nvars</span><span class="p">]</span>
    <span class="n">out_noise_samples</span> <span class="o">=</span> <span class="n">out_samples</span><span class="p">[</span><span class="n">nvars</span><span class="p">:]</span>
    <span class="n">out_prior_quad_data</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">out_prior_samples</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">out_prior_quad_data</span><span class="p">,</span> <span class="n">out_noise_samples</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_precompute_expected_kl_utility_data</span><span class="p">(</span><span class="n">out_quad_data</span><span class="p">,</span> <span class="n">in_quad_data</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    out_quad_data : tuple(outerquad_x, outerquad_w)</span>
<span class="sd">        Tuple containing the points and weights of the outer quadrature rule</span>
<span class="sd">        with respect to the prior used for outerloop calculations.</span>
<span class="sd">        outerquad_x is np.ndarray(nprior_vars, nquad)</span>
<span class="sd">        outerquad_w is np.ndarray(nquad, 1)</span>

<span class="sd">    in_quad_data : tuple(outerquad_x, outerquad_w)</span>
<span class="sd">        Tuple containing the points and weights of the outer quadrature rule</span>
<span class="sd">        with respect to the joint prior used for innerloop calculations.</span>
<span class="sd">        outerquad_x is np.ndarray(nprior_vars, nquad)</span>
<span class="sd">        outerquad_w is np.ndarray(nquad, 1)</span>

<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns noiseless evaluations of the forward model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out_pred_obs : np.ndarray (nout_samples, ncandidates)</span>
<span class="sd">        The noiseless values of out_obs with noise removed</span>

<span class="sd">    in_pred_obs : np.ndarray (nout_samples*nin_samples, ncandidates)</span>
<span class="sd">        The noiseless values of obs_fun at all sets of innerloop samples</span>
<span class="sd">        used for each outerloop iteration. The values are stacked such</span>
<span class="sd">        that np.vstack((inner_loop1_vals, inner_loop2_vals, ...))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out_prior_samples</span><span class="p">,</span> <span class="n">out_weights</span> <span class="o">=</span> <span class="n">out_quad_data</span>
    <span class="k">assert</span> <span class="n">out_weights</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">out_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> outer model evaluations&quot;</span><span class="p">)</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">out_pred_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">out_prior_samples</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted observation bounds&quot;</span><span class="p">,</span>
          <span class="n">out_pred_obs</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">out_pred_obs</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluations took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">out_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;obs_fun is not returning an array with the correct shape.&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; nrows is </span><span class="si">{</span><span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">. Should be &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">out_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">in_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> inner model evaluations&quot;</span><span class="p">)</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">in_pred_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">in_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluations took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span>


<span class="k">def</span> <span class="nf">_precompute_expected_deviation_data</span><span class="p">(</span>
        <span class="n">out_quad_data</span><span class="p">,</span> <span class="n">in_quad_data</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="p">):</span>
    <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span> <span class="o">=</span> <span class="n">_precompute_expected_kl_utility_data</span><span class="p">(</span>
        <span class="n">out_quad_data</span><span class="p">,</span> <span class="n">in_quad_data</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">)</span>
    <span class="n">in_samples</span> <span class="o">=</span> <span class="n">in_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">in_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> qoi model evaluations&quot;</span><span class="p">)</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">in_pred_qois</span> <span class="o">=</span> <span class="n">qoi_fun</span><span class="p">(</span><span class="n">in_samples</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluations took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">in_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">in_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;qoi_fun is not returning an array with the correct shape&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_pred_qois</span>


<span class="k">def</span> <span class="nf">_evidences_and_weights</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">):</span>
    <span class="n">inner_likelihood_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">)</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ij,ij-&gt;i&quot;</span><span class="p">,</span> <span class="n">inner_likelihood_vals</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">inner_likelihood_vals</span><span class="o">*</span><span class="n">in_weights</span><span class="o">/</span><span class="n">evidences</span>
    <span class="k">return</span> <span class="n">evidences</span><span class="p">,</span> <span class="n">weights</span>


<span class="c1"># @njit(cache=True)</span>
<span class="c1"># def _evidences_and_weights(inner_log_likelihood_vals, in_weights):</span>
<span class="c1">#     MM, NN = inner_log_likelihood_vals.shape</span>
<span class="c1">#     evidences = np.empty((MM, 1))</span>
<span class="c1">#     weights = in_weights.copy()</span>
<span class="c1">#     for mm in range(MM):</span>
<span class="c1">#         evidences[mm, 0] = 0.0</span>
<span class="c1">#         for nn in range(NN):</span>
<span class="c1">#             likelihood_val = math.exp(inner_log_likelihood_vals[mm, nn])</span>
<span class="c1">#             weights[mm, nn] *= likelihood_val</span>
<span class="c1">#             evidences[mm, 0] += weights[mm, nn]</span>
<span class="c1">#     return evidences, weights/evidences</span>


<span class="k">def</span> <span class="nf">_compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
        <span class="n">out_pred_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">,</span>
        <span class="n">in_pred_qois</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">,</span>
        <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
    <span class="n">nout_samples</span> <span class="o">=</span> <span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nin_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">in_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">nout_samples</span><span class="p">)</span>
    <span class="n">nobs</span> <span class="o">=</span> <span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># tmp = in_pred_obs.reshape(nout_samples, nin_samples, nobs)</span>
    <span class="c1"># inner_log_likelihood_vals = _loglike_fun_from_noiseless_obs(</span>
    <span class="c1">#     out_pred_obs, tmp, noise_samples,</span>
    <span class="c1">#     noise_std, active_indices)</span>
    <span class="c1"># # evidences = _evidences(inner_log_likelihood_vals, in_weights)</span>
    <span class="c1"># # print(evidences.shape, &#39;e&#39;)</span>

    <span class="c1"># # inner_log_likelihood_vals = log_likelihood_fun(</span>
    <span class="c1"># #     out_pred_obs, tmp, active_indices)</span>
    <span class="c1"># evidences, weights = _evidences_and_weights(</span>
    <span class="c1">#     inner_log_likelihood_vals, in_weights)</span>

    <span class="c1"># # make deviation_fun operate on columns of samples</span>
    <span class="c1"># # so that it returns a vector of deviations one for each column</span>
    <span class="c1"># deviations = deviation_fun(in_pred_qois, weights)</span>

    <span class="n">out_obs</span> <span class="o">=</span> <span class="n">out_pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="c1"># print(out_obs.shape, active_indices.shape, noise_samples.shape)</span>
    <span class="n">out_obs</span> <span class="o">+=</span> <span class="n">noise_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">deviations</span><span class="p">,</span> <span class="n">evidences</span> <span class="o">=</span> <span class="n">deviation_fun</span><span class="p">(</span>
        <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">in_pred_qois</span><span class="p">)</span>

    <span class="c1"># expectation taken with respect to observations</span>
    <span class="c1"># assume always want deviation here, but this can be changed</span>
    <span class="c1"># expected_obs_deviations = np.sum(deviations*out_weights, axis=0)</span>
    <span class="c1"># use einsum because it does not create intermediate arrays</span>
    <span class="c1"># expected_obs_deviations = np.einsum(</span>
    <span class="c1">#    &quot;ij,i-&gt;j&quot;, deviations, out_weights[:, 0])</span>
    <span class="n">expected_obs_deviations</span> <span class="o">=</span> <span class="n">data_risk_fun</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">)</span>

    <span class="n">disutility_val</span> <span class="o">=</span> <span class="n">pred_risk_fun</span><span class="p">(</span><span class="n">expected_obs_deviations</span><span class="p">)</span>

    <span class="n">utility_val</span> <span class="o">=</span> <span class="o">-</span><span class="n">disutility_val</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;utility_val&#39;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;utility_val&#39;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">,</span> <span class="s1">&#39;evidences&#39;</span><span class="p">:</span> <span class="n">evidences</span><span class="p">,</span>
        <span class="s1">&#39;deviations&#39;</span><span class="p">:</span> <span class="n">deviations</span><span class="p">,</span>
        <span class="s1">&#39;expected_deviations&#39;</span><span class="p">:</span> <span class="n">expected_obs_deviations</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">update_observations</span><span class="p">(</span><span class="n">design_candidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                        <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">,</span>
                        <span class="n">collected_obs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updated the real collected data with obsevations at the new selected</span>
<span class="sd">    candidate locations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------</span>
<span class="sd">    design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_design_samples)</span>
<span class="sd">        The indices into the design_candidates array of the new selected</span>
<span class="sd">        design samples</span>

<span class="sd">    obs_process : callable</span>
<span class="sd">        The true data generation model with the signature</span>

<span class="sd">        `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">        where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">    collected_obs : np.ndarray (1, nobs)</span>
<span class="sd">        The observations at the previously selected design samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    updated_collected_obs : np.ndarray (1, nobs+nnew_design_samples)</span>
<span class="sd">        The updated collected observations with the new observations</span>
<span class="sd">        appended to the previous observations</span>

<span class="sd">    updated_collected_design_indices : np.ndarray (1, nobs+nnew_design_samples)</span>
<span class="sd">        The updated indices associated with all the collected observations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_obs</span> <span class="o">=</span> <span class="n">obs_process</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">collected_obs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">new_obs</span><span class="p">,</span> <span class="n">new_design_indices</span>

    <span class="n">updated_collected_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">))</span>
    <span class="n">updated_collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">updated_collected_obs</span><span class="p">,</span> <span class="n">updated_collected_design_indices</span>


<span class="k">def</span> <span class="nf">d_optimal_utility</span><span class="p">(</span><span class="n">Amat</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the d-optimality criterion for a linear model f(x) = Amat.dot(x)</span>

<span class="sd">    Assume R = sigma^2 I</span>

<span class="sd">    Posterior covaiance</span>
<span class="sd">    sigma^2 inv(A^TA+R)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Alen Alexanderian and Arvind K. Saibaba</span>
<span class="sd">    Efficient D-Optimal Design of Experiments for</span>
<span class="sd">    Infinite-Dimensional Bayesian Linear Inverse Problems</span>
<span class="sd">    SIAM Journal on Scientific Computing 2018 40:5, A2956-A2985</span>
<span class="sd">    https://doi.org/10.1137/17M115712X</span>
<span class="sd">    Theorem 1</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">Amat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">hess_misfit</span> <span class="o">=</span> <span class="n">Amat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Amat</span><span class="p">)</span><span class="o">/</span><span class="n">noise_std</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">ident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nvars</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="n">hess_misfit</span><span class="o">+</span><span class="n">ident</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_define_design_data</span><span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span>
                        <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span>
                        <span class="n">ndata_per_candidate</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
    <span class="c1"># unlike open loop design (closed loop batch design)</span>
    <span class="c1"># we do not update inner and outer loop weights but rather</span>
    <span class="c1"># just compute likelihood for all collected and new design indices</span>
    <span class="c1"># If want to update weights then we must have a different set of</span>
    <span class="c1"># weights for each inner iteration of the inner loop that is</span>
    <span class="c1"># computed using</span>
    <span class="c1"># the associated outerloop data</span>
    <span class="k">if</span> <span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># assume the observations at the collected_design_indices are</span>
        <span class="c1"># already incorporated into the inner and outer loop weights</span>
        <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>

    <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">idx</span><span class="o">*</span><span class="n">ndata_per_candidate</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
        <span class="n">ndata_per_candidate</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">design_indices</span><span class="p">])</span>
    <span class="c1"># assume same noise_std for each data point associated with a design</span>
    <span class="c1"># candidate. Consider adding ndata_per_candidate to self.__init__</span>
    <span class="c1"># and defining noise_std correct length there.</span>
    <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">noise_std</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">*</span><span class="n">ndata_per_candidate</span>
         <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndesign_candidates</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span>


<span class="k">def</span> <span class="nf">oed_data_expectation</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected deviation for each outer loop sample</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deviations : np.ndarray (nout_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, 1)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    expected_obs_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">expected_obs_deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ij,i-&gt;j&quot;</span><span class="p">,</span> <span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">expected_obs_deviations</span>


<div class="viewcode-block" id="AbstractBayesianOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED">[docs]</a><span class="k">class</span> <span class="nc">AbstractBayesianOED</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Base Bayesian OED class&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span>
                 <span class="n">in_quad_opts</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ndata_per_candidate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">oed_data_expectation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ndesign_candidates :</span>
<span class="sd">            The number of design candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, ndesign_candidates*ndata_per_candidate)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        nin_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nout_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">        nprocs : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>

<span class="sd">        max_ncollected_obs : integer</span>
<span class="sd">            The maximum number of observations that will be collected.</span>

<span class="sd">        outer_quad_type : string</span>
<span class="sd">            The type of quadrature used for the outerloop. Choose from</span>
<span class="sd">            [&quot;mc&quot;, :&quot;qmc:, &quot;gauss&quot;]</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span> <span class="o">=</span> <span class="n">ndesign_candidates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span> <span class="o">=</span> <span class="n">ndata_per_candidate</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">obs_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span> <span class="o">=</span> <span class="n">obs_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span> <span class="o">=</span> <span class="n">noise_std</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;noise_std must be scalar or given for each design candidate&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># for now assume homoscedastic noise. TODO. currently</span>
        <span class="c1"># noise_variable_marginals is used to create quadrature rule</span>
        <span class="c1"># used for all design candidates. IF want to allow for heteroscedastic</span>
        <span class="c1"># noise then must scale this quadrule for each design location</span>
        <span class="c1"># when computing noisy data in utility functions</span>
        <span class="c1"># Also assume same noise applied to each data point associated</span>
        <span class="c1"># with a design candidate. See compute_expected_utility</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span> <span class="o">=</span> <span class="n">prior_variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_ncollected_obs</span> <span class="o">=</span> <span class="n">max_ncollected_obs</span>
        <span class="n">noise_variable_marginals</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">max_ncollected_obs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">joint_prior_noise_variable</span> <span class="o">=</span> <span class="n">IndependentMarginalsVariable</span><span class="p">(</span>
            <span class="n">prior_variable</span><span class="o">.</span><span class="n">marginals</span><span class="p">()</span><span class="o">+</span><span class="n">noise_variable_marginals</span><span class="p">)</span>

        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_quad_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_quad_data</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quad_rules</span><span class="p">(</span><span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nout_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nin_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_prior_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_quad_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_quad_data</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nprocs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_nprocs</span><span class="p">(</span><span class="n">nprocs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span> <span class="o">=</span> <span class="n">data_risk_fun</span>

    <span class="k">def</span> <span class="nf">_get_quad_rules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">):</span>
        <span class="n">out_quad_data</span> <span class="o">=</span> <span class="n">integrate</span><span class="p">(</span>
            <span class="n">out_quad_opts</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">joint_prior_noise_variable</span><span class="p">,</span>
            <span class="o">*</span><span class="n">out_quad_opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;args&quot;</span><span class="p">,</span> <span class="p">[]),</span> <span class="o">**</span><span class="n">out_quad_opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;kwargs&quot;</span><span class="p">,</span> <span class="p">[]))</span>
        <span class="n">out_prior_samples</span> <span class="o">=</span> <span class="n">out_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()]</span>
        <span class="n">out_noise_samples</span> <span class="o">=</span> <span class="n">out_quad_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">():]</span><span class="o">.</span><span class="n">T</span>
        <span class="n">out_quad_data</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">out_prior_samples</span><span class="p">,</span> <span class="n">out_quad_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">in_quad_data</span> <span class="o">=</span> <span class="n">integrate</span><span class="p">(</span>
            <span class="n">in_quad_opts</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span><span class="p">,</span>
            <span class="o">*</span><span class="n">in_quad_opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;args&quot;</span><span class="p">,</span> <span class="p">[]),</span> <span class="o">**</span><span class="n">in_quad_opts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;kwargs&quot;</span><span class="p">,</span> <span class="p">[]))</span>
        <span class="n">econ</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">out_quad_data</span><span class="p">,</span> <span class="n">out_noise_samples</span><span class="p">,</span> <span class="n">in_quad_data</span><span class="p">,</span> <span class="n">econ</span>

    <span class="k">def</span> <span class="nf">_set_nprocs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nprocs</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">nprocs</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="s1">&#39;OMP_NUM_THREADS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span> <span class="ow">or</span>
                <span class="ow">not</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;OMP_NUM_THREADS&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;User set assert_omp=True but OMP_NUM_THREADS has not been &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;set to 1. Run script with &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;OMP_NUM_THREADS=1 python script.py&#39;</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nprocs</span>

<div class="viewcode-block" id="AbstractBayesianOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.populate">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.update_design"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.update_design">[docs]</a>    <span class="k">def</span> <span class="nf">update_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nnew</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_pred_obs&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must call self.populate before creating designs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">nnew</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_ncollected_obs</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;To many new design points requested. Decrease nnew and/or &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;increase self.max_ncollected_obs&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_indices</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_design</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">nnew</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">selected_indices</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_all</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_indices</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_indices</span><span class="p">,</span> <span class="n">results</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.set_collected_design_indices"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.set_collected_design_indices">[docs]</a>    <span class="k">def</span> <span class="nf">set_collected_design_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.compute_expected_utility">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_compute_utilities_parallel_shared</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">worker_fun</span><span class="p">,</span> <span class="n">init_worker</span><span class="p">,</span> <span class="n">_get_initargs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span>
            <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
        <span class="n">nindices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="n">split_indices</span><span class="p">(</span><span class="n">nindices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nprocs</span><span class="p">)</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[(</span><span class="n">indices</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="n">ii</span><span class="p">]:</span><span class="n">splits</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                 <span class="n">return_all</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">splits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="c1"># t0 = time.time()</span>
        <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nprocs</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_worker</span><span class="p">,</span>
                  <span class="n">initargs</span><span class="o">=</span><span class="n">_get_initargs</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
            <span class="c1"># print(&quot;pool startup&quot;, time.time()-t0)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">worker_fun</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="n">utility_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">])</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">+=</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">results</span>

    <span class="c1"># does not work due to ussues with pickling</span>
    <span class="c1"># def _compute_utilities_parallel(self, ncandidates,</span>
    <span class="c1">#                                 collected_design_indices, return_all):</span>
    <span class="c1">#     splits = split_indices(self.ndesign_candidates, self.nprocs)</span>
    <span class="c1">#     args = [(splits[ii], splits[ii+1]) for ii in range(splits.shape[0]-1)]</span>
    <span class="c1">#     t0 = time.time()</span>
    <span class="c1">#     with Pool(processes=self.nprocs) as pool:</span>
    <span class="c1">#         print(&quot;pool startup&quot;, time.time()-t0)</span>
    <span class="c1">#         result = pool.map(</span>
    <span class="c1">#             partial(self._compute_utilities_serial,</span>
    <span class="c1">#                     self.compute_expected_utility,</span>
    <span class="c1">#                     collected_design_indices,</span>
    <span class="c1">#                     return_all), args)</span>
    <span class="c1">#     utility_vals = np.hstack([r[0] for r in result])</span>
    <span class="c1">#     results = []</span>
    <span class="c1">#     for r in result:</span>
    <span class="c1">#         results += r[1]</span>
    <span class="c1">#     return utility_vals, results</span>

    <span class="k">def</span> <span class="nf">_compute_utilities_serial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">compute_expected_utility</span><span class="p">,</span>
                                  <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span>
                                  <span class="n">indices</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">time</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">ncandidates</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">utility_vals</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)]</span>
        <span class="n">ii</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
            <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_expected_utility</span><span class="p">(</span>
                <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
                <span class="n">return_all</span><span class="o">=</span><span class="n">return_all</span><span class="p">)</span>
            <span class="n">utility_vals</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="s2">&quot;utility_val&quot;</span><span class="p">]</span>
            <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computing utilities in serial took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">results</span>

<div class="viewcode-block" id="AbstractBayesianOED.compute_utilities"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.compute_utilities">[docs]</a>    <span class="k">def</span> <span class="nf">compute_utilities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ncandidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                          <span class="n">new_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nprocs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_utilities_serial</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">compute_expected_utility</span><span class="p">,</span>
                <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span> <span class="n">new_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_utilities_parallel_shared</span><span class="p">(</span>
            <span class="n">kl_worker_fun</span><span class="p">,</span> <span class="n">init_kl_worker</span><span class="p">,</span> <span class="n">_get_kl_compute_utilities_initargs</span><span class="p">,</span>
            <span class="n">new_indices</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div>
        <span class="c1"># return self._compute_utilities_parallel(</span>
        <span class="c1">#     ncandidates, collected_design_indices, return_all)</span>

<div class="viewcode-block" id="AbstractBayesianOED.select_design"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.select_design">[docs]</a>    <span class="k">def</span> <span class="nf">select_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">nnew</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update an experimental design.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        utility_vals : np.ndarray (ncandidates)</span>
<span class="sd">            The utility vals at the candidate design samples. If the candidate</span>
<span class="sd">            sample is already in collected design then the utility value will</span>
<span class="sd">            be set to -np.inf</span>

<span class="sd">        selected_index : integer</span>
<span class="sd">            The index of the best design, i.e. the largest utility</span>

<span class="sd">        results : dict</span>
<span class="sd">            Dictionary of useful data used to compute expected utility</span>
<span class="sd">            At a minimum it has the keys [&quot;utilties&quot;, &quot;evidences&quot;, &quot;weights&quot;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations_with_replacement</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">),</span> <span class="n">nnew</span><span class="p">)))</span>
        <span class="n">utility_vals</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_utilities</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_indices</span><span class="p">,</span>
            <span class="n">return_all</span><span class="p">)</span>
        <span class="n">selected_index</span> <span class="o">=</span> <span class="n">new_indices</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">utility_vals</span><span class="p">,</span> <span class="mi">16</span><span class="p">))]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_index</span><span class="p">,</span> <span class="n">results</span></div>

    <span class="k">def</span> <span class="nf">_define_design_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                            <span class="n">new_design_indices</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_define_design_data</span><span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span>
                                   <span class="n">new_design_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">OEDSharedData</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;in_weights&quot;</span><span class="p">,</span> <span class="s2">&quot;out_weights&quot;</span><span class="p">,</span>
            <span class="s2">&quot;in_pred_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;out_pred_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;noise_samples&quot;</span><span class="p">,</span> <span class="s2">&quot;noise_std&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">set_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span><span class="p">)):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">ii</span><span class="p">])</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="s2">&quot;_shape&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_data</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr_names</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_funs</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_funs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">deviation_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span> <span class="o">=</span> <span class="n">pred_risk_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span> <span class="o">=</span> <span class="n">data_risk_fun</span>

    <span class="k">def</span> <span class="nf">set_in_pred_qois</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_pred_qois</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span> <span class="o">=</span> <span class="n">in_pred_qois</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois_shape</span> <span class="o">=</span> <span class="n">shape</span>


<span class="n">global_oed_shared_data</span> <span class="o">=</span> <span class="n">OEDSharedData</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_create_global_array_from_name</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">array</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">RawArray</span><span class="p">(</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
    <span class="c1"># X[:] = array.ravel() very slow</span>
    <span class="n">X_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">copyto</span><span class="p">(</span><span class="n">X_np</span><span class="p">,</span> <span class="n">array</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span>


<span class="kn">import</span> <span class="nn">time</span>
<span class="k">def</span> <span class="nf">_get_kl_compute_utilities_initargs</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="c1"># t0 = time.time()</span>
    <span class="n">initargs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">attr_names</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="n">_create_global_array_from_name</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="n">initargs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">shape</span><span class="p">]</span>
    <span class="n">initargs</span> <span class="o">=</span> <span class="p">(</span><span class="n">initargs</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">)</span>
    <span class="c1"># print(&quot;data time&quot;, time.time()-t0)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">initargs</span><span class="p">,</span> <span class="p">)</span>


<span class="k">def</span> <span class="nf">init_kl_worker</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">data_risk_fun</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">funs</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">]</span>
    <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">set_funs</span><span class="p">(</span><span class="o">*</span><span class="n">funs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_deviation_compute_utilities_initargs</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="c1"># t0 = time.time()</span>
    <span class="n">initargs</span> <span class="o">=</span> <span class="n">_get_kl_compute_utilities_initargs</span><span class="p">(</span><span class="n">obj</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="n">_create_global_array_from_name</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;in_pred_qois&quot;</span><span class="p">)</span>
    <span class="n">initargs</span> <span class="o">=</span> <span class="p">(</span><span class="n">initargs</span><span class="p">,</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">shape</span><span class="p">],</span>
                <span class="p">[</span><span class="n">obj</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">])</span>
    <span class="c1"># print(&quot;data time&quot;, time.time()-t0)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">initargs</span><span class="p">,</span> <span class="p">)</span>


<span class="k">def</span> <span class="nf">init_deviation_worker</span><span class="p">(</span><span class="n">initargs</span><span class="p">):</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">in_pred_qois</span><span class="p">,</span> <span class="n">funs</span> <span class="o">=</span> <span class="n">initargs</span>
    <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">set_in_pred_qois</span><span class="p">(</span><span class="o">*</span><span class="n">in_pred_qois</span><span class="p">)</span>
    <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">set_funs</span><span class="p">(</span><span class="o">*</span><span class="n">funs</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">from_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">global_oed_shared_data</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="n">global_oed_shared_data</span><span class="p">,</span> <span class="n">name</span><span class="o">+</span><span class="s2">&quot;_shape&quot;</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">kl_worker_fun</span><span class="p">(</span><span class="n">arg</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">in_weights</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;in_weights&quot;</span><span class="p">)</span>
    <span class="n">out_weights</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;out_weights&quot;</span><span class="p">)</span>
    <span class="n">in_pred_obs</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;in_pred_obs&quot;</span><span class="p">)</span>
    <span class="n">out_pred_obs</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;out_pred_obs&quot;</span><span class="p">)</span>
    <span class="n">noise_samples</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;noise_samples&quot;</span><span class="p">)</span>
    <span class="n">noise_std</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;noise_std&quot;</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">arg</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">ndata_per_candidate</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">arg</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">data_risk_fun</span> <span class="o">=</span> <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">data_risk_fun</span>
    <span class="n">nindices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nindices</span><span class="p">)]</span>
    <span class="n">utility_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">nindices</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">noise_std</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">*</span><span class="n">ndata_per_candidate</span>
         <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndesign_candidates</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">new_design_indices</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># assume the observations at the collected_design_indices</span>
            <span class="c1"># are already incorporated into the inner and outer loop weights</span>
            <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>

        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">idx</span><span class="o">*</span><span class="n">ndata_per_candidate</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">ndata_per_candidate</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">design_indices</span><span class="p">])</span>
        <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">_compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
            <span class="n">out_pred_obs</span><span class="p">,</span>  <span class="n">in_pred_obs</span><span class="p">,</span>  <span class="n">in_weights</span><span class="p">,</span>
            <span class="n">out_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
            <span class="n">data_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span>
        <span class="n">utility_vals</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="s2">&quot;utility_val&quot;</span><span class="p">]</span>
        <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Worker Took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">deviation_worker_fun</span><span class="p">(</span><span class="n">arg</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">in_weights</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;in_weights&quot;</span><span class="p">)</span>
    <span class="n">out_weights</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;out_weights&quot;</span><span class="p">)</span>
    <span class="n">in_pred_obs</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;in_pred_obs&quot;</span><span class="p">)</span>
    <span class="n">out_pred_obs</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;out_pred_obs&quot;</span><span class="p">)</span>
    <span class="n">noise_samples</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;noise_samples&quot;</span><span class="p">)</span>
    <span class="n">noise_std</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;noise_std&quot;</span><span class="p">)</span>
    <span class="n">in_pred_qois</span> <span class="o">=</span> <span class="n">from_buffer</span><span class="p">(</span><span class="s2">&quot;in_pred_qois&quot;</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">arg</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">ndata_per_candidate</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">arg</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">data_risk_fun</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span>
        <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span>
        <span class="n">global_oed_shared_data</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">)</span>

    <span class="n">nindices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nindices</span><span class="p">)]</span>
    <span class="n">utility_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">nindices</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">noise_std</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">*</span><span class="n">ndata_per_candidate</span>
         <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndesign_candidates</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">new_design_indices</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># assume the observations at the collected_design_indices</span>
            <span class="c1"># are already incorporated into the inner and outer loop weights</span>
            <span class="n">design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">idx</span><span class="o">*</span><span class="n">ndata_per_candidate</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">ndata_per_candidate</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">design_indices</span><span class="p">])</span>
        <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">_compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
            <span class="n">out_pred_obs</span><span class="p">,</span>  <span class="n">in_pred_obs</span><span class="p">,</span>  <span class="n">in_weights</span><span class="p">,</span> <span class="n">out_weights</span><span class="p">,</span>
            <span class="n">in_pred_qois</span><span class="p">,</span>  <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span>
            <span class="n">data_risk_fun</span><span class="p">,</span> <span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span>
        <span class="n">utility_vals</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="s2">&quot;utility_val&quot;</span><span class="p">]</span>
        <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Worker Took&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">results</span>


<div class="viewcode-block" id="BayesianBatchKLOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianBatchKLOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute open-loop OED my maximizing KL divergence between the prior and</span>
<span class="sd">    posterior.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BayesianBatchKLOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED.populate">[docs]</a>    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">)</span> <span class="o">=</span> \
            <span class="n">_precompute_expected_kl_utility_data</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">out_quad_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_quad_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="p">)</span></div>

<div class="viewcode-block" id="BayesianBatchKLOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return_all true used for debugging returns more than just utilities</span>
<span class="sd">        and also returns itermediate data useful for testing</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_define_design_data</span><span class="p">(</span>
            <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">in_weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">,</span>
            <span class="n">noise_std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">oed_prediction_average</span><span class="p">(</span><span class="n">qoi_vals</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">*</span><span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OEDQOIDeviation</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span>
                 <span class="n">noise_std</span><span class="p">,</span> <span class="n">in_pred_qois</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;variance&quot;</span><span class="p">:</span>
            <span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">_posterior_push_fwd_variance_deviation</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;std_dev&quot;</span><span class="p">:</span>
            <span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">_posterior_push_fwd_standard_deviation</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;entropic&#39;</span><span class="p">:</span>
            <span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">_posterior_push_fwd_entropic_deviation</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;cvar&#39;</span><span class="p">:</span>
            <span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">_posterior_push_fwd_cvar_deviation</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;deviation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not supported&quot;</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_compute_posterior_push_fwd_deviation</span><span class="p">(</span>
            <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
            <span class="n">in_pred_qois</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">)</span>



<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_posterior_push_fwd_variance_deviation</span><span class="p">(</span><span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">qoi_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">):</span>
        <span class="n">qoi_mean</span> <span class="o">+=</span> <span class="n">qoi_vals</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="n">deviations</span> <span class="o">+=</span> <span class="n">qoi_vals</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
    <span class="n">deviations</span> <span class="o">-=</span> <span class="n">qoi_mean</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">deviations</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_posterior_push_fwd_standard_deviation</span><span class="p">(</span><span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">_posterior_push_fwd_variance_deviation</span><span class="p">(</span>
        <span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">deviations</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_posterior_push_fwd_entropic_deviation</span><span class="p">(</span>
        <span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">qoi_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">):</span>
        <span class="n">qoi_mean</span> <span class="o">+=</span> <span class="n">qoi_vals</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="n">deviations</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">qoi_vals</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:])</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">deviations</span><span class="p">)</span><span class="o">-</span><span class="n">qoi_mean</span>
    <span class="k">return</span> <span class="n">deviations</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_posterior_push_fwd_cvar_deviation</span><span class="p">(</span>
        <span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="n">qoi_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># qoi_vars = np.zeros(qoi_vals.shape[1])</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">):</span>
        <span class="n">qoi_means</span> <span class="o">+=</span> <span class="n">qoi_vals</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="p">:]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>
        <span class="c1"># qoi_vars += qoi_vals[jj, :]**2*weights[jj]</span>
    <span class="c1"># qoi_vars -= qoi_means**2</span>
    <span class="n">nqoi</span> <span class="o">=</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">weights_expanded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="n">weights_expanded</span><span class="p">[</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="c1"># qoi_vals.copy() is necessary because numba is updating qoi_vals</span>
    <span class="n">risks</span> <span class="o">=</span> <span class="n">conditional_value_at_risk_vectorized</span><span class="p">(</span>
        <span class="n">qoi_vals</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">weights_expanded</span><span class="p">,</span>
        <span class="n">samples_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">risks</span><span class="o">-</span><span class="n">qoi_means</span>
    <span class="k">return</span> <span class="n">deviations</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_compute_posterior_push_fwd_deviation</span><span class="p">(</span>
        <span class="n">out_obs</span><span class="p">,</span> <span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">in_weights</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">qoi_vals</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">nout_samples</span> <span class="o">=</span> <span class="n">out_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nin_samples</span> <span class="o">=</span> <span class="n">in_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">const1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nout_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nout_samples</span><span class="p">,</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">const2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">const1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nout_samples</span><span class="p">):</span>
        <span class="n">evidences</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">):</span>
            <span class="n">loglike_val</span> <span class="o">=</span> <span class="n">const2</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">loglike_val</span> <span class="o">+=</span> <span class="n">const1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">out_obs</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span> <span class="o">-</span>
                    <span class="n">in_pred_obs</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike_val</span><span class="p">)</span><span class="o">*</span><span class="n">in_weights</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">evidences</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span>

        <span class="n">weights</span> <span class="o">/=</span> <span class="n">evidences</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">deviations</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">deviation_fun</span><span class="p">(</span>
            <span class="n">qoi_vals</span><span class="p">,</span> <span class="n">nin_samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">deviations</span><span class="p">,</span> <span class="n">evidences</span>


<span class="k">def</span> <span class="nf">oed_variance_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the variance deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nout_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For large arrays variance_3D_pyx is the same speed as einsum</span>
    <span class="c1"># implementation below</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyapprox.cython.utilities</span> <span class="kn">import</span> <span class="n">variance_3D_pyx</span>
        <span class="k">return</span> <span class="n">variance_3D_pyx</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
         <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span><span class="o">-</span><span class="n">means</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">variances</span>


<span class="k">def</span> <span class="nf">oed_entropic_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the entropic risk deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nout_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">risks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">weights</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">risks</span><span class="o">-</span><span class="n">means</span>


<span class="k">def</span> <span class="nf">oed_data_cvar</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the conditional value of risk of the deviations</span>
<span class="sd">    for each outer loop sample</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deviations : np.ndarray (nout_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, 1)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    quantile : float</span>
<span class="sd">        The quantile used to compute of the conditional value at risk</span>
<span class="sd">        of the deviations for each outerloop obsevation</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cvar_obs_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">cvar_obs_deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">deviations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">qq</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deviations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">cvar_obs_deviations</span><span class="p">[</span><span class="n">qq</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">conditional_value_at_risk</span><span class="p">(</span>
            <span class="n">deviations</span><span class="p">[:,</span> <span class="n">qq</span><span class="p">],</span> <span class="n">quantile</span><span class="p">,</span> <span class="n">weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cvar_obs_deviations</span>


<span class="k">def</span> <span class="nf">oed_standard_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the standard deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nout_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">oed_variance_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="c1"># rouding error can cause slightly negative values</span>
    <span class="n">variance</span><span class="p">[</span><span class="n">variance</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">oed_conditional_value_at_risk_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">samples_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the conditional value at risk deviation for each outer loop</span>
<span class="sd">    sample using the corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">        Weights associated with each inner loop sample</span>

<span class="sd">    quantile : float</span>
<span class="sd">        The quantile of the conditional value at risk used to</span>
<span class="sd">        compute the deviation</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nout_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">samples_sorted</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;samples cannot be sorted if nqoi &gt; 1&quot;</span><span class="p">)</span>
    <span class="n">cvars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">qq</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="n">qq</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:])</span>
            <span class="n">cvars</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">qq</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conditional_value_at_risk</span><span class="p">(</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="n">qq</span><span class="p">],</span> <span class="n">quantile</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">samples_sorted</span><span class="p">)</span> <span class="o">-</span>
                             <span class="n">mean</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cvars</span>


<div class="viewcode-block" id="BayesianBatchDeviationOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianBatchDeviationOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute open-loop OED by minimizing the deviation on the push forward</span>
<span class="sd">    of the posterior through a QoI model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">deviation_fun</span><span class="o">=</span><span class="n">oed_standard_deviation</span><span class="p">,</span>
                 <span class="n">pred_risk_fun</span><span class="o">=</span><span class="n">oed_prediction_average</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">oed_data_expectation</span><span class="p">,</span>
                 <span class="n">nprocs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ndata_per_candidate</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        qoi_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `qoi_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns evaluations of the forward model. Observations are</span>
<span class="sd">            assumed to be :math:`f(z)+\epsilon` where :math:`\epsilon` is</span>
<span class="sd">            additive noise nsamples : np.ndarray (nvars, nsamples)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        nin_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nout_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">         deviation_fun : callable</span>
<span class="sd">             Function with the signature</span>

<span class="sd">            `deviation_fun(in_pred_qois, weights) -&gt;</span>
<span class="sd">             np.ndarray(nout_samples, nqois)`</span>

<span class="sd">             where</span>

<span class="sd">             in_pred_qois : np.ndarray (</span>
<span class="sd">             nout_samples, nin_samples, nqois)</span>
<span class="sd">             weights : np.ndarray (nout_samples, nin_samples)</span>

<span class="sd">        nprocs : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>

<span class="sd">        pred_risk_fun : callable</span>
<span class="sd">            Function to compute risk over multiple qoi with the signature</span>

<span class="sd">             `pred_risk_fun(expected_deviations) -&gt; float`</span>

<span class="sd">            where expected_deviations : np.ndarray (nqois, 1)</span>

<span class="sd">        data_risk_fun : callable</span>
<span class="sd">            Function to compute risk of deviations over all outerloop samples</span>

<span class="sd">             `data_risk_fun(deviations) -&gt; np.ndarray (nqois, 1)`</span>

<span class="sd">            where deviations : np.ndarray (nout_samples, nqois)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                         <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span>
                         <span class="n">in_quad_opts</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">nprocs</span><span class="p">,</span>
                         <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="n">max_ncollected_obs</span><span class="p">,</span>
                         <span class="n">ndata_per_candidate</span><span class="o">=</span><span class="n">ndata_per_candidate</span><span class="p">,</span>
                         <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">data_risk_fun</span><span class="p">)</span>
        <span class="c1"># qoi fun deafult is None so that same api can be used for KL based OED</span>
        <span class="c1"># which does not require qoi_fun</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">qoi_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;qoi_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">deviation_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;deviation_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qoi_fun</span> <span class="o">=</span> <span class="n">qoi_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">deviation_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span> <span class="o">=</span> <span class="n">pred_risk_fun</span>

    <span class="k">def</span> <span class="nf">_populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the data needed to initialize the OED algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span><span class="p">)</span> <span class="o">=</span> <span class="n">_precompute_expected_deviation_data</span><span class="p">(</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">out_quad_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_quad_data</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qoi_fun</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;out_pred_obs.shape[1] != &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;self.ndesign_candidates*self.ndata_per_candidate. &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;!=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;check ndata_per_candidate.</span><span class="se">\n</span><span class="s2">Each design candidate&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot; must have the same number of data returned by obs_fun&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sort_qoi</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Sort in_pred_qois and use this order to sort</span>
        <span class="c1"># in_samples so that cvar deviation does not have to</span>
        <span class="c1"># constantly sort samples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sorting can only be used for a single QoI&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianBatchDeviationOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED.populate">[docs]</a>    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the data needed to initialize the OED algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_populate</span><span class="p">()</span></div>
        <span class="c1"># if self.in_pred_qois.shape[1] == 1:</span>
        <span class="c1">#     # speeds up calcualtion of avar</span>
        <span class="c1">#     self._sort_qoi()</span>

<div class="viewcode-block" id="BayesianBatchDeviationOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the negative expected deviation in predictions of QoI</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        return_all : boolean</span>
<span class="sd">             False - return the utilities</span>
<span class="sd">             True - used for debugging returns utilities</span>
<span class="sd">             and itermediate data useful for testing</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        utility : float</span>
<span class="sd">            The negative expected deviation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">active_indices</span><span class="p">,</span> <span class="n">noise_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_define_design_data</span><span class="p">(</span>
            <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div>

<div class="viewcode-block" id="BayesianBatchDeviationOED.compute_utilities"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED.compute_utilities">[docs]</a>    <span class="k">def</span> <span class="nf">compute_utilities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ncandidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                          <span class="n">new_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nprocs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_utilities_serial</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">compute_expected_utility</span><span class="p">,</span>
                <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span> <span class="n">new_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_utilities_parallel_shared</span><span class="p">(</span>
            <span class="n">deviation_worker_fun</span><span class="p">,</span> <span class="n">init_deviation_worker</span><span class="p">,</span>
            <span class="n">_get_deviation_compute_utilities_initargs</span><span class="p">,</span>
            <span class="n">new_indices</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BayesianSequentialOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute sequential optimal experimental designs that collect</span>
<span class="sd">    data and use this to inform the choice of subsequent design locations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">obs_process</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs_process must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_process</span> <span class="o">=</span> <span class="n">obs_process</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_weights_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_weights_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_loglike_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_compute_evidence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the evidence associated with using the true collected data.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a private function because calling by user will upset</span>
<span class="sd">        evidence calculation</span>

<span class="sd">        Always just use the first inner loop sample set to compute evidence.</span>
<span class="sd">        To avoid numerical precision problems recompute evidence with</span>
<span class="sd">        all data as opposed to updating evidence just using new data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># For now only allow one data per design location</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">ndesign_candidates</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="n">atol</span><span class="o">=</span><span class="mf">1e-14</span><span class="p">)</span>
        <span class="n">log_like_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loglike_fun</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">])</span>

        <span class="c1"># compute evidence moving from initial prior to current posterior</span>
        <span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_like_vals</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">in_weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="c1"># compute evidence moving from previous posterior to current posterior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence_from_prior</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="n">evidence_from_prior</span>

<div class="viewcode-block" id="BayesianSequentialOED.compute_importance_weights"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.compute_importance_weights">[docs]</a>    <span class="k">def</span> <span class="nf">compute_importance_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the importance weights used in the computation of the expected</span>
<span class="sd">        utility that acccount for the fact we want to use the current posterior</span>
<span class="sd">        as the prior in the utility formula.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loglike_fun</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">[</span>
                <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">]))</span><span class="o">/</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span><span class="p">)</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nin_samples</span><span class="p">,</span> <span class="n">nobs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_loglike_fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">[</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">]))</span><span class="o">/</span><span class="p">(</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span><span class="p">))</span><span class="o">.</span><span class="n">T</span></div>

<div class="viewcode-block" id="BayesianSequentialOED.update_observations"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.update_observations">[docs]</a>    <span class="k">def</span> <span class="nf">update_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store the newly collected obsevations which will dictate</span>
<span class="sd">        the next design point.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_obs : np.ndarray (1, nnew_obs)</span>
<span class="sd">            The new observations</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        self.inner_importance_weights contains likelihood vals/evidence</span>
<span class="sd">        at in_samples</span>
<span class="sd">        self.in_weights is the prior quadrature weights which</span>
<span class="sd">        for random samples drawn from</span>
<span class="sd">        prior is just 1/N and for Gauss Quadrature is the quadrature rule</span>
<span class="sd">        weights.</span>

<span class="sd">        Similarly for self.outer_importance_weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="n">new_obs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_evidence</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_importance_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_weights_up</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">out_weights</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_weights_up</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">in_weights</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span></div>

<div class="viewcode-block" id="BayesianSequentialOED.set_collected_design_indices"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.set_collected_design_indices">[docs]</a>    <span class="k">def</span> <span class="nf">set_collected_design_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the initial design indices and collect data at the</span>
<span class="sd">        corresponding design points.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        indices : np.ndarray (nindices, 1)</span>
<span class="sd">            The indices corresponding to an initial design</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_observations</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span></div></div>

    <span class="c1"># def update_design(self, return_all=False, rounding_decimals=16):</span>
    <span class="c1">#     return super().update_design(return_all, rounding_decimals)</span>


<div class="viewcode-block" id="BayesianSequentialKLOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialKLOED.html#pyapprox.expdesign.BayesianSequentialKLOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialKLOED</span><span class="p">(</span><span class="n">BayesianSequentialOED</span><span class="p">,</span> <span class="n">BayesianBatchKLOED</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute closed-loop OED my maximizing KL divergence between the prior and</span>
<span class="sd">    posterior.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span>
                 <span class="n">obs_process</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        obs_process : callable</span>
<span class="sd">            The true data generation model with the signature</span>

<span class="sd">            `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">            where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        nin_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nout_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">        nprocs : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># obs_process default is None so same API can be used as</span>
        <span class="c1"># open loop design</span>
        <span class="n">BayesianBatchKLOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
            <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span>
            <span class="n">nprocs</span><span class="o">=</span><span class="n">nprocs</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="n">max_ncollected_obs</span><span class="p">)</span>
        <span class="n">BayesianSequentialOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianSequentialKLOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialKLOED.html#pyapprox.expdesign.BayesianSequentialKLOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the expected utility. Using the current posterior as the new</span>
<span class="sd">        prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Passing None for collected_design_indices will ensure</span>
<span class="sd">        only obs at new_design indices is used to evaluate likelihood</span>
<span class="sd">        the data at collected indices is incoroporated into the</span>
<span class="sd">        inner and outer loop weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_weights_up</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_weights_up</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BayesianSequentialDeviationOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialDeviationOED.html#pyapprox.expdesign.BayesianSequentialDeviationOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialDeviationOED</span><span class="p">(</span>
        <span class="n">BayesianSequentialOED</span><span class="p">,</span> <span class="n">BayesianBatchDeviationOED</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute closed-loop OED by minimizing the deviation on the push forward</span>
<span class="sd">    of the posterior through a QoI model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span>  <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span>
                 <span class="n">qoi_fun</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obs_process</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">deviation_fun</span><span class="o">=</span><span class="n">oed_standard_deviation</span><span class="p">,</span>
                 <span class="n">pred_risk_fun</span><span class="o">=</span><span class="n">oed_prediction_average</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">oed_data_expectation</span><span class="p">,</span>
                 <span class="n">nprocs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        obs_process : callable</span>
<span class="sd">            The true data generation model with the signature</span>

<span class="sd">            `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">            where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">        qoi_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `qoi_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns evaluations of the forward model. Observations are</span>
<span class="sd">            assumed to be :math:`f(z)+\epsilon` where :math:`\epsilon` is</span>
<span class="sd">            additive noise nsamples : np.ndarray (nvars, nsamples)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        nin_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nout_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">         deviation_fun : callable</span>
<span class="sd">             Function with the signature</span>

<span class="sd">            `deviation_fun(in_pred_qois, weights) -&gt;</span>
<span class="sd">             np.ndarray(nout_samples, nqois)`</span>

<span class="sd">             where</span>

<span class="sd">             in_pred_qois : np.ndarray (</span>
<span class="sd">             nout_samples, nin_samples, nqois)</span>
<span class="sd">             weights : np.ndarray (nout_samples, nin_samples)</span>

<span class="sd">        nprocs : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>

<span class="sd">        pred_risk_fun : callable</span>
<span class="sd">            Function to compute risk over multiple qoi with the signature</span>

<span class="sd">             `pred_risk_fun(expected_deviations) -&gt; float`</span>

<span class="sd">            where expected_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># obs_process default is None so same API can be used as</span>
        <span class="c1"># open loop design</span>
        <span class="n">BayesianBatchDeviationOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
            <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="p">,</span>
            <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">,</span>
            <span class="n">nprocs</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="p">)</span>
        <span class="n">BayesianSequentialOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianSequentialDeviationOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialDeviationOED.html#pyapprox.expdesign.BayesianSequentialDeviationOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the expected utility. Using the current posterior as the new</span>
<span class="sd">        prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Passing None for collected_design_indices will ensure</span>
<span class="sd">        only obs at new_design indices is used to evaluate likelihood</span>
<span class="sd">        the data at collected indices is incoroporated into the</span>
<span class="sd">        inner and outer loop weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_weights_up</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_weights_up</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_pred_qois</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">get_oed_inner_quadrature_rule</span><span class="p">(</span><span class="n">nin_samples</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
                                  <span class="n">quad_method</span><span class="o">=</span><span class="s1">&#39;gauss&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    quad_method : string</span>
<span class="sd">        The method used to compute the inner loop integral needed to</span>
<span class="sd">        evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">        [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">        The first 3 construct tensor product quadrature rules from</span>
<span class="sd">        univariate rules that are respectively piecewise linear,</span>
<span class="sd">        piecewise quadratic or Gauss-quadrature.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nrandom_vars</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">nin_samples_1d</span> <span class="o">=</span> <span class="n">nin_samples</span>
    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;gauss&quot;</span><span class="p">:</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">prior_variable</span><span class="p">)</span>
        <span class="n">univariate_quad_rules</span> <span class="o">=</span> \
            <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
                <span class="n">prior_variable</span><span class="p">,</span> <span class="p">[</span><span class="n">nin_samples_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nrandom_vars</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> <span class="n">get_tensor_product_quadrature_rule</span><span class="p">(</span>
            <span class="p">[</span><span class="n">nin_samples_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nrandom_vars</span><span class="p">,</span> <span class="n">nrandom_vars</span><span class="p">,</span>
            <span class="n">univariate_quad_rules</span><span class="p">,</span> <span class="n">transform_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

    <span class="n">degree</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;linear&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;quadratic&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}[</span><span class="n">quad_method</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">is_bounded_continuous_variable</span><span class="p">():</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="mf">1e-6</span>
    <span class="n">new_ranges</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">get_statistics</span><span class="p">(</span>
        <span class="s2">&quot;interval&quot;</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> \
        <span class="n">get_tensor_product_piecewise_polynomial_quadrature_rule</span><span class="p">(</span>
            <span class="n">nin_samples_1d</span><span class="p">,</span> <span class="n">new_ranges</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
    <span class="n">w_quad</span> <span class="o">*=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_quad</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_posterior_weights_at_in_samples</span><span class="p">(</span><span class="n">oed</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">):</span>
    <span class="c1"># plot posterior for one realization of the data</span>
    <span class="c1"># nn : number of data used to form posterior</span>
    <span class="c1"># out_idx : the outer loop iteration used to generate the data</span>
    <span class="k">assert</span> <span class="n">nn</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">idx</span><span class="o">*</span><span class="n">oed</span><span class="o">.</span><span class="n">ndata_per_candidate</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">ndata_per_candidate</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">oed</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">[:</span><span class="n">nn</span><span class="p">]])</span>
    <span class="n">outer_log_likelihood_vals</span><span class="p">,</span> <span class="n">evidences</span> <span class="o">=</span> <span class="n">_compute_evidences</span><span class="p">(</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">[</span><span class="n">out_idx</span><span class="p">:</span><span class="n">out_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span> <span class="n">oed</span><span class="o">.</span><span class="n">in_weights</span><span class="p">,</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">out_weights</span><span class="p">[</span><span class="n">out_idx</span><span class="p">:</span><span class="n">out_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">active_indices</span><span class="p">,</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">[</span><span class="n">out_idx</span><span class="p">:</span><span class="n">out_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">oed</span><span class="o">.</span><span class="n">noise_std</span><span class="p">)</span>
    <span class="n">inner_log_likelihood_vals</span> <span class="o">=</span> <span class="n">_loglike_fun_from_noiseless_obs</span><span class="p">(</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">out_pred_obs</span><span class="p">[</span><span class="n">out_idx</span><span class="p">:</span><span class="n">out_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">oed</span><span class="o">.</span><span class="n">in_pred_obs</span><span class="p">,</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">noise_samples</span><span class="p">[</span><span class="n">out_idx</span><span class="p">:</span><span class="n">out_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">)</span><span class="o">*</span><span class="n">oed</span><span class="o">.</span><span class="n">in_weights</span><span class="o">/</span><span class="n">evidences</span>
    <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span> <span class="nf">get_posterior_2d_interpolant_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">quad_method</span><span class="p">):</span>
    <span class="c1"># plot posterior for one realization of the data</span>
    <span class="c1"># nn : number of data used to form posterior</span>
    <span class="c1"># out_idx : the outer loop iteration used to generate the data</span>
    <span class="k">assert</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">get_posterior_weights_at_in_samples</span><span class="p">(</span><span class="n">oed</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="n">weights</span><span class="o">/</span><span class="n">oed</span><span class="o">.</span><span class="n">in_weights</span>
    <span class="c1"># multiply vals by prior.</span>
    <span class="n">vals</span> <span class="o">*=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">oed</span><span class="o">.</span><span class="n">in_samples</span><span class="p">)</span>

    <span class="n">nin_samples</span> <span class="o">=</span> <span class="n">vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;gauss&quot;</span><span class="p">:</span>
        <span class="c1"># interpolate posterior vals onto equidistant mesh for plotting</span>
        <span class="n">nvars</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
        <span class="n">abscissa_1d</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">abscissa_1d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                    <span class="n">oed</span><span class="o">.</span><span class="n">in_samples</span><span class="p">[</span><span class="n">dd</span><span class="p">,</span> <span class="p">:</span><span class="n">nin_samples</span><span class="p">]))</span>
        <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tensor_product_barycentric_interpolation</span><span class="p">,</span> <span class="n">abscissa_1d</span><span class="p">,</span>
                      <span class="n">vals</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fun</span>

    <span class="n">quad_methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;quadratic&#39;</span><span class="p">,</span> <span class="s1">&#39;gauss&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">!=</span> <span class="s2">&quot;linear&quot;</span> <span class="ow">and</span> <span class="n">quad_method</span> <span class="o">!=</span> <span class="s2">&quot;quadratic&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;quad_method must be in </span><span class="si">{</span><span class="n">quad_methods</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># if using piecewise polynomial quadrature interpolate between using</span>
    <span class="c1"># piecewise linear method</span>
    <span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">griddata</span>
    <span class="n">x_quad</span> <span class="o">=</span> <span class="n">oed</span><span class="o">.</span><span class="n">in_samples</span>
    <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">griddata</span><span class="p">(</span><span class="n">x_quad</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">vals</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">plot_2d_posterior_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">oed_results</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="kn">from</span> <span class="nn">pyapprox.util.visualization</span> <span class="kn">import</span> <span class="n">plt</span><span class="p">,</span> <span class="n">get_meshgrid_function_data</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">is_bounded_continuous_variable</span><span class="p">():</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.99</span>
    <span class="n">plot_limits</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">get_statistics</span><span class="p">(</span>
        <span class="s2">&quot;interval&quot;</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">get_posterior_2d_interpolant_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">get_meshgrid_function_data</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">plot_limits</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">Z</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">21</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">tensor_product_barycentric_interpolation</span><span class="p">(</span><span class="n">abscissa_1d</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">abscissa_1d</span><span class="p">)</span>
    <span class="n">barycentric_weights_1d</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">interval_length</span> <span class="o">=</span> <span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">barycentric_weights_1d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">compute_barycentric_weights_1d</span><span class="p">(</span>
                <span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">],</span> <span class="n">interval_length</span><span class="o">=</span><span class="n">interval_length</span><span class="p">))</span>
    <span class="n">poly_vals</span> <span class="o">=</span> <span class="n">multivariate_barycentric_lagrange_interpolation</span><span class="p">(</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">abscissa_1d</span><span class="p">,</span> <span class="n">barycentric_weights_1d</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nvars</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">poly_vals</span>


<span class="k">def</span> <span class="nf">generate_inner_prior_samples_fixed</span><span class="p">(</span><span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper that can be used with functools.partial to create a</span>
<span class="sd">    function with the signature generate_inner_samples(nsamples)</span>
<span class="sd">    that always returns the same quadrature rule. This function</span>
<span class="sd">    will be called many times and creating a quadrature each time</span>
<span class="sd">    can be computationally expensive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">nsamples</span> <span class="o">==</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span>


<span class="k">def</span> <span class="nf">get_deviation_fun</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the deviation function used to compute the deviation of the</span>
<span class="sd">    posterior push-forward for a realization of the observational data</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : string</span>
<span class="sd">        Name of the deviation function.</span>
<span class="sd">        Must be one of [&quot;std&quot;, &quot;cvar&quot;, &quot;entropic&quot;]</span>

<span class="sd">    opts : dict</span>
<span class="sd">         Any options needed by the desired deviation function. cvar requires</span>
<span class="sd">         {&quot;quantile&quot;, p} where 0&lt;=p&lt;1. No options are needed for the other</span>
<span class="sd">         deviation functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `deviation_fun(in_pred_qois, weights) -&gt;</span>
<span class="sd">         np.ndarray(nout_samples, nqois)`</span>

<span class="sd">         where</span>

<span class="sd">         in_pred_qois : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">deviation_funs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">oed_standard_deviation</span><span class="p">,</span>
        <span class="s2">&quot;cvar&quot;</span><span class="p">:</span> <span class="n">oed_conditional_value_at_risk_deviation</span><span class="p">,</span>
        <span class="s2">&quot;entropic&quot;</span><span class="p">:</span> <span class="n">oed_entropic_deviation</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">deviation_funs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">deviation_funs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">deviation_funs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="o">**</span><span class="n">opts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">get_data_risk_fun</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the risk function used to compute the risk of the deviation for all</span>
<span class="sd">    outerloop realizations of the observations</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : string</span>
<span class="sd">        Name of the deviation function.</span>
<span class="sd">        Must be one of [&quot;std&quot;, &quot;cvar&quot;, &quot;entropic&quot;]</span>

<span class="sd">    opts : dict</span>
<span class="sd">         Any options needed by the desired deviation function. cvar requires</span>
<span class="sd">         {&quot;quantile&quot;, p} where 0&lt;=p&lt;1. No options are needed for the other</span>
<span class="sd">         deviation functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `deviation_fun(in_pred_qois, weights) -&gt;</span>
<span class="sd">         np.ndarray(nout_samples, nqois)`</span>

<span class="sd">         where</span>

<span class="sd">         in_pred_qois : np.ndarray (nout_samples, nin_samples, nqois)</span>
<span class="sd">         weights : np.ndarray (nout_samples, nin_samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">risk_funs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">oed_data_expectation</span><span class="p">,</span>
        <span class="s2">&quot;cvar&quot;</span><span class="p">:</span> <span class="n">oed_data_cvar</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">risk_funs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">risk_funs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">risk_funs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="o">**</span><span class="n">opts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">get_pred_risk_fun</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">risk_funs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">oed_prediction_average</span><span class="p">,</span>
        <span class="s2">&quot;cvar&quot;</span><span class="p">:</span> <span class="n">conditional_value_at_risk</span><span class="p">,</span>
        <span class="s2">&quot;entropic&quot;</span><span class="p">:</span> <span class="n">entropic_risk_measure</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">risk_funs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">risk_funs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">risk_funs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">extract_independent_noise_cov</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    When computing laplace approximations we need a covariance matrix that</span>
<span class="sd">    treats each observation independent even when indices are the same,</span>
<span class="sd">    that is we have two or more observations for the same observation matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nindices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">nindices</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cov</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
    <span class="n">new_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="p">)[</span><span class="n">indices</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_cov</span>


<span class="k">def</span> <span class="nf">sequential_oed_synthetic_observation_process</span><span class="p">(</span>
        <span class="n">obs_fun</span><span class="p">,</span> <span class="n">true_sample</span><span class="p">,</span> <span class="n">noise_fun</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use obs_model to generate all observations then downselect. For true</span>
<span class="sd">    observation processes this defeats the purpose of experimental design</span>
<span class="sd">    In these cases a custom obs_model must takes design indices as an</span>
<span class="sd">    argument.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun() -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns the synethic truth for all design candidates.</span>

<span class="sd">    true_sample : np.ndaray (nvars, 1)</span>
<span class="sd">        The true sample used to generate the synthetic truth</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">        The indices into the qoi vector associated with new design locations</span>
<span class="sd">        under consideration</span>

<span class="sd">    noise_fun : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        `noise_fun(values, new_design_indices) -&gt; np.ndarray (values.shape[0], new_design_indices.shape)`</span>

<span class="sd">         that returns noise for the new observations. Here</span>
<span class="sd">         values : np.ndarray (1, nobs) and</span>
<span class="sd">         new_design_indices : np.ndarary (nindices) where nindices&lt;=nobs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">true_sample</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">noise_fun</span><span class="p">(</span><span class="n">all_obs</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">all_obs</span><span class="p">[:,</span> <span class="n">new_design_indices</span><span class="p">]</span><span class="o">+</span><span class="n">noise</span>
    <span class="k">return</span> <span class="n">obs</span>


<span class="k">def</span> <span class="nf">gaussian_noise_fun</span><span class="p">(</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate gaussian possibly heteroscedastic random noise</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    noise_std : float or np.ndarray (nobs)</span>
<span class="sd">        The standard deviation of the noise at each observation</span>

<span class="sd">    values : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The observations at variour realizations of the random parameters</span>

<span class="sd">    active_indices :np.ndarray (nindices)</span>
<span class="sd">        The indices of the active observations with nindices &lt;= nobs</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    noise : np.ndarray (nsamples, nindices)</span>
<span class="sd">        The noise at the active observations nindices=nobs if</span>
<span class="sd">        active_indices is None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">noise_std</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">],</span> <span class="n">shape</span><span class="p">)</span>


<div class="viewcode-block" id="get_bayesian_oed_optimizer"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.get_bayesian_oed_optimizer.html#pyapprox.expdesign.get_bayesian_oed_optimizer">[docs]</a><span class="k">def</span> <span class="nf">get_bayesian_oed_optimizer</span><span class="p">(</span>
        <span class="n">short_oed_type</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">prior_variable</span><span class="p">,</span> <span class="n">out_quad_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">pre_collected_design_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a Bayesian OED optimizer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    short_oed_type : string</span>
<span class="sd">        The type of experimental design strategy</span>

<span class="sd">    design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns noiseless evaluations of the forward model.</span>

<span class="sd">    noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">        The standard deviation of the mean zero Gaussian noise added to each</span>
<span class="sd">        observation</span>

<span class="sd">    nin_samples : integer</span>
<span class="sd">        The number of quadrature samples used for the inner integral that</span>
<span class="sd">        computes the evidence for each realiaztion of the predicted</span>
<span class="sd">        observations</span>

<span class="sd">    nout_samples : integer</span>
<span class="sd">        The number of Monte Carlo samples used to compute the outer integral</span>
<span class="sd">        over all possible observations</span>

<span class="sd">    quad_method : string</span>
<span class="sd">        The method used to compute the inner loop integral needed to</span>
<span class="sd">        evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">        [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">        The first 3 construct tensor product quadrature rules from univariate</span>
<span class="sd">        rules that are respectively piecewise linear, piecewise quadratic</span>
<span class="sd">        or Gauss-quadrature.</span>

<span class="sd">    pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    kwargs : kwargs</span>
<span class="sd">        Key word arguments specific to the OED type</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    oed : pyapprox.expdesign.AbstractBayesianOED</span>
<span class="sd">        Bayesian OED optimizer object</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="s2">&quot;obs_process&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">oed_type</span> <span class="o">=</span> <span class="s2">&quot;closed_loop_&quot;</span> <span class="o">+</span> <span class="n">short_oed_type</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">oed_type</span> <span class="o">=</span> <span class="s2">&quot;open_loop_&quot;</span> <span class="o">+</span> <span class="n">short_oed_type</span>

    <span class="n">oed_types</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;open_loop_kl_params&quot;</span><span class="p">:</span> <span class="n">BayesianBatchKLOED</span><span class="p">,</span>
                 <span class="s2">&quot;closed_loop_kl_params&quot;</span><span class="p">:</span> <span class="n">BayesianSequentialKLOED</span><span class="p">,</span>
                 <span class="s2">&quot;open_loop_dev_pred&quot;</span><span class="p">:</span> <span class="n">BayesianBatchDeviationOED</span><span class="p">,</span>
                 <span class="s2">&quot;closed_loop_dev_pred&quot;</span><span class="p">:</span> <span class="n">BayesianSequentialDeviationOED</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">oed_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">oed_types</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;oed_type </span><span class="si">{</span><span class="n">short_oed_type</span><span class="si">}</span><span class="s2"> not supported.&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Select from [kl_params, dev_pred]&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">and</span>
            <span class="n">noise_std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">ndesign_candidates</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;noise_std must be specified for each design candiate&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">out_quad_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out_quad_opts</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;quasimontecarlo&quot;</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;nsamples&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)}}</span>
    <span class="k">if</span> <span class="n">in_quad_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">in_quad_opts</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;quasimontecarlo&quot;</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;nsamples&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)}}</span>

    <span class="n">oed</span> <span class="o">=</span> <span class="n">oed_types</span><span class="p">[</span><span class="n">oed_type</span><span class="p">](</span>
        <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
        <span class="n">out_quad_opts</span><span class="p">,</span> <span class="n">in_quad_opts</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">nprocs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">oed</span><span class="o">.</span><span class="n">populate</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">pre_collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">set_collected_design_indices</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pre_collected_design_indices</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">oed</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>