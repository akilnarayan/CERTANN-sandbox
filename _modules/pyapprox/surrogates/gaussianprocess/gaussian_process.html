<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyapprox.surrogates.gaussianprocess.gaussian_process &mdash; PyApprox 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> PyApprox
            <img src="../../../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../auto_examples/index.html">Software Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>pyapprox.surrogates.gaussianprocess.gaussian_process</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyapprox.surrogates.gaussianprocess.gaussian_process</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span><span class="p">,</span> <span class="n">Bounds</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">solve_triangular</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">kv</span><span class="p">,</span> <span class="n">gamma</span>

<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Matern</span><span class="p">,</span> <span class="n">RBF</span><span class="p">,</span> <span class="n">Product</span><span class="p">,</span> <span class="n">Sum</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">,</span> <span class="n">WhiteKernel</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyapprox.util.utilities</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">cartesian_product</span><span class="p">,</span> <span class="n">outer_product</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.expdesign.low_discrepancy_sequences</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">transformed_halton_sequence</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.linalg</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">pivoted_cholesky_decomposition</span><span class="p">,</span>
    <span class="n">continue_pivoted_cholesky_decomposition</span><span class="p">,</span> <span class="n">cholesky_solve_linear_system</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.joint</span> <span class="kn">import</span> <span class="n">IndependentMarginalsVariable</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AffineTransform</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.indexing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">argsort_indices_leixographically</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.polychaos.gpc</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_univariate_quadrature_rules_from_variable</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.sampling</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">generate_independent_random_samples</span>
<span class="p">)</span>


<div class="viewcode-block" id="GaussianProcess"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess">[docs]</a><span class="k">class</span> <span class="nc">GaussianProcess</span><span class="p">(</span><span class="n">GaussianProcessRegressor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Gaussian process.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="GaussianProcess.set_variable_transformation"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.set_variable_transformation">[docs]</a>    <span class="k">def</span> <span class="nf">set_variable_transformation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="n">var_trans</span></div>

<div class="viewcode-block" id="GaussianProcess.map_to_canonical"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.map_to_canonical">[docs]</a>    <span class="k">def</span> <span class="nf">map_to_canonical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;var_trans&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span></div>

<div class="viewcode-block" id="GaussianProcess.map_from_canonical"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.map_from_canonical">[docs]</a>    <span class="k">def</span> <span class="nf">map_from_canonical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonical_samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;var_trans&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical</span><span class="p">(</span><span class="n">canonical_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">canonical_samples</span></div>

<div class="viewcode-block" id="GaussianProcess.fit"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_values</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A light weight wrapper of sklearn GaussianProcessRegressor.fit</span>
<span class="sd">        function. See sklearn documentation for more info. This wrapper</span>
<span class="sd">        is needed because sklearn stores a unique sample in each row</span>
<span class="sd">        of a samples matrix whereas pyapprox uses the transpose.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">            Samples at which to evaluate the GP. Sklearn requires the</span>
<span class="sd">            transpose of this matrix, i.e a matrix with size (nsamples,nvars)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">canonical_train_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">canonical_train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">train_values</span><span class="p">)</span></div>

<div class="viewcode-block" id="GaussianProcess.__call__"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.__call__">[docs]</a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A light weight wrapper of sklearn GaussianProcessRegressor.predict</span>
<span class="sd">        function. See sklearn documentation for more info. This wrapper</span>
<span class="sd">        is needed because sklearn stores a unique sample in each row</span>
<span class="sd">        of a samples matrix whereas pyapprox uses the transpose.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">            Samples at which to evaluate the GP. Sklearn requires the</span>
<span class="sd">            transpose of this matrix, i.e a matrix with size (nsamples,nvars)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">jac</span> <span class="ow">and</span> <span class="p">(</span><span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;if jac is True then return_std and return_cov must be False&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="n">canonical_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">return_std</span><span class="p">,</span> <span class="n">return_cov</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">jac</span><span class="p">:</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">Matern</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">RBF</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;jac only available when using the Matern kernel&quot;</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nu</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">nu</span>
            <span class="k">assert</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">gradK</span> <span class="o">=</span> <span class="n">matern_gradient_wrt_samples</span><span class="p">(</span>
                <span class="n">nu</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">gradK</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">ConstantKernel</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">grad</span> <span class="o">*=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">constant_value</span>
            <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">grad</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="c1"># when returning prior stdev covariance then must reshape vals</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="GaussianProcess.predict_random_realization"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.predict_random_realization">[docs]</a>    <span class="k">def</span> <span class="nf">predict_random_realization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">rand_noise</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">truncated_svd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict values of a random realization of the Gaussian process</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A different realization will be returned for two different samples</span>
<span class="sd">        Even if the same random noise i used. To see this for a 1D GP use:</span>

<span class="sd">        xx = np.linspace(0, 1, 101)</span>
<span class="sd">        rand_noise = np.random.normal(0, 1, (xx.shape[0], 1))</span>
<span class="sd">        yy = gp.predict_random_realization(xx[None, :], rand_noise)</span>
<span class="sd">        plt.plot(xx, yy)</span>
<span class="sd">        xx = np.linspace(0, 1, 97)</span>
<span class="sd">        rand_noise = np.random.normal(0, 1, (xx.shape[0], 1))</span>
<span class="sd">        yy = gp.predict_random_realization(xx[None, :], rand_noise)</span>
<span class="sd">        plt.plot(xx, yy)</span>
<span class="sd">        plt.show()</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        truncated_svd : dictionary</span>
<span class="sd">           Dictionary containing the following attribues needed to define</span>
<span class="sd">           a truncated singular values decomposition. If None then</span>
<span class="sd">           factor the entire matrix</span>

<span class="sd">        nsingular_vals : integer</span>
<span class="sd">            Only compute the first n singular values when</span>
<span class="sd">            factorizing the covariance matrix. n=truncated_svd</span>

<span class="sd">        tol : float</span>
<span class="sd">            The contribution to total variance from the truncated singular</span>
<span class="sd">            values must not exceed this value.</span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function replaces</span>
<span class="sd">        gp.sample_y(samples.T, n_samples=rand_noise, random_state=0)</span>
<span class="sd">        which cannot be passed rand_noise vectors and cannot use truncated SVD</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># mapping of samples is performed in __call__</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">keep_normalized</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_std</span>
            <span class="n">cov</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">**</span><span class="mi">2</span>
        <span class="c1"># Use SVD because it is more robust than Cholesky</span>
        <span class="c1"># L = np.linalg.cholesky(cov)</span>
        <span class="k">if</span> <span class="n">truncated_svd</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
            <span class="n">svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span>
                <span class="n">n_components</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">truncated_svd</span><span class="p">[</span><span class="s1">&#39;nsingular_vals&#39;</span><span class="p">]),</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
            <span class="n">svd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
            <span class="n">U</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">T</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">singular_values_</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained variance&#39;</span><span class="p">,</span> <span class="n">svd</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="k">assert</span> <span class="n">svd</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">truncated_svd</span><span class="p">[</span><span class="s1">&#39;tol&#39;</span><span class="p">]</span>
            <span class="c1"># print(S.shape, cov.shape)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">U</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
        <span class="c1"># create nsamples x nvars then transpose so same samples</span>
        <span class="c1"># are produced if this function is called repeatedly with nsamples=1</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">rand_noise</span><span class="p">):</span>
            <span class="n">rand_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">rand_noise</span><span class="p">,</span> <span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">rand_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">truncated_svd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rand_noise</span> <span class="o">=</span> <span class="n">rand_noise</span><span class="p">[:</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">L</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rand_noise</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vals</span></div>

<div class="viewcode-block" id="GaussianProcess.num_training_samples"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.num_training_samples">[docs]</a>    <span class="k">def</span> <span class="nf">num_training_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="GaussianProcess.condition_number"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.condition_number">[docs]</a>    <span class="k">def</span> <span class="nf">condition_number</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">T</span><span class="p">))</span></div>

<div class="viewcode-block" id="GaussianProcess.get_training_samples"><a class="viewcode-back" href="../../../../api/pyapprox.surrogates.GaussianProcess.html#pyapprox.surrogates.GaussianProcess.get_training_samples">[docs]</a>    <span class="k">def</span> <span class="nf">get_training_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;var_trans&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span></div></div>


<span class="k">class</span> <span class="nc">RandomGaussianProcessRealizations</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Light weight wrapper that allows random realizations of a Gaussian process</span>
<span class="sd">    to be evaluated at an arbitrary set of samples.</span>
<span class="sd">    GaussianProcess.predict_random_realization can only evaluate the GP</span>
<span class="sd">    at a finite set of samples. This wrapper can only compute the mean</span>
<span class="sd">    interpolant as we assume that the number of training samples</span>
<span class="sd">    was sufficient to produce an approximation with accuracy (samll pointwise</span>
<span class="sd">    variance acceptable to the user. Unlike GaussianProcess predictions</span>
<span class="sd">    can return a np.ndarray (nsamples, nrandom_realizations)</span>
<span class="sd">    instead of size (nsamples, 1) where nrandom_realizations is the number</span>
<span class="sd">    of random realizations interpolated</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nvalidation_samples : integer</span>
<span class="sd">        The number of samples of the random realization used to compute the</span>
<span class="sd">        accuracy of the interpolant.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">use_cholesky</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">gp</span>
        <span class="n">kernel_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">RBF</span><span class="p">,</span> <span class="n">Matern</span><span class="p">]</span>
        <span class="c1"># ignore white noise kernel as we want to interpolate the data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">)</span>
        <span class="n">constant_kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span>
            <span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">ConstantKernel</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">constant_kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">constant_kernel</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_cholesky</span> <span class="o">=</span> <span class="n">use_cholesky</span>
        <span class="c1"># it is useful to specify alpha different to the one use to invert</span>
        <span class="c1"># Kernel marix at training data of gp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">candidate_samples</span><span class="p">,</span> <span class="n">rand_noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">ninterpolation_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">nvalidation_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct interpolants of random realizations evaluated at the</span>
<span class="sd">        training data and at a new set of additional points</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">ninterpolation_samples</span> <span class="o">&lt;=</span>
                <span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">(</span>
                    <span class="n">ninterpolation_samples</span><span class="p">,</span>
                    <span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">canonical_candidate_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span>
            <span class="n">candidate_samples</span><span class="p">)</span>
        <span class="n">canonical_candidate_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">canonical_candidate_samples</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cholesky</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">Kmatrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">canonical_candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">Kmatrix</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices_from</span><span class="p">(</span><span class="n">Kmatrix</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
            <span class="n">init_pivots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># init_pivots = None</span>
            <span class="n">L</span><span class="p">,</span> <span class="n">pivots</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">chol_flag</span> <span class="o">=</span> <span class="n">pivoted_cholesky_decomposition</span><span class="p">(</span>
                <span class="n">Kmatrix</span><span class="p">,</span> <span class="n">ninterpolation_samples</span><span class="p">,</span>
                <span class="n">init_pivots</span><span class="o">=</span><span class="n">init_pivots</span><span class="p">,</span> <span class="n">pivot_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">error_on_small_tol</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Realization log10 cond num&quot;</span><span class="p">,</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">))))</span>
            <span class="k">if</span> <span class="n">chol_flag</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">pivots</span> <span class="o">=</span> <span class="n">pivots</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Number of samples used for interpolation &quot;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pivots</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;was less than requested </span><span class="si">{</span><span class="n">ninterpolation_samples</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="c1"># then not all points requested were selected</span>
                <span class="c1"># because L became illconditioned. This usually means that no</span>
                <span class="c1"># more candidate samples are useful and that error in</span>
                <span class="c1"># interpolant will be small. Note  chol_flag &gt; 0 even when</span>
                <span class="c1"># pivots.shape[0] == ninterpolation_samples. This means last</span>
                <span class="c1"># step of cholesky factorization triggered the incomplete flag</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span><span class="p">[</span><span class="n">pivots</span><span class="p">,</span> <span class="p">:</span><span class="n">pivots</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="c1"># print(&#39;Condition Number&#39;, np.linalg.cond(L.dot(L.T)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span> <span class="o">=</span> \
                <span class="n">canonical_candidate_samples</span><span class="p">[:,</span> <span class="n">pivots</span><span class="p">]</span>

            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">canonical_candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">pivots</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">canonical_validation_samples</span> <span class="o">=</span> <span class="n">canonical_candidate_samples</span><span class="p">[</span>
                <span class="p">:,</span> <span class="n">mask</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">canonical_validation_samples</span> <span class="o">=</span> \
                <span class="n">canonical_validation_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">nvalidation_samples</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span><span class="n">ninterpolation_samples</span> <span class="o">+</span> <span class="n">nvalidation_samples</span> <span class="o">&lt;=</span>
                    <span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span> <span class="o">=</span> \
                <span class="n">canonical_candidate_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ninterpolation_samples</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">canonical_validation_samples</span> <span class="o">=</span> \
                <span class="n">canonical_candidate_samples</span><span class="p">[:,</span> <span class="n">ninterpolation_samples</span><span class="p">:</span><span class="n">ninterpolation_samples</span><span class="o">+</span><span class="n">nvalidation_samples</span><span class="p">]</span>
            <span class="n">Kmatrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">Kmatrix</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices_from</span><span class="p">(</span><span class="n">Kmatrix</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Kmatrix</span><span class="p">)</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">canonical_validation_samples</span><span class="p">))</span>
        <span class="c1"># make last sample mean of gaussian process</span>
        <span class="n">rand_noise</span> <span class="o">=</span> <span class="n">rand_noise</span><span class="p">[:</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
        <span class="n">rand_noise</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">rand_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict_random_realization</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">map_from_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span>
            <span class="n">rand_noise</span><span class="o">=</span><span class="n">rand_noise</span><span class="p">,</span> <span class="n">truncated_svd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">keep_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_vals</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_vals</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>
        <span class="c1"># Entries of the following should be size of alpha when</span>
        <span class="c1"># rand_noise[:, -1] = np.zeros((rand_noise.shape[0]))</span>
        <span class="c1"># print(self.train_vals[:, -1]-self.gp.y_train_[:, 0])</span>

        <span class="c1"># L_inv = np.linalg.inv(L.T)</span>
        <span class="c1"># L_inv = solve_triangular(L.T, np.eye(L.shape[0]))</span>
        <span class="c1"># self.K_inv_ = L_inv.dot(L_inv.T)</span>
        <span class="c1"># self.alpha_ = self.K_inv_.dot(self.train_vals)</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_vals</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">approx_validation_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">canonical_validation_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
            <span class="n">approx_validation_vals</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="c1"># Error in interpolation of gp mean when</span>
        <span class="c1"># rand_noise[:, -1] = np.zeros((rand_noise.shape[0]))</span>
        <span class="c1"># print(np.linalg.norm((approx_validation_vals[:, -1]*self.gp._y_train_std+self.gp._y_train_mean)-self.gp(self.canonical_validation_samples)[:, 0])/np.linalg.norm(self.gp(self.canonical_validation_samples)[:, 0]))</span>
        <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Worst case relative interpolation error&#39;</span><span class="p">,</span> <span class="n">error</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Median relative interpolation error&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="n">canonical_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">K_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span>
            <span class="n">canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">selected_canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">K_pred</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">*</span><span class="n">vals</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">_y_train_mean</span>
        <span class="k">return</span> <span class="n">vals</span>


<span class="k">class</span> <span class="nc">AdaptiveGaussianProcess</span><span class="p">(</span><span class="n">GaussianProcess</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">sampler</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>

    <span class="k">def</span> <span class="nf">refine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
        <span class="c1"># new samples must be in user domain</span>
        <span class="n">new_samples</span><span class="p">,</span> <span class="n">chol_flag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">new_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>  <span class="c1"># must be scalar values QoI</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;X_train_&#39;</span><span class="p">):</span>
            <span class="c1"># get_training_samples returns samples in user space</span>
            <span class="n">train_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_training_samples</span><span class="p">()</span>
            <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">new_samples</span><span class="p">])</span>
            <span class="n">train_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">new_values</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_values</span> <span class="o">=</span> <span class="n">new_samples</span><span class="p">,</span> <span class="n">new_values</span>
            <span class="c1"># if self.var_trans is not None then when fit is called</span>
            <span class="c1"># train_samples are mapped to cannonical domain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">chol_flag</span>


<span class="k">def</span> <span class="nf">is_covariance_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="ow">in</span> <span class="n">kernel_types</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">extract_covariance_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">):</span>
    <span class="n">cov_kernel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">is_covariance_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">==</span> <span class="n">Product</span> <span class="ow">or</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">==</span> <span class="n">Sum</span><span class="p">:</span>
        <span class="n">cov_kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">k1</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cov_kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cov_kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">k2</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cov_kernel</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_tau</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_samples</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">delta</span><span class="o">/</span><span class="p">(</span><span class="n">delta</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="o">-</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">delta</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_u</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">delta</span><span class="o">/</span><span class="p">(</span><span class="n">delta</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">gaussian_P</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">nvars</span><span class="p">,</span> <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">si</span><span class="p">,</span> <span class="n">mi</span><span class="p">,</span> <span class="n">di</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">delta</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">denom1</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="n">di</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">term2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">di</span><span class="o">/</span><span class="p">(</span><span class="n">di</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">):</span>
            <span class="n">xm</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">mm</span><span class="p">]</span>
            <span class="n">xn</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span>
            <span class="n">P</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">di</span><span class="p">)</span><span class="o">*</span><span class="p">(</span>
                <span class="mi">2</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xm</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">xn</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">di</span><span class="o">*</span><span class="n">mi</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span>
                <span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xm</span><span class="o">+</span><span class="n">xn</span><span class="p">)</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">di</span><span class="o">*</span><span class="n">mi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">denom1</span><span class="p">))</span><span class="o">*</span><span class="n">term2</span>
            <span class="n">P</span><span class="p">[</span><span class="n">mm</span><span class="p">:,</span> <span class="n">mm</span><span class="p">]</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">P</span>


<span class="k">def</span> <span class="nf">gaussian_nu</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">delta</span><span class="o">/</span><span class="p">(</span><span class="n">delta</span><span class="o">+</span><span class="mf">8.</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">gaussian_Pi</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">nvars</span><span class="p">,</span> <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">Pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">si</span><span class="p">,</span> <span class="n">mi</span><span class="p">,</span> <span class="n">di</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">delta</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">denom1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">4</span><span class="o">+</span><span class="mi">8</span><span class="o">*</span><span class="n">di</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">di</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">denom2</span><span class="p">,</span> <span class="n">denom3</span> <span class="o">=</span> <span class="p">(</span><span class="n">di</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="n">di</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">):</span>
            <span class="n">xm</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">mm</span><span class="p">]</span>
            <span class="n">xn</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span>
            <span class="n">t1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xm</span><span class="o">-</span><span class="n">xn</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">di</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">mi</span><span class="o">+</span><span class="n">xm</span><span class="o">+</span><span class="n">xn</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">denom2</span><span class="o">+</span><span class="p">(</span><span class="n">xm</span><span class="o">-</span><span class="n">xn</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">denom3</span>
            <span class="n">Pi</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t1</span><span class="o">/</span><span class="mi">6</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">di</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">denom1</span><span class="p">))</span>
            <span class="n">Pi</span><span class="p">[</span><span class="n">mm</span><span class="p">:,</span> <span class="n">mm</span><span class="p">]</span> <span class="o">=</span> <span class="n">Pi</span><span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">mm</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">Pi</span>


<span class="k">def</span> <span class="nf">compute_v_sq</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="c1"># v_sq = 1-np.trace(A_inv.dot(P))</span>
    <span class="n">v_sq</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_inv</span><span class="o">*</span><span class="n">P</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">v_sq</span>


<span class="k">def</span> <span class="nf">compute_zeta</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_zeta_econ</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_P</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">compute_varpi</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tau</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_varsigma_sq</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">varpi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">u</span><span class="o">-</span><span class="n">varpi</span>


<span class="k">def</span> <span class="nf">compute_varphi</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">varphi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tmp</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">tmp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">varphi</span>


<span class="k">def</span> <span class="nf">compute_varphi_econ</span><span class="p">(</span><span class="n">A_inv_P</span><span class="p">):</span>
    <span class="n">varphi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_inv_P</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">A_inv_P</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">varphi</span>


<span class="k">def</span> <span class="nf">compute_psi</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">Pi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">Pi</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_chi</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">varphi</span><span class="p">,</span> <span class="n">psi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nu</span><span class="o">+</span><span class="n">varphi</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">psi</span>


<span class="k">def</span> <span class="nf">compute_phi</span><span class="p">(</span><span class="n">train_vals</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">,</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pi</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">train_vals</span><span class="p">)</span> <span class="o">-</span>\
        <span class="n">train_vals</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">train_vals</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_phi_econ</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A_inv_y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">))</span><span class="o">-</span><span class="n">A_inv_y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
        <span class="n">P</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_P</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">compute_varrho</span><span class="p">(</span><span class="n">lamda</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lamda</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">train_vals</span><span class="p">))</span> <span class="o">-</span> <span class="n">tau</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
        <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">train_vals</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">compute_varrho_econ</span><span class="p">(</span><span class="n">lamda</span><span class="p">,</span> <span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lamda</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)</span> <span class="o">-</span> <span class="n">tau</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_P</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">compute_xi</span><span class="p">(</span><span class="n">xi_1</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xi_1</span><span class="o">+</span><span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span> <span class="o">-</span>\
        <span class="mi">2</span><span class="o">*</span><span class="n">lamda</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_xi_econ</span><span class="p">(</span><span class="n">xi_1</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">A_inv_tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xi_1</span><span class="o">+</span><span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_P</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_tau</span><span class="p">))</span> <span class="o">-</span>\
        <span class="mi">2</span><span class="o">*</span><span class="n">lamda</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_var_of_var_term1</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">chi</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">):</span>
    <span class="c1"># E[ I_2^2] (term1)</span>
    <span class="k">return</span> <span class="mi">4</span><span class="o">*</span><span class="n">phi</span><span class="o">*</span><span class="n">kernel_var</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">chi</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="p">(</span>
        <span class="n">zeta</span><span class="o">+</span><span class="n">v_sq</span><span class="o">*</span><span class="n">kernel_var</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>


<span class="k">def</span> <span class="nf">compute_var_of_var_term2</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">varrho</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span>
                             <span class="n">varsigma_sq</span><span class="p">):</span>
    <span class="c1"># -2E[I_2I^2] (term2)</span>
    <span class="k">return</span> <span class="mi">4</span><span class="o">*</span><span class="n">eta</span><span class="o">*</span><span class="n">varrho</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">xi</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>\
        <span class="n">zeta</span><span class="o">*</span><span class="n">varsigma_sq</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">+</span><span class="n">v_sq</span><span class="o">*</span><span class="n">varsigma_sq</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>\
        <span class="n">zeta</span><span class="o">*</span><span class="n">eta</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">eta</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">v_sq</span><span class="o">*</span><span class="n">kernel_var</span>


<span class="k">def</span> <span class="nf">compute_var_of_var_term3</span><span class="p">(</span><span class="n">varsigma_sq</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">):</span>
    <span class="c1"># E[I^4]</span>
    <span class="k">return</span> <span class="mi">3</span><span class="o">*</span><span class="n">varsigma_sq</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">eta</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">varsigma_sq</span><span class="o">*</span><span class="n">kernel_var</span> <span class="o">+</span>\
        <span class="n">eta</span><span class="o">**</span><span class="mi">4</span>


<span class="k">def</span> <span class="nf">gaussian_lamda</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lamda</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">xxi</span><span class="p">,</span> <span class="n">si</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">sigma</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">mi</span><span class="p">,</span> <span class="n">di</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">delta</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">denom1</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">4</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">di</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">di</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="p">(</span><span class="n">di</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">si</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">denom1</span><span class="o">*</span><span class="p">(</span><span class="n">mi</span><span class="o">-</span><span class="n">xxi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">lamda</span> <span class="o">*=</span> <span class="n">di</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">denom1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lamda</span>


<span class="k">def</span> <span class="nf">gaussian_xi_1</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">delta</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">delta</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">delta</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">variance_of_mean</span><span class="p">(</span><span class="n">kernel_var</span><span class="p">,</span> <span class="n">varsigma_sq</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">kernel_var</span><span class="o">*</span><span class="n">varsigma_sq</span>


<span class="k">def</span> <span class="nf">mean_of_variance</span><span class="p">(</span><span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">expected_random_mean</span><span class="p">,</span>
                     <span class="n">variance_random_mean</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">zeta</span><span class="o">+</span><span class="n">v_sq</span><span class="o">*</span><span class="n">kernel_var</span><span class="o">-</span><span class="n">expected_random_mean</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">variance_random_mean</span>


<span class="k">def</span> <span class="nf">extract_gaussian_process_attributes_for_integration</span><span class="p">(</span><span class="n">gp</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">WhiteKernel</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;kernels with noise not supported&#39;</span><span class="p">)</span>

    <span class="n">kernel_types</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">RBF</span><span class="p">,</span> <span class="n">Matern</span><span class="p">,</span> <span class="n">UnivariateMarginalizedSquaredExponentialKernel</span><span class="p">]</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">)</span>

    <span class="n">constant_kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">ConstantKernel</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">constant_kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kernel_var</span> <span class="o">=</span> <span class="n">constant_kernel</span><span class="o">.</span><span class="n">constant_value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">kernel_var</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">==</span> <span class="n">RBF</span> <span class="ow">and</span> <span class="ow">not</span>
        <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">==</span> <span class="n">Matern</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">nu</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span>
        <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">==</span> <span class="n">UnivariateMarginalizedSquaredExponentialKernel</span><span class="p">)):</span>
        <span class="c1"># Squared exponential kernel</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;GP Kernel type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span><span class="si">}</span><span class="s1"> &#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;Only squared exponential kernel supported&#39;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="s1">&#39;_K_inv&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">gp</span><span class="o">.</span><span class="n">_K_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># scikit-learn &lt; 0.24.2 has _K_inv</span>
        <span class="c1"># scikit-learn &gt;= 0.24.2 does not</span>
        <span class="n">L_inv</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">K_inv</span> <span class="o">=</span> <span class="n">L_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_inv</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">K_inv</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">_K_inv</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">transform_quad_rules</span> <span class="o">=</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="s1">&#39;var_trans&#39;</span><span class="p">))</span>
    <span class="c1"># gp.X_train_ will already be in the canonical space if var_trans is used</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># correct for normalization of gaussian process training data</span>
    <span class="c1"># gp.y_train_ is normalized such that</span>
    <span class="c1"># y_train = gp._y_train_std*gp.y_train_ + gp._y_train_mean</span>
    <span class="c1"># shift must be accounted for in integration so do not add here</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">*</span><span class="n">gp</span><span class="o">.</span><span class="n">y_train_</span>
    <span class="n">kernel_var</span> <span class="o">*=</span> <span class="nb">float</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">K_inv</span> <span class="o">/=</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">K_inv</span><span class="p">,</span> <span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span><span class="p">,</span> \
        <span class="n">kernel_var</span><span class="p">,</span> <span class="n">transform_quad_rules</span>


<span class="k">def</span> <span class="nf">integrate_gaussian_process</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">nquad_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The alpha regularization parameter used to construct the gp stored</span>
<span class="sd">    in gp.alpha can significantly impact condition number of A_inv</span>
<span class="sd">    and thus the accuracy that can be obtained in estimates of integrals</span>
<span class="sd">    particularly associated with variance. However setting alpha too large</span>
<span class="sd">    will also limit the accuracy that can be achieved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">K_inv</span><span class="p">,</span> <span class="n">kernel_length_scale</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> \
        <span class="n">transform_quad_rules</span> <span class="o">=</span> \
            <span class="n">extract_gaussian_process_attributes_for_integration</span><span class="p">(</span><span class="n">gp</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">integrate_gaussian_process_squared_exponential_kernel</span><span class="p">(</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">K_inv</span><span class="p">,</span> <span class="n">kernel_length_scale</span><span class="p">,</span>
        <span class="n">kernel_var</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">return_full</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span>
        <span class="n">nquad_samples</span><span class="p">,</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_mean</span><span class="p">)</span>
    <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">,</span> <span class="n">expected_random_var</span><span class="p">,</span> \
        <span class="n">variance_random_var</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">return_full</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">,</span> \
            <span class="n">expected_random_var</span><span class="p">,</span> <span class="n">variance_random_var</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">,</span> \
        <span class="n">expected_random_var</span><span class="p">,</span> <span class="n">variance_random_var</span>


<span class="k">def</span> <span class="nf">integrate_tau_P</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale_ii</span><span class="p">):</span>
    <span class="n">dist_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cdist</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
    <span class="n">dists_1d_x1_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span>
        <span class="n">xx_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">,</span> <span class="n">xtr</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_1d_x1_xtr</span><span class="p">)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">ww_1d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tau</span><span class="p">,</span> <span class="n">P</span>


<span class="k">def</span> <span class="nf">integrate_u_lamda_Pi_nu</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale_ii</span><span class="p">):</span>
    <span class="c1"># Get 2D tensor product quadrature rule</span>
    <span class="n">xx_2d</span> <span class="o">=</span> <span class="n">cartesian_product</span><span class="p">([</span><span class="n">xx_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ww_2d</span> <span class="o">=</span> <span class="n">outer_product</span><span class="p">([</span><span class="n">ww_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">dists_2d_x1_x2</span> <span class="o">=</span> <span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="o">-</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x1_x2</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">ww_2d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

    <span class="n">dist_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cdist</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
    <span class="n">dists_2d_x1_x2</span> <span class="o">=</span> <span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="o">-</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">dists_2d_x2_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">,</span> <span class="n">xtr</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span>
    <span class="n">lamda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x1_x2</span><span class="o">.</span><span class="n">T</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x2_xtr</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_2d</span><span class="p">)</span>

    <span class="n">dists_2d_x1_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">,</span> <span class="n">xtr</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span>
    <span class="c1"># ntrain_samples = xtr.shape[1]</span>
    <span class="c1"># Pi = np.empty((ntrain_samples, ntrain_samples))</span>
    <span class="c1"># for mm in range(ntrain_samples):</span>
    <span class="c1">#     dists1=dists_2d_x1_xtr[:, mm:mm+1]</span>
    <span class="c1">#     Pi[mm, mm:]= np.exp(</span>
    <span class="c1">#         -.5*dists1-.5*dists_2d_x1_x2-.5*dists_2d_x2_xtr[:, mm:]).T.dot(</span>
    <span class="c1">#             ww_2d)</span>
    <span class="c1">#     Pi[mm:, mm] = Pi[mm, mm:]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x1_x2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">ww_2d</span>
    <span class="n">Pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x1_xtr</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x2_xtr</span><span class="p">))</span>

    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dists_2d_x1_x2</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_2d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">nu</span>


<span class="k">def</span> <span class="nf">integrate_xi_1</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">lscale_ii</span><span class="p">):</span>
    <span class="n">xx_3d</span> <span class="o">=</span> <span class="n">cartesian_product</span><span class="p">([</span><span class="n">xx_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ww_3d</span> <span class="o">=</span> <span class="n">outer_product</span><span class="p">([</span><span class="n">ww_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">dists_3d_x1_x2</span> <span class="o">=</span> <span class="p">(</span><span class="n">xx_3d</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="n">lscale_ii</span><span class="o">-</span><span class="n">xx_3d</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">dists_3d_x2_x3</span> <span class="o">=</span> <span class="p">(</span><span class="n">xx_3d</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="n">lscale_ii</span><span class="o">-</span><span class="n">xx_3d</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">xi_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_3d_x1_x2</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_3d_x2_x3</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_3d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xi_1</span>


<span class="k">def</span> <span class="nf">get_gaussian_process_squared_exponential_kernel_1d_integrals</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span>
        <span class="n">nquad_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">skip_xi_1</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="n">nquad_samples</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>
    <span class="n">univariate_quad_rules</span> <span class="o">=</span> <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
        <span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="n">lscale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span>
    <span class="c1"># tau, u = 1, 1</span>
    <span class="c1"># ntrain_samples = X_train.shape[1]</span>
    <span class="c1"># P = np.ones((ntrain_samples, ntrain_samples))</span>
    <span class="c1"># lamda = np.ones(ntrain_samples)</span>
    <span class="c1"># Pi = np.ones((ntrain_samples, ntrain_samples))</span>
    <span class="c1"># xi_1, nu = 1, 1</span>

    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

    <span class="n">tau_list</span><span class="p">,</span> <span class="n">P_list</span><span class="p">,</span> <span class="n">u_list</span><span class="p">,</span> <span class="n">lamda_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">Pi_list</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">xi_1_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="c1"># TODO only compute quadrature once for each unique quadrature rules</span>
        <span class="c1"># But all quantities must be computed for all dimensions because</span>
        <span class="c1"># distances depend on either of both dimension dependent length scale</span>
        <span class="c1"># and training sample values</span>
        <span class="c1"># But others like u only needed to be computed for each unique</span>
        <span class="c1"># Quadrature rule and raised to the power equal to the number of</span>
        <span class="c1"># instances of a unique rule</span>

        <span class="c1"># Define distance function</span>
        <span class="c1"># dist_func = partial(cdist, metric=&#39;sqeuclidean&#39;)</span>

        <span class="c1"># Training samples of ith variable</span>
        <span class="n">xtr</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Get 1D quadrature rule</span>
        <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="n">univariate_quad_rules</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span><span class="n">degrees</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transform_quad_rules</span><span class="p">:</span>
            <span class="n">xx_1d</span> <span class="o">=</span> <span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical_1d</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ii</span><span class="p">)</span>

        <span class="c1"># Evaluate 1D integrals</span>
        <span class="n">tau_ii</span><span class="p">,</span> <span class="n">P_ii</span> <span class="o">=</span> <span class="n">integrate_tau_P</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
        <span class="c1"># tau *= tau_ii</span>
        <span class="c1"># P *= P_ii</span>

        <span class="n">u_ii</span><span class="p">,</span> <span class="n">lamda_ii</span><span class="p">,</span> <span class="n">Pi_ii</span><span class="p">,</span> <span class="n">nu_ii</span> <span class="o">=</span> <span class="n">integrate_u_lamda_Pi_nu</span><span class="p">(</span>
            <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
        <span class="c1"># u *= u_ii</span>
        <span class="c1"># lamda *= lamda_ii</span>
        <span class="c1"># Pi *= Pi_ii</span>
        <span class="c1"># nu *= nu_ii</span>
        <span class="k">if</span> <span class="n">skip_xi_1</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">xi_1_ii</span> <span class="o">=</span> <span class="n">integrate_xi_1</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">lscale</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xi_1_ii</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># xi_1 *= xi_1_ii</span>

        <span class="n">tau_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tau_ii</span><span class="p">)</span>
        <span class="n">P_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">P_ii</span><span class="p">)</span>
        <span class="n">u_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u_ii</span><span class="p">)</span>
        <span class="n">lamda_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lamda_ii</span><span class="p">)</span>
        <span class="n">Pi_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Pi_ii</span><span class="p">)</span>
        <span class="n">nu_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nu_ii</span><span class="p">)</span>
        <span class="n">xi_1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xi_1_ii</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tau_list</span><span class="p">,</span> <span class="n">P_list</span><span class="p">,</span> <span class="n">u_list</span><span class="p">,</span> <span class="n">lamda_list</span><span class="p">,</span> <span class="n">Pi_list</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">xi_1_list</span>


<span class="k">def</span> <span class="nf">integrate_gaussian_process_squared_exponential_kernel</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">Y_train</span><span class="p">,</span>
        <span class="n">K_inv</span><span class="p">,</span>
        <span class="n">length_scale</span><span class="p">,</span>
        <span class="n">kernel_var</span><span class="p">,</span>
        <span class="n">variable</span><span class="p">,</span>
        <span class="n">return_full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">transform_quad_rules</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">nquad_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">y_train_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute</span>

<span class="sd">    .. math:: I = \int \eta(\rv) \rho(\rv) ;d\rv</span>

<span class="sd">    and</span>

<span class="sd">    .. math:: \Sigma = I_2 - I^2, \qquad I_2 = \int \eta^2(\rv) \rho(\rv) ;d\rv</span>

<span class="sd">    where :math:`\rho(\rv)` is the joint density of independent random</span>
<span class="sd">    variables and :math:`\eta(\rv)` is a Gaussian process (GP)</span>
<span class="sd">    constructed with the squared exponential kernel</span>

<span class="sd">    .. math: K(x,y;L)=\sigma_K^2 \exp(-\frac{\lVert x-y\rVert_2^2}{2*L^2})</span>

<span class="sd">    with :math:`L` being a np.ndarray of shape (nvars) containing the</span>
<span class="sd">    length scales of the covariance kernel.</span>

<span class="sd">    Because the GP is a random process, the expectation :math:`I` and the</span>
<span class="sd">    variance :math:`\Sigma` of the GP with respect to :math:`\rv` are</span>
<span class="sd">    themselves  random variables. Specifically the expectation is a Gaussian</span>
<span class="sd">    random  variable with mean :math:`\mu` and variance :math:`v^2`. The</span>
<span class="sd">    distribution of :math:`\Sigma` is harder to compute, but we can compute</span>
<span class="sd">    its mean and variance</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_train : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The locations of the training data used to train the GP</span>

<span class="sd">    Y_train : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The data values at ``X_train`` used to train the GP</span>

<span class="sd">    K_inv : np.ndarray (nsamples,nsamples)</span>
<span class="sd">        The inverse of the covariance matrix</span>
<span class="sd">        :math:`K(X_train,X_train;length_scale)`</span>

<span class="sd">    length_scale : np.ndarray (nvars)</span>
<span class="sd">        The length scales :math:`L`</span>

<span class="sd">    kernel_var : float</span>
<span class="sd">        The variance :math:`\sigma_K^2` of the kernel :math:`K`</span>

<span class="sd">    variable : :class:`pyapprox.variable.IndependentMarginalsVariable`</span>
<span class="sd">        A set of independent univariate random variables. The tensor-product</span>
<span class="sd">        of the 1D PDFs yields the joint density :math:`\rho`</span>

<span class="sd">    return_full : boolean</span>
<span class="sd">       If true return intermediate quantities used to compute statistics.</span>
<span class="sd">       This is only necessary for testing</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    expected_random_mean : float</span>
<span class="sd">        The mean :math:`\mu_I` of the Gaussian random variable representing the</span>
<span class="sd">        expectation :math:`I`</span>

<span class="sd">    variance_random_mean : float</span>
<span class="sd">        The variance :math:`v_I^2` of the Gaussian random variable representing</span>
<span class="sd">        the expectation :math:`I`</span>

<span class="sd">    expected_random_var : float</span>
<span class="sd">        The mean :math:`\mu_\Sigma` of the Gaussian random variable</span>
<span class="sd">        representing the variance :math:`\Sigma`</span>

<span class="sd">    variance_random_var : float</span>
<span class="sd">        The variance :math:`v_\Sigma^2` of the Gaussian random variable</span>
<span class="sd">        representing the variance :math:`\Sigma`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tau_list</span><span class="p">,</span> <span class="n">P_list</span><span class="p">,</span> <span class="n">u_list</span><span class="p">,</span> <span class="n">lamda_list</span><span class="p">,</span> <span class="n">Pi_list</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">xi_1_list</span> <span class="o">=</span> \
        <span class="n">get_gaussian_process_squared_exponential_kernel_1d_integrals</span><span class="p">(</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span>
            <span class="n">nquad_samples</span><span class="p">)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tau_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">P_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">u_list</span><span class="p">)</span>
    <span class="n">lamda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lamda_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Pi_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">nu_list</span><span class="p">)</span>
    <span class="n">xi_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">xi_1_list</span><span class="p">)</span>

    <span class="c1"># K_inv is inv(kernel_var*A). Thus multiply by kernel_var to get</span>
    <span class="c1"># Haylock formula</span>
    <span class="n">A_inv</span> <span class="o">=</span> <span class="n">K_inv</span><span class="o">*</span><span class="n">kernel_var</span>
    <span class="c1"># No kernel_var because it cancels out because it appears in K (1/s^2)</span>
    <span class="c1"># and t (s^2)</span>
    <span class="n">A_inv_y</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
    <span class="n">expected_random_mean</span> <span class="o">=</span> <span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)</span>
    <span class="n">expected_random_mean</span> <span class="o">+=</span> <span class="n">y_train_mean</span>

    <span class="n">varpi</span> <span class="o">=</span> <span class="n">compute_varpi</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">)</span>
    <span class="n">varsigma_sq</span> <span class="o">=</span> <span class="n">compute_varsigma_sq</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">varpi</span><span class="p">)</span>
    <span class="n">variance_random_mean</span> <span class="o">=</span> <span class="n">variance_of_mean</span><span class="p">(</span><span class="n">kernel_var</span><span class="p">,</span> <span class="n">varsigma_sq</span><span class="p">)</span>

    <span class="n">A_inv_P</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">A_inv_tau</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">v_sq</span> <span class="o">=</span> <span class="n">compute_v_sq</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
    <span class="c1"># zeta = compute_zeta(Y_train, A_inv, P)</span>
    <span class="n">zeta</span> <span class="o">=</span> <span class="n">compute_zeta_econ</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">)</span>
    <span class="n">zeta</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)</span><span class="o">*</span><span class="n">y_train_mean</span><span class="o">+</span><span class="n">y_train_mean</span><span class="o">**</span><span class="mi">2</span>

    <span class="n">expected_random_var</span> <span class="o">=</span> <span class="n">mean_of_variance</span><span class="p">(</span>
        <span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">)</span>

    <span class="c1"># varphi = compute_varphi(A_inv, P)</span>
    <span class="n">varphi</span> <span class="o">=</span> <span class="n">compute_varphi_econ</span><span class="p">(</span><span class="n">A_inv_P</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="n">compute_psi</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">Pi</span><span class="p">)</span>
    <span class="n">chi</span> <span class="o">=</span> <span class="n">compute_chi</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">varphi</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

    <span class="n">eta</span> <span class="o">=</span> <span class="n">expected_random_mean</span>
    <span class="c1"># varrho = compute_varrho(lamda, A_inv, Y_train, P, tau)</span>
    <span class="n">varrho</span> <span class="o">=</span> <span class="n">compute_varrho_econ</span><span class="p">(</span><span class="n">lamda</span><span class="p">,</span> <span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
    <span class="c1"># phi = compute_phi(Y_train, A_inv, Pi, P)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="n">compute_phi_econ</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
    <span class="c1"># adjust phi with unadjusted varrho</span>
    <span class="n">phi</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">y_train_mean</span><span class="o">*</span><span class="n">varrho</span><span class="o">+</span><span class="n">y_train_mean</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">varsigma_sq</span>
    <span class="c1"># now adjust varrho</span>
    <span class="n">varrho</span> <span class="o">+=</span> <span class="n">y_train_mean</span><span class="o">*</span><span class="n">varsigma_sq</span>
    <span class="c1"># xi = compute_xi(xi_1, lamda, tau, P, A_inv)</span>
    <span class="n">xi</span> <span class="o">=</span> <span class="n">compute_xi_econ</span><span class="p">(</span><span class="n">xi_1</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">A_inv_P</span><span class="p">,</span> <span class="n">A_inv_tau</span><span class="p">)</span>

    <span class="n">term1</span> <span class="o">=</span> <span class="n">compute_var_of_var_term1</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">chi</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">)</span>
    <span class="n">term2</span> <span class="o">=</span> <span class="n">compute_var_of_var_term2</span><span class="p">(</span>
        <span class="n">eta</span><span class="p">,</span> <span class="n">varrho</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span> <span class="n">varsigma_sq</span><span class="p">)</span>
    <span class="n">term3</span> <span class="o">=</span> <span class="n">compute_var_of_var_term3</span><span class="p">(</span><span class="n">varsigma_sq</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">)</span>
    <span class="n">variance_random_var</span> <span class="o">=</span> <span class="n">term1</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">term2</span><span class="o">+</span><span class="n">term3</span>
    <span class="n">variance_random_var</span> <span class="o">-=</span> <span class="n">expected_random_var</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_full</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">,</span> \
            <span class="n">expected_random_var</span><span class="p">,</span> <span class="n">variance_random_var</span>

    <span class="n">intermeadiate_quantities</span> <span class="o">=</span> <span class="n">tau</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">varpi</span><span class="p">,</span> <span class="n">varsigma_sq</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> \
        <span class="n">varphi</span><span class="p">,</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">chi</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">varrho</span><span class="p">,</span> <span class="n">xi_1</span><span class="p">,</span> <span class="n">xi</span>
    <span class="k">return</span> <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">variance_random_mean</span><span class="p">,</span> <span class="n">expected_random_var</span><span class="p">,</span>\
        <span class="n">variance_random_var</span><span class="p">,</span> <span class="n">intermeadiate_quantities</span>


<span class="k">def</span> <span class="nf">generate_gp_candidate_samples</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">num_candidate_samples</span><span class="p">,</span>
                                  <span class="n">generate_random_samples</span><span class="p">,</span> <span class="n">variable</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">generate_random_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_halton_candidates</span> <span class="o">=</span> <span class="n">num_candidate_samples</span><span class="o">//</span><span class="mi">2</span>
        <span class="n">num_random_candidates</span> <span class="o">=</span> <span class="n">num_candidate_samples</span><span class="o">//</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_halton_candidates</span> <span class="o">=</span> <span class="n">num_candidate_samples</span>
        <span class="n">num_random_candidates</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># if variable is None:</span>
    <span class="c1">#     marginal_icdfs = None</span>
    <span class="c1"># else:</span>
    <span class="c1">#     # marginal_icdfs = [v.ppf for v in self.variable]</span>
    <span class="c1">#     from scipy import stats</span>
    <span class="c1">#     marginal_icdfs = []</span>
    <span class="c1">#     # spread QMC samples over entire domain. Range of variable</span>
    <span class="c1">#     # is used but not its PDF</span>
    <span class="c1">#     for v in variable.marginals():</span>
    <span class="c1">#         lb, ub = v.interval(1)</span>
    <span class="c1">#         if not np.isfinite(lb) or not np.isfinite(ub):</span>
    <span class="c1">#             lb, ub = v.interval(1-1e-6)</span>
    <span class="c1">#         marginal_icdfs.append(stats.uniform(lb, ub-lb).ppf)</span>

    <span class="c1"># candidate_samples = transformed_halton_sequence(</span>
    <span class="c1">#     marginal_icdfs, nvars, num_halton_candidates)</span>
    <span class="kn">from</span> <span class="nn">pyapprox.expdesign.low_discrepancy_sequences</span> <span class="kn">import</span> <span class="n">sobol_sequence</span>
    <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">sobol_sequence</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">num_halton_candidates</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                                       <span class="n">variable</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num_random_candidates</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
            <span class="n">candidate_samples</span><span class="p">,</span> <span class="n">generate_random_samples</span><span class="p">(</span><span class="n">num_random_candidates</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">candidate_samples</span>


<span class="k">class</span> <span class="nc">CholeskySampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute samples for kernel based approximation using the power-function</span>
<span class="sd">    method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_vars : integer</span>
<span class="sd">        The number of variables</span>

<span class="sd">    num_candidate_samples : integer</span>
<span class="sd">        The number of candidate samples from which final samples are chosen</span>

<span class="sd">    variable : :class:`pyapprox.variable.IndependentMarginalsVariable`</span>
<span class="sd">        A set of independent univariate random variables. The tensor-product</span>
<span class="sd">        of the 1D PDFs yields the joint density :math:`\rho`</span>

<span class="sd">    max_num_samples : integer</span>
<span class="sd">        The maximum number of samples to be generated</span>

<span class="sd">    weight_function : callable</span>
<span class="sd">        Function used to precondition kernel with the signature</span>

<span class="sd">        ``weight_function(samples) -&gt; np.ndarray (num_samples)``</span>

<span class="sd">        where samples is a np.ndarray (num_vars,num_samples)</span>

<span class="sd">    generate_random_samples : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``generate_random_samples(nsamples) -&gt; np.ndarray (nvars, nsamples)``</span>

<span class="sd">        used to generate samples to enrich default candidate set.</span>
<span class="sd">        If this is not None then num_candidate_samples//2 will be created</span>
<span class="sd">        by this function and the other half of samples will be from a Halton</span>
<span class="sd">        sequence.</span>

<span class="sd">    init_pivots : np.ndarray (ninit_pivots)</span>
<span class="sd">        The array indices of the candidate_samples to keep</span>

<span class="sd">    econ : boolean</span>
<span class="sd">        True - pivot based upon diagonal of schur complement</span>
<span class="sd">        False - pivot to minimize trace norm of low-rank approximation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_vars</span><span class="p">,</span> <span class="n">num_candidate_samples</span><span class="p">,</span> <span class="n">variable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">generate_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_pivots</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">gen_candidate_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">var_trans</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span> <span class="o">=</span> <span class="n">num_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_theta</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span> <span class="o">=</span> <span class="n">generate_random_samples</span>
        <span class="k">if</span> <span class="n">gen_candidate_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">gen_candidate_samples</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">generate_gp_candidate_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span>
                <span class="n">generate_random_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span><span class="p">,</span>
                <span class="n">variable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="n">var_trans</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_candidate_samples</span><span class="p">(</span>
            <span class="n">gen_candidate_samples</span><span class="p">(</span><span class="n">num_candidate_samples</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_weight_function</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_init_pivots</span><span class="p">(</span><span class="n">init_pivots</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="o">=</span> <span class="n">econ</span>

    <span class="k">def</span> <span class="nf">set_candidate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">candidate_samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span>
                <span class="n">candidate_samples</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">candidate_samples</span>

    <span class="k">def</span> <span class="nf">add_nugget</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span>

    <span class="k">def</span> <span class="nf">set_weight_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_function</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">weight_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_function</span> <span class="o">=</span> <span class="n">weight_function</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># weight function is applied in canonical_space</span>
            <span class="k">def</span> <span class="nf">wt_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">weight_function</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_function</span> <span class="o">=</span> <span class="n">wt_function</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_function_changed</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">set_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">!=</span> <span class="n">kernel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">theta</span>

    <span class="k">def</span> <span class="nf">set_init_pivots</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_pivots</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="o">=</span> <span class="n">init_pivots</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots_changed</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Must call set_kernel&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;weight_function&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Must call set_weight_function&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Requesting number of samples </span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s1"> which is less &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;than number of training samples already generated &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_changed</span>

        <span class="n">nprev_train_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_function_changed</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_changed</span> <span class="ow">or</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots_changed</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span><span class="p">)</span>
                <span class="c1"># assert np.allclose(np.diag(weights).dot(self.Kmatrix.dot(</span>
                <span class="c1">#    np.diag(weights))),</span>
                <span class="c1">#    weights[:, np.newaxis]*self.Kmatrix*weights)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="o">*</span><span class="n">weights</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_nugget</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diag</span><span class="p">,</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">init_error</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> \
                <span class="n">pivoted_cholesky_decomposition</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">init_pivots</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">,</span>
                    <span class="n">pivot_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span><span class="p">,</span>
                    <span class="n">error_on_small_tol</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_full</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">weight_function_changed</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_changed</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span><span class="p">,</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> \
                <span class="n">continue_pivoted_cholesky_decomposition</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Kmatrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">,</span>
                    <span class="mf">0.</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivot_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diag</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_error</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">==</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># extract samples that were not already in sample set</span>
        <span class="c1"># pivots has already been reduced to have the size of the number of</span>
        <span class="c1"># samples requested</span>
        <span class="n">new_samples</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">[</span>
                <span class="n">nprev_train_samples</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span> <span class="n">new_samples</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">new_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical</span><span class="p">(</span>
            <span class="n">new_samples</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span>


<span class="k">class</span> <span class="nc">AdaptiveCholeskyGaussianProcessFixedKernel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Efficient implementation when Gaussian process kernel has no tunable</span>
<span class="sd">    hyper-parameters. Cholesky factor computed to generate training samples</span>
<span class="sd">    is reused for fiting</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">refine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Cannot refine. No well conditioned candidate samples &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;remaining&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="n">new_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chol_flag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">new_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">new_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;train_samples&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">new_samples</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_values</span><span class="p">,</span> <span class="n">new_values</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_values</span> <span class="o">=</span> <span class="n">new_samples</span><span class="p">,</span> <span class="n">new_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_current_chol_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">nn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">ntraining_samples</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span> <span class="o">==</span> <span class="n">CholeskySampler</span><span class="p">:</span>
            <span class="n">chol_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">L</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">pivots</span><span class="p">[:</span><span class="n">nn</span><span class="p">],</span> <span class="p">:</span><span class="n">nn</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span> <span class="o">==</span> <span class="n">GreedyIntegratedVarianceSampler</span><span class="p">:</span>
            <span class="n">chol_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">L</span><span class="p">[:</span><span class="n">nn</span><span class="p">,</span> <span class="p">:</span><span class="n">nn</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">chol_factor</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">chol_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_current_chol_factor</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">cholesky_solve_linear_system</span><span class="p">(</span>
            <span class="n">chol_factor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_values</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">num_training_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">condition_number</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">chol_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_current_chol_factor</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">chol_factor</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chol_factor</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">gaussian_process_pointwise_variance</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">pred_samples</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span>
                                        <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the pointwise variance of a Gaussian process, that is</span>

<span class="sd">    .. math::</span>

<span class="sd">       K(\hat{x}, \hat{x}) - K(\hat{X}, y)^T  K(\hat{X}, \hat{X}) K(\hat{X}, y)</span>

<span class="sd">    for each sample :math:`\hat{x}=[\hat{x}_1,\ldots,\hat{x}_d]` and a set of</span>
<span class="sd">    training samples :math:`X=[x^{(1)},\ldots,x^{(N)}]`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``K(X, Y) -&gt; np.ndarray(X.shape[0], Y.shape[0])``</span>

<span class="sd">        where X and Y are samples with shape (nsamples_X, nvars) and</span>
<span class="sd">        (nsamples_Y, nvars). Note this function accepts sample sets stored in</span>
<span class="sd">        the transpose of the typical pyapprox format</span>

<span class="sd">    train_samples : np.ndarray (nvars, ntrain_samples)</span>
<span class="sd">        The locations of the training data used to train the GP</span>

<span class="sd">    pred_samples : np.ndarray (nvars, npred_samples)</span>
<span class="sd">        The data values at ``X_train`` used to train the GP</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : np.ndarray (npred_samples)</span>
<span class="sd">       The pointwise variance at each prediction sample</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">K_train</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="c1"># add small number to diagonal to ensure covariance matrix is</span>
    <span class="c1"># positive definite</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">K_train</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">nugget</span>
    <span class="n">k_pred</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">pred_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_train</span><span class="p">)</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">k_pred</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">pred_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tmp</span><span class="o">*</span><span class="n">tmp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">variance</span>


<span class="k">def</span> <span class="nf">RBF_gradient_wrt_samples</span><span class="p">(</span><span class="n">query_sample</span><span class="p">,</span> <span class="n">other_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gradient of the squared exponential kernel</span>

<span class="sd">    .. math::</span>

<span class="sd">       \frac{\partial}{\partial x}K(x, Y) = -K(x, Y)^T \circ D\Lambda^{-1}</span>

<span class="sd">    Here :math:`x=[x_1,\ldots,x_d]^T` is a sample,</span>
<span class="sd">    :math:`Y=[y^{(1)},\ldots,y^{(N)}]`</span>
<span class="sd">    is a set of samples  and the kernel is given by</span>

<span class="sd">    .. math::</span>

<span class="sd">       K(x, y^{(i)}) =</span>
<span class="sd">       \exp\left(-\frac{1}{2}(x-y^{(i)})^T\Lambda^{-1}(x-y^{(i)})\right)</span>

<span class="sd">    where</span>
<span class="sd">    :math:`\Lambda^{-1}=\mathrm{diag}([l_1^2,\ldots,l_d^2])`,</span>
<span class="sd">    :math:`D=[\tilde{x}-\tilde{y}^{(1)},\ldots,\tilde{x}-\tilde{y}^{(N)}]` and</span>

<span class="sd">    .. math::</span>

<span class="sd">       \tilde{x} = \left[\frac{x_1}{l_1^2}, \ldots, \frac{x_d}{l_d^2}\right],</span>
<span class="sd">       \qquad  \tilde{y}^{(i)} =</span>
<span class="sd">       \left[\frac{y_1^{(i)}}{l_1^2},\ldots, \frac{y_d^{(i)}}{l_d^2}\right]</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    query_sample : np.ndarray (nvars, 1)</span>
<span class="sd">        The sample :math:`x`</span>

<span class="sd">    other_samples : np.ndarray (nvars, nother_samples)</span>
<span class="sd">        The samples :math:`y`</span>

<span class="sd">    length_scale : np.ndarray (nvars)</span>
<span class="sd">        The length scales `l` in each dimension</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    grad : np.ndarray (nother_samples, nvars)</span>
<span class="sd">        The gradient of the kernel</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">length_scale</span><span class="p">,</span> <span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">length_scale</span><span class="p">,</span>
                  <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">dists</span><span class="p">)</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">other_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span><span class="o">-</span><span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad</span>


<span class="k">def</span> <span class="nf">RBF_integrated_posterior_variance_gradient_wrt_samples</span><span class="p">(</span>
        <span class="n">train_samples</span><span class="p">,</span> <span class="n">quad_x</span><span class="p">,</span> <span class="n">quad_w</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">,</span> <span class="n">new_samples_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nvars</span><span class="p">,</span> <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">length_scale</span><span class="p">):</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">length_scale</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span><span class="p">)</span>
    <span class="n">K_train</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="c1"># add small number to diagonal to ensure covariance matrix is</span>
    <span class="c1"># positive definite</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">K_train</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">nugget</span>
    <span class="n">A_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">K_train</span><span class="p">)</span>
    <span class="n">grad_P</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">integrate_grad_P</span><span class="p">(</span>
        <span class="n">quad_x</span><span class="p">,</span> <span class="n">quad_w</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">)</span>
    <span class="n">AinvPAinv</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv</span><span class="p">))</span>

    <span class="n">noptimized_train_samples</span> <span class="o">=</span> <span class="n">ntrain_samples</span><span class="o">-</span><span class="n">new_samples_index</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nvars</span><span class="o">*</span><span class="n">noptimized_train_samples</span><span class="p">))</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_samples_index</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">):</span>
        <span class="n">K_train_grad_all_train_points_kk</span> <span class="o">=</span> \
            <span class="n">RBF_gradient_wrt_samples</span><span class="p">(</span>
                <span class="n">train_samples</span><span class="p">[:,</span> <span class="n">kk</span><span class="p">:</span><span class="n">kk</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">)</span>
        <span class="c1"># Use the follow properties for tmp3 and tmp4</span>
        <span class="c1"># Do sparse matrix element wise product</span>
        <span class="c1"># 0 a 0   D00 D01 D02</span>
        <span class="c1"># a b c x D10 D11 D12</span>
        <span class="c1"># 0 c 0   D20 D21 D22</span>
        <span class="c1"># =2*(a*D01 b*D11 + c*D21)-b*D11</span>
        <span class="c1">#</span>
        <span class="c1"># Trace [RCRP] = Trace[RPRC] for symmetric matrices</span>
        <span class="n">tmp3</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K_train_grad_all_train_points_kk</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">AinvPAinv</span><span class="p">[:,</span> <span class="n">kk</span><span class="p">],</span>
                         <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tmp3</span> <span class="o">-=</span> <span class="o">-</span><span class="n">K_train_grad_all_train_points_kk</span><span class="p">[</span><span class="n">kk</span><span class="p">,</span> <span class="p">:]</span><span class="o">*</span><span class="n">AinvPAinv</span><span class="p">[</span><span class="n">kk</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span>
        <span class="n">jac</span><span class="p">[</span><span class="n">cnt</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">cnt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">tmp3</span>
        <span class="n">tmp4</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grad_P</span><span class="p">[</span><span class="n">kk</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">kk</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">]</span><span class="o">*</span><span class="n">A_inv</span><span class="p">[:,</span> <span class="n">kk</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tmp4</span> <span class="o">-=</span> <span class="n">grad_P</span><span class="p">[</span><span class="n">kk</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">kk</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span><span class="o">*</span><span class="n">A_inv</span><span class="p">[</span><span class="n">kk</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span>
        <span class="n">jac</span><span class="p">[</span><span class="n">cnt</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">cnt</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">]</span> <span class="o">-=</span> <span class="n">tmp4</span>
        <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">jac</span>


<span class="k">def</span> <span class="nf">RBF_posterior_variance_jacobian_wrt_samples</span><span class="p">(</span>
        <span class="n">train_samples</span><span class="p">,</span> <span class="n">pred_samples</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">,</span> <span class="n">new_samples_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gradient of the posterior covariance of a Gaussian process built</span>
<span class="sd">    using the squared exponential kernel. Let :math:`\hat{x}^{(i)}` be a</span>
<span class="sd">    prediction sample and :math:`x=[x^{(1)}, \ldots, x^{(N)}]` be the</span>
<span class="sd">    training samples then the posterior covariance is</span>

<span class="sd">    .. math::</span>

<span class="sd">       c(\hat{x}^{(i)}, x)=c(\hat{x}^{(i)}, \hat{x}^{(i)}) -</span>
<span class="sd">       K(\hat{x}^{(i)}, x)R K(\hat{x}^{(i)}, x)^T</span>

<span class="sd">    and</span>

<span class="sd">    .. math::</span>

<span class="sd">       \frac{\partial c(\hat{x}^{(i)}, x)}{\partial x_l}=</span>
<span class="sd">       2\left(\frac{\partial}{\partial x_l}K(\hat{x}^{(i)}, x_l)\right)</span>
<span class="sd">       \sum_{k=1}^N</span>
<span class="sd">       R[l,k]K(\hat{x}^{(i)}, x_k) - \sum_{j=1}^N\sum_{k=1}^N K(\hat{x}^{(i)},</span>
<span class="sd">       x_j)\frac{\partial}{\partial x_l}\left(R[j,k]\right)(\hat{x}^{(i)}, x_k)</span>

<span class="sd">    where :math:`R = K(x, x)^{-1}` and</span>

<span class="sd">    .. math::</span>

<span class="sd">       \frac{\partial R^{-1}}{\partial x_l} = R^{-1}</span>
<span class="sd">       \frac{\partial R}{\partial x_l} R^{-1}</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars, ntrain_samples)</span>
<span class="sd">        The locations of the training data used to train the GP</span>

<span class="sd">    pred_samples : np.ndarray (nvars, npred_samples)</span>
<span class="sd">        The data values at ``X_train`` used to train the GP</span>

<span class="sd">    kernel : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``K(X, Y) -&gt; np.ndarray(X.shape[0], Y.shape[0])``</span>

<span class="sd">        where X and Y are samples with shape (nsamples_X, nvars) and</span>
<span class="sd">        (nsamples_Y, nvars). Note this function accepts sample sets stored in</span>
<span class="sd">        the transpose of the typical pyapprox format</span>

<span class="sd">    new_samples_index : integer</span>
<span class="sd">        Index in train samples that indicates the train samples for which</span>
<span class="sd">        derivatives will be computed. That is compute the derivatives of the</span>
<span class="sd">        coordinates of train_samples[:,new_sample_index:]</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    jac : np.ndarray (npred_samples, (ntrain_samples-new_sample_index)*nvars)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span>
    <span class="n">nvars</span><span class="p">,</span> <span class="n">npred_samples</span> <span class="o">=</span> <span class="n">pred_samples</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">noptimized_train_samples</span> <span class="o">=</span> <span class="n">ntrain_samples</span><span class="o">-</span><span class="n">new_samples_index</span>
    <span class="n">k_pred_grad_all_train_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="n">noptimized_train_samples</span><span class="p">,</span> <span class="n">npred_samples</span><span class="p">,</span> <span class="n">nvars</span><span class="p">))</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_samples_index</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">):</span>
        <span class="n">k_pred_grad_all_train_points</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> \
            <span class="n">RBF_gradient_wrt_samples</span><span class="p">(</span>
            <span class="n">train_samples</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">:</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">)</span>
        <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">K_train</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="c1"># add small number to diagonal to ensure covariance matrix is</span>
    <span class="c1"># positive definite</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">K_train</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">nugget</span>

    <span class="n">K_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">K_train</span><span class="p">)</span>
    <span class="n">k_pred</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">pred_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">npred_samples</span><span class="p">,</span> <span class="n">nvars</span><span class="o">*</span><span class="n">noptimized_train_samples</span><span class="p">))</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">k_pred</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K_inv</span><span class="p">)</span>
    <span class="c1"># K_train_grad = np.zeros((ntrain_samples, ntrain_samples))</span>
    <span class="n">ii</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_samples_index</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">):</span>
        <span class="n">K_train_grad_all_train_points_jj</span> <span class="o">=</span> \
            <span class="n">RBF_gradient_wrt_samples</span><span class="p">(</span>
                <span class="n">train_samples</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">:</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">)</span>
        <span class="n">jac</span><span class="p">[:,</span> <span class="n">ii</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">]</span> <span class="o">+=</span> \
            <span class="mi">2</span><span class="o">*</span><span class="n">tau</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">:</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">k_pred_grad_all_train_points</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">tmp1</span> <span class="o">=</span> <span class="n">K_train_grad_all_train_points_jj</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span>\
            <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tau</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">:</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">))</span>
        <span class="n">tmp1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">K_train_grad_all_train_points_jj</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tau</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tau</span><span class="o">*</span><span class="n">tmp1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">jac</span><span class="p">[:,</span> <span class="n">ii</span><span class="o">*</span><span class="n">nvars</span><span class="p">:(</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">nvars</span><span class="p">]</span> <span class="o">-=</span> <span class="n">tmp2</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># check if -= is needed over =</span>
        <span class="c1"># leave the following for loop to show how sparsity is taken advantage</span>
        <span class="c1"># of above. Above is abstract and hard to see what is being done</span>
        <span class="c1"># for kk in range(nvars):</span>
        <span class="c1">#     # K_train_grad[jj, :] = K_train_grad_all_train_points_jj[:, kk]</span>
        <span class="c1">#     # K_train_grad[:, jj] = K_train_grad[jj, :]</span>
        <span class="c1">#     # The following takes advantage of sparsity of</span>
        <span class="c1">#     # tmp = tau.dot(K_train_grad)</span>
        <span class="c1">#     # Reset to zero</span>
        <span class="c1">#     # K_train_grad[jj, :] = 0</span>
        <span class="c1">#     # K_train_grad[:, jj] = 0</span>
        <span class="c1">#     tmp = K_train_grad_all_train_points_jj[:, kk:kk+1].T *\</span>
        <span class="c1">#         np.tile(tau[:, jj:jj+1], (1, ntrain_samples))</span>
        <span class="c1">#     tmp[:, jj] = tau.dot(K_train_grad_all_train_points_jj[:, kk])</span>
        <span class="c1">#     assert np.allclose(tmp[:,jj], tmp1[kk,:,jj])</span>
        <span class="c1">#     assert np.allclose(tmp,tmp1[kk,:,:])</span>
        <span class="c1">#     jac[:, ii*nvars+kk] -= np.sum(tmp*tau, axis=1)</span>
        <span class="n">ii</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">jac</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">jac</span>


<span class="k">def</span> <span class="nf">gaussian_grad_P_diag_term1</span><span class="p">(</span><span class="n">xtr_ii</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">xtr_ii</span>
    <span class="n">term1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">a</span><span class="o">-</span><span class="n">m</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">*</span><span class="n">l</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">+</span><span class="n">m</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">term1</span>


<span class="k">def</span> <span class="nf">gaussian_grad_P_diag_term2</span><span class="p">(</span><span class="n">xtr_ii</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">xtr_ii</span>
    <span class="n">term2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">b</span><span class="o">-</span><span class="n">n</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">/</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">term2</span>


<span class="k">def</span> <span class="nf">gaussian_grad_P_offdiag_term1</span><span class="p">(</span><span class="n">xtr_ii</span><span class="p">,</span> <span class="n">xtr_jj</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">xtr_ii</span><span class="p">,</span> <span class="n">xtr_jj</span>
    <span class="n">term1</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">c</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">c</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span>
                  <span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span>
                      <span class="mi">2</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span>
                          <span class="n">l</span><span class="o">*</span><span class="p">(</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">term1</span>


<span class="k">def</span> <span class="nf">gaussian_grad_P_offdiag_term2</span><span class="p">(</span><span class="n">xtr_ii</span><span class="p">,</span> <span class="n">xtr_jj</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">xtr_ii</span><span class="p">,</span> <span class="n">xtr_jj</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>
    <span class="n">term2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">d</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">d</span> <span class="o">**</span>
                      <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="p">(</span><span class="n">d</span><span class="o">*</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">n</span><span class="o">*</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span>
                          <span class="mi">2</span><span class="o">*</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="n">term2</span> <span class="o">/=</span> <span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">/</span><span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">term2</span>


<span class="k">def</span> <span class="nf">integrate_grad_P</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">ww</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale</span><span class="p">):</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lscale</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">ww</span><span class="p">)</span> <span class="o">==</span> <span class="n">nvars</span>
    <span class="k">assert</span> <span class="n">xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">nvars</span>
    <span class="n">dist_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cdist</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">grad_P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nvars</span><span class="o">*</span><span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">))</span>
    <span class="n">K</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># keep K as list to allow for different size quadrature rules</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># similarly for diffs</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nvars</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">ntrain_samples</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="n">xx</span><span class="p">[</span><span class="n">nn</span><span class="p">],</span> <span class="n">ww</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span>
        <span class="n">lscale_nn</span> <span class="o">=</span> <span class="n">lscale</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span>
        <span class="n">dists_1d_x1_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span>
            <span class="n">xx_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">/</span><span class="n">lscale_nn</span><span class="p">,</span> <span class="n">xtr</span><span class="p">[</span><span class="n">nn</span><span class="p">:</span><span class="n">nn</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_nn</span><span class="p">)</span>
        <span class="n">K</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_1d_x1_xtr</span><span class="p">))</span>
        <span class="n">P</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">diffs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">xtr</span><span class="p">[</span><span class="n">nn</span><span class="p">:</span><span class="n">nn</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">-</span><span class="n">xx_1d</span><span class="p">)</span><span class="o">/</span><span class="n">lscale_nn</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># TODO replace loop over train samples with numpy operations</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">diffs</span><span class="p">[</span><span class="n">nn</span><span class="p">][</span><span class="n">ii</span><span class="p">]</span>
            <span class="n">grad_P</span><span class="p">[</span><span class="n">nvars</span><span class="o">*</span><span class="n">ii</span><span class="o">+</span><span class="n">nn</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">ww_1d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="p">(</span><span class="n">diff</span><span class="o">*</span><span class="n">K</span><span class="p">[</span><span class="n">nn</span><span class="p">][:,</span> <span class="n">ii</span><span class="p">])[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">[</span><span class="n">nn</span><span class="p">])</span>
            <span class="n">grad_P</span><span class="p">[</span><span class="n">nvars</span><span class="o">*</span><span class="n">ii</span><span class="o">+</span><span class="n">nn</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">P</span><span class="p">[:</span><span class="n">nn</span><span class="p">,</span> <span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">grad_P</span><span class="p">[</span><span class="n">nvars</span><span class="o">*</span><span class="n">ii</span><span class="o">+</span><span class="n">nn</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">nn</span><span class="o">+</span><span class="mi">1</span><span class="p">:,</span> <span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">grad_P</span><span class="p">[</span><span class="n">nvars</span><span class="o">*</span><span class="n">ii</span><span class="o">+</span><span class="n">nn</span><span class="p">,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">grad_P</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">IVARSampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_vars : integer</span>
<span class="sd">        The number of dimensions</span>

<span class="sd">    nquad_samples : integer</span>
<span class="sd">        The number of samples used to compute the sample based estimate</span>
<span class="sd">        of the integrated variance (IVAR). If use_quadrature is True</span>
<span class="sd">        then this should be 100-1000. Otherwise this value should be at</span>
<span class="sd">        least 10,000.</span>

<span class="sd">    ncandidate_samples : integer</span>
<span class="sd">        The number of samples used by the greedy downselection procedure</span>
<span class="sd">        used to determine the initial guess (set of points) for the gradient</span>
<span class="sd">        based optimization</span>

<span class="sd">    generate_random_samples : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``generate_random_samples(nsamples) -&gt; np.ndarray (nvars, nsamples)``</span>

<span class="sd">        used to generate samples needed to compute IVAR using Monte Carlo</span>
<span class="sd">        quadrature. Note even if use_gauss_quadrature is True, this function</span>
<span class="sd">        will be used (if provided) to enrich the default candidate set of the</span>
<span class="sd">        greedy method used to compute the initial guess for the gradient based</span>
<span class="sd">        optimization.</span>
<span class="sd">        If this is not None then num_candidate_samples//2 will be created</span>
<span class="sd">        by this function and the other half of samples will be from a Halton</span>
<span class="sd">        sequence.</span>

<span class="sd">    variable : :class:`pyapprox.variable.IndependentMarginalsVariable`</span>
<span class="sd">        A set of independent univariate random variables. The tensor-product</span>
<span class="sd">        of the 1D PDFs yields the joint density :math:`\rho`. The bounds and</span>
<span class="sd">        CDFs of these variables are used to transform the Halton sequence used</span>
<span class="sd">        as the candidate set for the greedy generation of the initial guess.</span>

<span class="sd">    greedy_method : string</span>
<span class="sd">        Name of the greedy strategy for computing the initial guess used</span>
<span class="sd">        for the gradient based optimization</span>

<span class="sd">    use_gauss_quadrature : boolean</span>
<span class="sd">        True - Assume the kernel is the tensor product of univariate kernels</span>
<span class="sd">               and compute integrated variance by computing a set of univariate</span>
<span class="sd">               integrals with Gaussian quadrature</span>
<span class="sd">        False - Use monte carlo quadrature to estimate integrated variance.</span>
<span class="sd">                Any kernel can be used.</span>

<span class="sd">    nugget : float</span>
<span class="sd">        A small value added to the diagonal of the kernel matrix to improve</span>
<span class="sd">        conditioning.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_vars</span><span class="p">,</span> <span class="n">nquad_samples</span><span class="p">,</span>
                 <span class="n">ncandidate_samples</span><span class="p">,</span> <span class="n">generate_random_samples</span><span class="p">,</span> <span class="n">variable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">greedy_method</span><span class="o">=</span><span class="s1">&#39;ivar&#39;</span><span class="p">,</span> <span class="n">use_gauss_quadrature</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span> <span class="o">=</span> <span class="n">num_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span> <span class="o">=</span> <span class="n">nquad_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_method</span> <span class="o">=</span> <span class="n">greedy_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span> <span class="o">=</span> <span class="n">use_gauss_quadrature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span> <span class="o">=</span> <span class="n">generate_random_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ncandidate_samples</span> <span class="o">=</span> <span class="n">ncandidate_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span> <span class="o">=</span> <span class="n">generate_random_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_optimization_options</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">&#39;gtol&#39;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;ftol&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;iprint&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_greedy_sampler</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">use_gauss_quadrature</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">precompute_gauss_quadrature</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quadrature_objective</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quadrature_objective_gradient</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">variable</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">monte_carlo_objective</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">monte_carlo_objective_gradient</span>

    <span class="k">def</span> <span class="nf">initialize_greedy_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_method</span> <span class="o">==</span> <span class="s1">&#39;chol&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span> <span class="o">=</span> <span class="n">CholeskySampler</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ncandidate_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span>
                <span class="n">generate_random_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_method</span> <span class="o">==</span> <span class="s1">&#39;ivar&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span> <span class="o">=</span> <span class="n">GreedyIntegratedVarianceSampler</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ncandidate_samples</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span>
                <span class="n">use_gauss_quadrature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">nugget</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Incorrect greedy_method </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">greedy_method</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">precompute_gauss_quadrature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">)]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">univariate_quad_rules</span> <span class="o">=</span> \
            <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quad_rules</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">univariate_quad_rules</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span><span class="n">degrees</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quad_rules</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_univariate_quadrature_rule</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ii</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">quad_rules</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">compute_P</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">length_scale</span><span class="p">):</span>
            <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">length_scale</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_univariate_quadrature_rule</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span>
            <span class="n">xtr</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernels_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span>
                <span class="n">xx_1d</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
            <span class="n">P_ii</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">)</span>
            <span class="n">P</span> <span class="o">*=</span> <span class="n">P_ii</span>
        <span class="k">return</span> <span class="n">P</span>

    <span class="k">def</span> <span class="nf">quadrature_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="p">):</span>
        <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span>
             <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span>
                 <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)])</span>
        <span class="n">A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span>

        <span class="n">A_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_P</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">quadrature_objective_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="p">):</span>
        <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span>
             <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span>
                 <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)])</span>
        <span class="n">xx</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quad_rules</span><span class="p">]</span>
        <span class="n">ww</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quad_rules</span><span class="p">]</span>
        <span class="n">new_samples_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">RBF_integrated_posterior_variance_gradient_wrt_samples</span><span class="p">(</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="n">xx</span><span class="p">,</span> <span class="n">ww</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
            <span class="n">new_samples_index</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">monte_carlo_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="p">):</span>
        <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span>
             <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span>
                 <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)])</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">gaussian_process_pointwise_variance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="p">,</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="c1"># print(&#39;f&#39;,val)</span>
        <span class="k">return</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">monte_carlo_objective_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="p">):</span>
        <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span>
             <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">new_train_samples_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span>
                 <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)])</span>
        <span class="n">new_samples_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">RBF_posterior_variance_jacobian_wrt_samples</span><span class="p">(</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
            <span class="n">new_samples_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_weight_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_function</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">set_weight_function</span><span class="p">(</span><span class="n">weight_function</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">kernels_1d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span>
                <span class="p">((</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">!=</span> <span class="n">Matern</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">nu</span><span class="p">)))):</span>
            <span class="c1"># TODO: To deal with sum kernel with noise, need to ammend</span>
            <span class="c1"># gradient computation which currently assumes no noise</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;GP Kernel type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span><span class="si">}</span><span class="s1"> &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;Only squared exponential kernel supported when &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;use_gauss_quadrature is True and nvars &gt; 1&#39;</span>
            <span class="c1"># TODO add other tensor product kernels</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">set_kernel</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">kernel</span><span class="p">),</span> <span class="n">kernels_1d</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_optimization_options</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">opts</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">variable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lbs</span><span class="p">,</span> <span class="n">ubs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">marginals</span><span class="p">()</span>
            <span class="n">lbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">]</span>
            <span class="n">ubs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">]</span>
        <span class="n">lbs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lbs</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">)</span>
        <span class="n">ubs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">ubs</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">Bounds</span><span class="p">(</span><span class="n">lbs</span><span class="p">,</span> <span class="n">ubs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>

        <span class="c1"># Remove previous training samples from candidate set to prevent</span>
        <span class="c1"># adding them twice</span>
        <span class="n">candidate_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">candidate_samples</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">candidate_samples</span><span class="p">[</span>
                <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:]</span>

        <span class="c1"># Add previous optimized sample set to candidate samples. This could</span>
        <span class="c1"># potentially add a candidate twice if the optimization picks some</span>
        <span class="c1"># of the original candidate samples chosen by</span>
        <span class="c1"># greedy_sampler.generate_samples, but this is unlikely. If it does</span>
        <span class="c1"># happen these points will never be chosen by the cholesky algorithm</span>
        <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">candidate_samples</span><span class="p">])</span>

        <span class="c1"># make sure greedy sampler recomputes all necessary information</span>
        <span class="c1"># but first extract necessary information</span>
        <span class="n">pred_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">pred_samples</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="p">,</span> <span class="s1">&#39;weight_function&#39;</span><span class="p">):</span>
            <span class="n">weight_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">weight_function</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight_function</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_greedy_sampler</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">weight_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_weight_function</span><span class="p">(</span><span class="n">weight_function</span><span class="p">)</span>
        <span class="c1"># self.greedy_sampler.candidate_samples must be called before</span>
        <span class="c1"># set kernel to make sure self.A matrix is set correctly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">candidate_samples</span>
        <span class="c1"># currently the following will no effect a different set</span>
        <span class="c1"># of prediction samples will be generated by greedy sampler when</span>
        <span class="c1"># set kernel is called</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">pred_samples</span> <span class="o">=</span> <span class="n">pred_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>

        <span class="c1"># Make sure greedy_sampler chooses self.training_samples</span>
        <span class="c1"># only used if greedy_sampler is a Choleskysampler.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="o">.</span><span class="n">set_init_pivots</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">))</span>

        <span class="c1"># Get the initial guess for new samples to add.</span>
        <span class="c1"># Note the Greedy sampler will return only new samples not in</span>
        <span class="c1"># self.training_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_guess</span><span class="p">,</span> <span class="n">chol_flag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_sampler</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_guess</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_guess</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">:]</span>
        <span class="c1"># assert np.allclose(</span>
        <span class="c1">#    self.greedy_sampler.L[:self.ntraining_samples,</span>
        <span class="c1">#                          :self.ntraining_samples],</span>
        <span class="c1">#    np.linalg.cholesky(kernel(self.training_samples.T)))</span>
        <span class="k">assert</span> <span class="n">chol_flag</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_bounds</span><span class="p">(</span><span class="n">nsamples</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">)</span>

        <span class="n">init_guess</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_guess</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
        <span class="c1"># Optimize the locations of only the new training samples</span>
        <span class="n">jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_gradient</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span> <span class="n">init_guess</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span>
                       <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optim_opts</span><span class="p">,</span>
                       <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

        <span class="n">new_samples</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span> <span class="n">new_samples</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_samples</span><span class="p">,</span> <span class="mi">0</span>


<span class="k">def</span> <span class="nf">matern_kernel_1d_inf</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">matern_kernel_1d_12</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dists</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">matern_kernel_1d_32</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="n">dists</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">tmp</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tmp</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">matern_kernel_1d_52</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">dists</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">tmp</span><span class="o">+</span><span class="n">tmp</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tmp</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">matern_kernel_general</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">dists</span><span class="p">):</span>
    <span class="n">dists</span><span class="p">[</span><span class="n">dists</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">nu</span><span class="p">)</span> <span class="o">*</span> <span class="n">dists</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tmp</span><span class="o">**</span><span class="n">nu</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">nu</span><span class="p">))</span><span class="o">/</span><span class="n">gamma</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span><span class="o">*</span><span class="n">kv</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">tmp</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">matern_kernel_1d</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lscale</span><span class="p">):</span>
    <span class="n">explicit_funcs</span> <span class="o">=</span> <span class="p">{</span><span class="mf">0.5</span><span class="p">:</span> <span class="n">matern_kernel_1d_12</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">:</span> <span class="n">matern_kernel_1d_32</span><span class="p">,</span>
                      <span class="mf">2.</span><span class="p">:</span> <span class="n">matern_kernel_1d_52</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span> <span class="n">matern_kernel_1d_inf</span><span class="p">}</span>
    <span class="n">dist_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cdist</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nu</span> <span class="ow">in</span> <span class="n">explicit_funcs</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">explicit_funcs</span><span class="p">[</span><span class="n">nu</span><span class="p">](</span><span class="n">dists</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">matern_kernel_general</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">GreedyVarianceOfMeanSampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_vars : integer</span>
<span class="sd">        The number of dimensions</span>

<span class="sd">    nquad_samples : integer</span>
<span class="sd">        The number of samples used to compute the sample based estimate</span>
<span class="sd">        of the variance of mean criteria</span>

<span class="sd">    ncandidate_samples : integer</span>
<span class="sd">        The number of samples used by the greedy downselection procedure</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_vars</span><span class="p">,</span> <span class="n">nquad_samples</span><span class="p">,</span>
                 <span class="n">ncandidate_samples</span><span class="p">,</span> <span class="n">generate_random_samples</span><span class="p">,</span> <span class="n">variable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">use_gauss_quadrature</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">compute_cond_nums</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span> <span class="o">=</span> <span class="n">num_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span> <span class="o">=</span> <span class="n">nquad_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span> <span class="o">=</span> <span class="n">generate_random_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span> <span class="o">=</span> <span class="n">use_gauss_quadrature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="o">=</span> <span class="n">econ</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">generate_gp_candidate_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="p">,</span> <span class="n">generate_random_samples</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cond_nums</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_cond_nums</span> <span class="o">=</span> <span class="n">compute_cond_nums</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># def monte_carlo_objective(self, new_sample_index):</span>
    <span class="c1">#     train_samples = np.hstack(</span>
    <span class="c1">#         [self.training_samples,</span>
    <span class="c1">#          self.candidate_samples[:, new_sample_index:new_sample_index+1]])</span>
    <span class="c1">#     return gaussian_process_pointwise_variance(</span>
    <span class="c1">#         self.kernel, self.pred_samples,</span>
    <span class="c1">#         train_samples).mean()</span>

    <span class="k">def</span> <span class="nf">precompute_monte_carlo</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Note because tau is simplified down to one integral instead of their</span>
        <span class="c1"># double used for u, it is possible for self.u - tau.dot(A_inv.dot(tau)</span>
        <span class="c1"># to be negative if tau is comptued using an inaccurate quadrature</span>
        <span class="c1"># rule. This is not important if using gauss quadrature</span>
        <span class="c1"># pred_samples2 = self.generate_random_samples(self.pred_samples.shape[1])</span>
        <span class="c1"># self.u = np.diag(</span>
        <span class="c1">#    self.kernel(self.pred_samples.T, pred_samples2.T)).mean()</span>

    <span class="k">def</span> <span class="nf">get_univariate_quadrature_rule</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ii</span><span class="p">):</span>
        <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">univariate_quad_rules</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span>

    <span class="k">def</span> <span class="nf">precompute_gauss_quadrature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">nvars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">length_scale</span><span class="p">):</span>
            <span class="n">length_scale</span> <span class="o">=</span> <span class="p">[</span><span class="n">length_scale</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">univariate_quad_rules</span> <span class="o">=</span> \
            <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="c1"># dist_func = partial(cdist, metric=&#39;sqeuclidean&#39;)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">):</span>
            <span class="c1"># Get 1D quadrature rule</span>
            <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_univariate_quadrature_rule</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span>

            <span class="c1"># Training samples of ith variable</span>
            <span class="n">xtr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">lscale_ii</span> <span class="o">=</span> <span class="n">length_scale</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
            <span class="c1"># dists_1d_x1_xtr = dist_func(</span>
            <span class="c1">#    xx_1d[:, np.newaxis]/lscale_ii, xtr.T/lscale_ii)</span>
            <span class="c1"># K = np.exp(-.5*dists_1d_x1_xtr)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span><span class="n">xx_1d</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale_ii</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*=</span> <span class="n">ww_1d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">[</span><span class="n">new_sample_index</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">tau</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">cholesky_solve_linear_system</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">tau</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">objective_vals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">mm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">:</span>
                <span class="n">obj_vals</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span>
        <span class="c1"># assert np.allclose(self.candidate_samples[:,self.pivots],self.training_samples)</span>
        <span class="c1"># if len(self.pivots)&gt;22:</span>
        <span class="c1">#     I = np.argsort(self.candidate_samples[0,:])</span>
        <span class="c1">#     plt.plot(self.candidate_samples[0,self.pivots],np.ones((len(self.pivots)))*obj_vals.min(),&#39;ko&#39;)</span>
        <span class="c1">#     plt.plot(self.candidate_samples[0,I],obj_vals[I])</span>
        <span class="c1">#     J = np.argmin(obj_vals)</span>
        <span class="c1">#     plt.plot(self.candidate_samples[0,J],obj_vals[J], &#39;rs&#39;)</span>
        <span class="c1">#     plt.show()</span>
        <span class="k">return</span> <span class="n">obj_vals</span>

    <span class="k">def</span> <span class="nf">refine_naive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">)):</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">pivot</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># ntraining_samples = self.ntraining_samples</span>
            <span class="n">obj_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_vals</span><span class="p">()</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">obj_vals</span><span class="p">)</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="p">[</span><span class="n">pivot</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span>

    <span class="k">def</span> <span class="nf">refine_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">)):</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_econ</span><span class="p">(</span><span class="n">pivot</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># training_samples = self.ntraining_samples</span>
            <span class="n">obj_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorized_objective_vals_econ</span><span class="p">()</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">obj_vals</span><span class="p">)</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="p">[</span><span class="n">pivot</span><span class="p">]</span>

        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">obj_val</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">A_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">pivot</span><span class="p">:</span><span class="n">pivot</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">L_22_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">L_22_sq</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># recompute Cholesky from scratch to make sure roundoff error</span>
                <span class="c1"># is not causing L_22_sq to be negative</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">[</span><span class="n">pivot</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)])</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

            <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">L_22_sq</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span>
                <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">L_12</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span>
                 <span class="p">[</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">L_22</span><span class="p">]])</span>

        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="n">pivot</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">y_1</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="n">pivot</span><span class="p">]]])</span>

        <span class="k">return</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span>

    <span class="k">def</span> <span class="nf">objective_vals_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">mm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">:</span>
                <span class="n">obj_vals</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_econ</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj_vals</span>

    <span class="k">def</span> <span class="nf">vectorized_objective_vals_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">diag_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diag_A</span><span class="p">)</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">diag_A</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="o">/</span><span class="n">L</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">vals</span>

        <span class="n">A_12</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">useful_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">useful_candidates</span><span class="p">[</span><span class="n">J</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">useful_candidates</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">L_12</span><span class="p">[:,</span> <span class="n">useful_candidates</span><span class="p">]</span>
        <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)[</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">y_2</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">useful_candidates</span><span class="p">]</span><span class="o">-</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_1</span><span class="p">))</span><span class="o">/</span><span class="n">L_22</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="o">~</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">z_2</span> <span class="o">=</span> <span class="n">y_2</span><span class="o">/</span><span class="n">L_22</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="n">vals</span><span class="p">[</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">useful_candidates</span><span class="p">]</span><span class="o">*</span><span class="n">z_2</span> <span class="o">-</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">L_12</span><span class="o">*</span><span class="n">z_2</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">vals</span>

    <span class="k">def</span> <span class="nf">objective_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span><span class="o">/</span><span class="n">L</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span>
                <span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">val</span>

        <span class="n">A_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">:</span><span class="n">new_sample_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="p">))</span>
        <span class="n">y_2</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span><span class="o">-</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_1</span><span class="p">))</span><span class="o">/</span><span class="n">L_22</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_y_2</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_2</span>
        <span class="n">z_2</span> <span class="o">=</span> <span class="n">y_2</span><span class="o">/</span><span class="n">L_22</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">val</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">]</span><span class="o">*</span><span class="n">z_2</span> <span class="o">-</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                    <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">L_12</span><span class="o">*</span><span class="n">z_2</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">compute_A</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">active_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">kernels_1d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kernels_1d</span> <span class="o">=</span> <span class="n">kernels_1d</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels_1d</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span><span class="p">:</span>
            <span class="c1"># TODO: remove kernels 1D and just create tensor product</span>
            <span class="c1"># kernel with this as a property.</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernels_1d</span> <span class="o">=</span> <span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">matern_kernel_1d</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span>

        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span>
                <span class="p">((</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="o">!=</span> <span class="n">Matern</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">nu</span><span class="p">)))):</span>
            <span class="c1"># TODO: To deal with sum kernel with noise, need to ammend</span>
            <span class="c1"># gradient computation which currently assumes no noise</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;GP Kernel type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span><span class="si">}</span><span class="s1"> &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;Only squared exponential kernel supported when &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;use_gauss_quadrature is True and nvars &gt; 1&#39;</span>
            <span class="c1"># TODO add other tensor product kernels</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_gauss_quadrature</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">precompute_gauss_quadrature</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">precompute_monte_carlo</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_A</span><span class="p">()</span>
        <span class="c1"># designs are better if a small nugget is added to the diagonal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_nugget</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">add_nugget</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span>

    <span class="k">def</span> <span class="nf">set_init_pivots</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_pivots</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">init_pivots</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_training_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pivot</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pivot</span><span class="p">)</span>
        <span class="c1"># new_sample = self.candidate_samples[:, pivot:pivot+1]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">[:,</span> <span class="n">pivot</span><span class="p">:</span><span class="n">pivot</span><span class="o">+</span><span class="mi">1</span><span class="p">]])</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Must call set_kernel&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refine_econ</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refine_naive</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsamples_requested</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
        <span class="n">ntraining_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span>
        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntraining_samples</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
            <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refine</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">pivot</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">flag</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">break</span>
                <span class="c1"># if self.econ is False:</span>
                <span class="c1">#     flag = 1</span>
                <span class="c1">#     break</span>
                <span class="c1"># else:</span>
                <span class="c1">#     self.econ = False</span>
                <span class="c1">#     # Switch of econ mode which struggles when condition</span>
                <span class="c1">#     # number is poor</span>
                <span class="c1">#     print(&#39;switching naive updating strategy on&#39;)</span>
                <span class="c1">#     self.refine = self.refine_naive</span>
                <span class="c1">#     pivot, obj_val = self.refine()</span>
                <span class="c1">#     if pivot &lt; 0:</span>
                <span class="c1">#         flag = 1</span>
                <span class="c1">#         break</span>
            <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iter: </span><span class="si">{</span><span class="n">nn</span><span class="si">}</span><span class="s1">, Objective: </span><span class="si">{</span><span class="n">obj_val</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_val</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">update_training_samples</span><span class="p">(</span><span class="n">pivot</span><span class="p">)</span>
            <span class="c1"># print(f&#39;Number of points generated {nn+1}&#39;)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_candidates</span><span class="p">[</span><span class="n">pivot</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cond_nums</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cond_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cond_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]))</span>
            <span class="c1"># print(np.linalg.cond(</span>
            <span class="c1">#    self.A[np.ix_(self.pivots, self.pivots)]))</span>

        <span class="n">new_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="p">[:,</span> <span class="n">ntraining_samples</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntraining_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_samples</span><span class="p">,</span> <span class="n">flag</span>


<span class="k">def</span> <span class="nf">matern_gradient_wrt_samples</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">query_sample</span><span class="p">,</span> <span class="n">other_samples</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    query_sample : np.ndarray (nvars, 1)</span>

<span class="sd">    other_samples : np.ndarray (nvars, nother_samples)</span>

<span class="sd">    length_scale : np.ndarray (nvars)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">length_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">query_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">length_scale</span><span class="p">,</span> <span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">length_scale</span><span class="p">,</span>
                  <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nu</span> <span class="o">==</span> <span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">tmp1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="n">dists</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">other_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span><span class="o">-</span><span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">tmp2</span>
    <span class="k">elif</span> <span class="n">nu</span> <span class="o">==</span> <span class="mi">5</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">tmp1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">dists</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">)</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">other_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span><span class="o">-</span><span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="o">*</span><span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">tmp2</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">dists</span><span class="o">.</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">nu</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">query_sample</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">other_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span><span class="o">-</span><span class="n">other_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">dists</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">tmp2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Matern gradient with nu=</span><span class="si">{</span><span class="n">nu</span><span class="si">}</span><span class="s1"> not supported&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad</span>


<span class="k">class</span> <span class="nc">GreedyIntegratedVarianceSampler</span><span class="p">(</span><span class="n">GreedyVarianceOfMeanSampler</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_vars : integer</span>
<span class="sd">        The number of dimensions</span>

<span class="sd">    nquad_samples : integer</span>
<span class="sd">        The number of samples used to compute the sample based estimate</span>
<span class="sd">        of the integrated variance (IVAR)</span>

<span class="sd">    ncandidate_samples : integer</span>
<span class="sd">        The number of samples used by the greedy downselection procedure</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">precompute_monte_carlo</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">)</span>
        <span class="c1"># lscale = self.kernel.length_scale</span>
        <span class="c1"># if np.isscalar(lscale):</span>
        <span class="c1">#    lscale = np.array([lscale]*self.nvars)</span>
        <span class="c1"># dist_func = partial(cdist, metric=&#39;sqeuclidean&#39;)</span>
        <span class="c1"># dists_x1_xtr = dist_func(</span>
        <span class="c1">#    self.pred_samples.T/lscale, self.candidate_samples.T/lscale)</span>
        <span class="c1"># K = np.exp(-.5*dists_x1_xtr)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">ww</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">precompute_gauss_quadrature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nquad_samples</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">length_scale</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">length_scale</span><span class="p">):</span>
            <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">length_scale</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">univariate_quad_rules</span> <span class="o">=</span> \
            <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_univariate_quadrature_rule</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span>
            <span class="n">xtr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span>
                <span class="n">xx_1d</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
            <span class="n">P_ii</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_1d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">K</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">*=</span> <span class="n">P_ii</span>

    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">[</span><span class="n">new_sample_index</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
        <span class="n">A_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
        <span class="c1"># P1=1</span>
        <span class="c1"># length_scale = self.kernel.length_scale</span>
        <span class="c1"># if np.isscalar(length_scale):</span>
        <span class="c1">#     length_scale = np.array([length_scale]*self.nvars)</span>
        <span class="c1"># for ii in range(self.nvars):</span>
        <span class="c1">#     xx_1d, ww_1d = self.get_univariate_quadrature_rule(ii)</span>
        <span class="c1">#     xtr = self.candidate_samples[ii:ii+1, indices]</span>
        <span class="c1">#     K = self.kernels_1d[ii](</span>
        <span class="c1">#         xx_1d[np.newaxis, :], xtr, length_scale[ii])</span>
        <span class="c1">#     P_ii = K.T.dot(ww_1d[:, np.newaxis]*K)</span>
        <span class="c1">#     P1*=P_ii</span>
        <span class="c1"># assert np.allclose(P, P1)</span>

        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">objective_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span>
                <span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">val</span>

        <span class="n">A_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">:</span><span class="n">new_sample_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="p">))</span>
        <span class="n">C</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">L_22</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="p">)</span>

        <span class="c1"># TODO set self.P_11 when pivot is chosen so do not constantly</span>
        <span class="c1"># have to reduce matrix</span>
        <span class="n">P_11</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]</span>
        <span class="n">P_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">:</span><span class="n">new_sample_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">P_22</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">new_sample_index</span><span class="p">,</span> <span class="n">new_sample_index</span><span class="p">]</span>

        <span class="n">val</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">*</span><span class="n">P_11</span><span class="p">)</span> <span class="o">+</span>
                <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">L_22</span><span class="o">*</span><span class="n">P_12</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">L_22</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">P_22</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">vectorized_objective_vals_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">vals</span>

        <span class="n">A_12</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">useful_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">useful_candidates</span><span class="p">[</span><span class="n">J</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">useful_candidates</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">L_12</span><span class="p">[:,</span> <span class="n">useful_candidates</span><span class="p">]</span>
        <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)[</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">L_12</span><span class="o">*</span><span class="n">L_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="n">P_11</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]</span>
        <span class="n">P_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">useful_candidates</span><span class="p">)]</span>
        <span class="n">P_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)[</span><span class="n">useful_candidates</span><span class="p">]</span>

        <span class="n">C</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">L_12</span><span class="o">/</span><span class="n">L_22</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="n">vals</span><span class="p">[</span><span class="n">useful_candidates</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span>
            <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">best_obj_vals</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="o">*</span><span class="n">P_11</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span>
            <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">L_22</span><span class="o">*</span><span class="n">P_12</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">L_22</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">P_22</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">vals</span>

    <span class="k">def</span> <span class="nf">refine_econ</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">)):</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_pivots</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">)]</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_econ</span><span class="p">(</span><span class="n">pivot</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># training_samples = self.ntraining_samples</span>
            <span class="n">obj_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorized_objective_vals_econ</span><span class="p">()</span>
            <span class="c1"># obj_vals = self.objective_vals_econ()</span>
            <span class="n">pivot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">obj_vals</span><span class="p">)</span>
            <span class="n">obj_val</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="p">[</span><span class="n">pivot</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">obj_val</span><span class="p">):</span>  <span class="c1"># or obj_val &lt; -1:</span>
            <span class="c1"># ill conditioning causes obj_val to go below -1 which should not</span>
            <span class="c1"># be possible</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span>

        <span class="n">A_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="n">pivot</span><span class="p">:</span><span class="n">pivot</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">L_12</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">A_12</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">L_22_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">L_22_sq</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># recompute Cholesky from scratch to make sure roundoff error</span>
            <span class="c1"># is not causing L_22_sq to be negative</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">[</span><span class="n">pivot</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)])</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span>

        <span class="n">L_22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">L_22_sq</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span>
            <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">L_12</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span>
             <span class="p">[</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">L_22</span><span class="p">]])</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">pivots</span><span class="p">,</span> <span class="p">[</span><span class="n">pivot</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">L_22_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">L_22</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span>
            <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">L_12</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span>
             <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_22_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_12</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="p">),</span> <span class="n">L_22_inv</span><span class="p">]])</span>

        <span class="k">return</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">obj_val</span>


<span class="k">class</span> <span class="nc">UnivariateMarginalizedGaussianProcess</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mean : float</span>
<span class="sd">        The expectation of the gaussian process with respect to the random</span>
<span class="sd">        variables. If provided then the marginalized gaussian process will</span>
<span class="sd">        the main effect used in sensitivity analysis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">L_factor</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span>
                 <span class="n">y_train_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y_train_std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="c1"># the names are chosen to match names of _gpr from sklearn</span>
        <span class="c1"># so functions can be applied to both these methods in the same way</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L_</span> <span class="o">=</span> <span class="n">L_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_inv_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">train_values</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="o">=</span> <span class="n">train_values</span>
        <span class="k">assert</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_mean</span> <span class="o">=</span> <span class="n">y_train_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_std</span> <span class="o">=</span> <span class="n">y_train_std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_K_inv</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>

    <span class="k">def</span> <span class="nf">map_to_canonical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span>

    <span class="k">def</span> <span class="nf">set_variable_transformation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="n">var_trans</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">canonical_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">K_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">K_pred</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K_inv_y</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">*</span><span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mean</span>

        <span class="n">pointwise_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">canonical_samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">K_pred</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L_inv</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pointwise_cov</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">UnivariateMarginalizedSquaredExponentialKernel</span><span class="p">(</span><span class="n">RBF</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">X_train</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">u</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="n">X_train</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># only used for prediction</span>
        <span class="n">K</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span>


<span class="k">def</span> <span class="nf">marginalize_gaussian_process</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return all 1D marginal Gaussian process obtained after excluding all</span>
<span class="sd">    but a single variable</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kernel_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">RBF</span><span class="p">,</span> <span class="n">Matern</span><span class="p">]</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="n">kernel_types</span><span class="p">)</span>

    <span class="n">constant_kernel</span> <span class="o">=</span> <span class="n">extract_covariance_kernel</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">,</span> <span class="p">[</span><span class="n">ConstantKernel</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">constant_kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kernel_var</span> <span class="o">=</span> <span class="n">constant_kernel</span><span class="o">.</span><span class="n">constant_value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">kernel_var</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Warning  extract_gaussian_process scales kernel_var by gp.y_train_std**2</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">K_inv</span><span class="p">,</span> <span class="n">kernel_length_scale</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> \
        <span class="n">transform_quad_rules</span> <span class="o">=</span> \
        <span class="n">extract_gaussian_process_attributes_for_integration</span><span class="p">(</span><span class="n">gp</span><span class="p">)</span>

    <span class="c1"># x_train = gp.X_train_.T</span>
    <span class="c1"># kernel_length_scale = kernel.length_scale</span>
    <span class="c1"># transform_quad_rules = (not hasattr(gp, &#39;var_trans&#39;))</span>
    <span class="n">L_factor</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">L_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">tau_list</span><span class="p">,</span> <span class="n">P_list</span><span class="p">,</span> <span class="n">u_list</span><span class="p">,</span> <span class="n">lamda_list</span><span class="p">,</span> <span class="n">Pi_list</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> \
        <span class="n">get_gaussian_process_squared_exponential_kernel_1d_integrals</span><span class="p">(</span>
            <span class="n">x_train</span><span class="p">,</span> <span class="n">kernel_length_scale</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span>
            <span class="n">skip_xi_1</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">center</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">A_inv</span> <span class="o">=</span> <span class="n">K_inv</span><span class="o">*</span><span class="n">kernel_var</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tau_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">A_inv_y</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)</span>
        <span class="n">shift</span> <span class="o">+=</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_mean</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">kernel_var</span> <span class="o">/=</span> <span class="nb">float</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">kernel_length_scale</span><span class="p">)</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">marginalized_gps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tau_list</span><span class="p">)[:</span><span class="n">ii</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tau_list</span><span class="p">)[</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">u_list</span><span class="p">[:</span><span class="n">ii</span><span class="p">])</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">u_list</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">kernel_var</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel_var</span><span class="o">*</span><span class="n">UnivariateMarginalizedSquaredExponentialKernel</span><span class="p">(</span>
            <span class="n">tau</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># undo kernel_var *= gp._y_train_std**2 in extact_gaussian_process_attr</span>
        <span class="n">gp_ii</span> <span class="o">=</span> <span class="n">UnivariateMarginalizedGaussianProcess</span><span class="p">(</span>
            <span class="n">kernel</span><span class="p">,</span> <span class="n">gp</span><span class="o">.</span><span class="n">X_train_</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">L_factor</span><span class="p">,</span> <span class="n">gp</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span>
            <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_mean</span><span class="p">,</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_std</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">shift</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="s1">&#39;var_trans&#39;</span><span class="p">):</span>
            <span class="n">variable_ii</span> <span class="o">=</span> <span class="n">IndependentMarginalsVariable</span><span class="p">(</span>
                <span class="p">[</span><span class="n">gp</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">marginals</span><span class="p">()[</span><span class="n">ii</span><span class="p">]])</span>
            <span class="n">var_trans_ii</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable_ii</span><span class="p">)</span>
            <span class="n">gp_ii</span><span class="o">.</span><span class="n">set_variable_transformation</span><span class="p">(</span><span class="n">var_trans_ii</span><span class="p">)</span>
        <span class="n">marginalized_gps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gp_ii</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">marginalized_gps</span>


<span class="k">def</span> <span class="nf">compute_conditional_P</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale_ii</span><span class="p">):</span>
    <span class="c1"># Get 2D tensor product quadrature rule</span>
    <span class="n">xx_2d</span> <span class="o">=</span> <span class="n">cartesian_product</span><span class="p">([</span><span class="n">xx_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ww_2d</span> <span class="o">=</span> <span class="n">outer_product</span><span class="p">([</span><span class="n">ww_1d</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># ntrain_samples = xtr.shape[1]</span>
    <span class="n">dist_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cdist</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
    <span class="n">dists_2d_x2_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">,</span> <span class="n">xtr</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span>
    <span class="n">dists_2d_x1_xtr</span> <span class="o">=</span> <span class="n">dist_func</span><span class="p">(</span><span class="n">xx_2d</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">,</span> <span class="n">xtr</span><span class="o">.</span><span class="n">T</span><span class="o">/</span><span class="n">lscale_ii</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x1_xtr</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ww_2d</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">.5</span><span class="o">*</span><span class="n">dists_2d_x2_xtr</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">P</span>


<span class="k">def</span> <span class="nf">compute_expected_sobol_indices</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">interaction_terms</span><span class="p">,</span>
                                   <span class="n">nquad_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The alpha regularization parameter used to construct the gp stored</span>
<span class="sd">    in gp.alpha can significantly impact condition number of A_inv</span>
<span class="sd">    and thus the accuracy that can be obtained in estimates of integrals</span>
<span class="sd">    particularly associated with variance. However setting alpha too large</span>
<span class="sd">    will also limit the accuracy that can be achieved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">K_inv</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">transform_quad_rules</span> <span class="o">=</span> \
        <span class="n">extract_gaussian_process_attributes_for_integration</span><span class="p">(</span><span class="n">gp</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_compute_expected_sobol_indices</span><span class="p">(</span>
        <span class="n">gp</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">interaction_terms</span><span class="p">,</span> <span class="n">nquad_samples</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
        <span class="n">K_inv</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span> <span class="n">gp</span><span class="o">.</span><span class="n">_y_train_mean</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">_compute_expected_sobol_indices</span><span class="p">(</span>
        <span class="n">gp</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">interaction_terms</span><span class="p">,</span> <span class="n">nquad_samples</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
        <span class="n">K_inv</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span> <span class="n">y_train_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">y_train_mean</span><span class="p">)</span> <span class="ow">or</span> <span class="n">y_train_mean</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="n">tau_list</span><span class="p">,</span> <span class="n">P_list</span><span class="p">,</span> <span class="n">u_list</span><span class="p">,</span> <span class="n">lamda_list</span><span class="p">,</span> <span class="n">Pi_list</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> \
        <span class="n">get_gaussian_process_squared_exponential_kernel_1d_integrals</span><span class="p">(</span>
            <span class="n">x_train</span><span class="p">,</span> <span class="n">lscale</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">transform_quad_rules</span><span class="p">,</span>
            <span class="n">nquad_samples</span><span class="o">=</span><span class="n">nquad_samples</span><span class="p">,</span> <span class="n">skip_xi_1</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">lscale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">lscale</span><span class="p">)</span>  <span class="c1"># for 1D gps</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="n">nquad_samples</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>
    <span class="n">univariate_quad_rules</span> <span class="o">=</span> <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
        <span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

    <span class="n">P_mod_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="c1"># Training samples of ith variable</span>
        <span class="n">xtr</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span> <span class="o">=</span> <span class="n">univariate_quad_rules</span><span class="p">[</span><span class="n">ii</span><span class="p">](</span><span class="n">degrees</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transform_quad_rules</span><span class="p">:</span>
            <span class="n">xx_1d</span> <span class="o">=</span> <span class="n">var_trans</span><span class="o">.</span><span class="n">map_from_canonical_1d</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ii</span><span class="p">)</span>
        <span class="n">P_mod_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compute_conditional_P</span><span class="p">(</span><span class="n">xx_1d</span><span class="p">,</span> <span class="n">ww_1d</span><span class="p">,</span> <span class="n">xtr</span><span class="p">,</span> <span class="n">lscale</span><span class="p">[</span><span class="n">ii</span><span class="p">]))</span>

    <span class="n">cond_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">K_inv</span><span class="p">)</span>
    <span class="c1"># print(&quot;Kernel log10 Cond Num&quot;, np.log10(cond_num))</span>
    <span class="k">if</span> <span class="n">cond_num</span> <span class="o">&gt;</span> <span class="mf">1e11</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Condition number of kernel matrix is to high.&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; Log10 condition number is </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">cond_num</span><span class="p">)</span><span class="si">}</span><span class="s2">. &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Increase alpha&quot;</span>
        <span class="c1"># raise RuntimeError(msg)</span>

    <span class="n">A_inv</span> <span class="o">=</span> <span class="n">K_inv</span><span class="o">*</span><span class="n">kernel_var</span>
    <span class="c1"># print(&#39;cond num&#39;, np.linalg.cond(A_inv))</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tau_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">varpi</span> <span class="o">=</span> <span class="n">compute_varpi</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">A_inv</span><span class="p">)</span>
    <span class="n">varsigma_sq</span> <span class="o">=</span> <span class="n">compute_varsigma_sq</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">varpi</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">P_list</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">A_inv_P</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">v_sq</span> <span class="o">=</span> <span class="n">compute_v_sq</span><span class="p">(</span><span class="n">A_inv</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>

    <span class="n">A_inv_y</span> <span class="o">=</span> <span class="n">A_inv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">expected_random_mean</span> <span class="o">=</span> <span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">)</span>
    <span class="n">expected_random_mean</span> <span class="o">+=</span> <span class="n">y_train_mean</span>
    <span class="n">variance_random_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">expected_random_mean</span><span class="p">)</span>
    <span class="n">expected_random_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">expected_random_mean</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">variance_random_mean</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">variance_of_mean</span><span class="p">(</span><span class="n">kernel_var</span><span class="p">,</span> <span class="n">varsigma_sq</span><span class="p">)</span>
        <span class="n">zeta_ii</span> <span class="o">=</span> <span class="n">compute_zeta_econ</span><span class="p">(</span>
            <span class="n">y_train</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">A_inv_y</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">A_inv_P</span><span class="p">)</span>
        <span class="n">zeta_ii</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">y_train_mean</span><span class="o">+</span><span class="n">y_train_mean</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">expected_random_var</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_of_variance</span><span class="p">(</span>
            <span class="n">zeta_ii</span><span class="p">,</span> <span class="n">v_sq</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">expected_random_mean</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span>
            <span class="n">variance_random_mean</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>

    <span class="k">assert</span> <span class="n">interaction_terms</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="c1"># add indices need to compute main effects. These may already be</span>
    <span class="c1"># in interaction terms but cost of recomputing them is negligible</span>
    <span class="c1"># and avoids extra book keeping</span>
    <span class="n">total_effect_interaction_terms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">nvars</span><span class="p">,</span> <span class="n">nvars</span><span class="p">))</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nvars</span><span class="p">)</span>
    <span class="n">myinteraction_terms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">interaction_terms</span><span class="p">,</span> <span class="n">total_effect_interaction_terms</span><span class="p">))</span>
    <span class="n">unnormalized_interaction_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="p">(</span><span class="n">myinteraction_terms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">myinteraction_terms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">myinteraction_terms</span><span class="p">[:,</span> <span class="n">jj</span><span class="p">]</span>
        <span class="n">P_p</span><span class="p">,</span> <span class="n">U_p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">index</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">P_p</span> <span class="o">*=</span> <span class="n">P_list</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
                <span class="n">U_p</span> <span class="o">*=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">P_p</span> <span class="o">*=</span> <span class="n">P_mod_list</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
                <span class="n">U_p</span> <span class="o">*=</span> <span class="n">u_list</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
        <span class="n">trace_A_inv_Pp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_inv</span><span class="o">*</span><span class="n">P_p</span><span class="p">)</span>  <span class="c1"># U_p-np.trace(A_inv.dot(P_p))</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">v_sq_ii</span> <span class="o">=</span> <span class="n">U_p</span><span class="o">-</span><span class="n">trace_A_inv_Pp</span>
            <span class="n">zeta_ii</span> <span class="o">=</span> <span class="n">A_inv_y</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P_p</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">zeta_ii</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">tau</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_inv_y</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">y_train_mean</span> <span class="o">+</span>\
                <span class="n">y_train_mean</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">unnormalized_interaction_values</span><span class="p">[</span><span class="n">jj</span><span class="p">,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_of_variance</span><span class="p">(</span>
                <span class="n">zeta_ii</span><span class="p">,</span> <span class="n">v_sq_ii</span><span class="p">,</span> <span class="n">kernel_var</span><span class="p">,</span> <span class="n">expected_random_mean</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span>
                <span class="n">variance_random_mean</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
    <span class="n">unnormalized_total_effect_values</span> <span class="o">=</span> \
        <span class="n">unnormalized_interaction_values</span><span class="p">[</span><span class="n">interaction_terms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>
    <span class="n">unnormalized_interaction_values</span> <span class="o">=</span> \
        <span class="n">unnormalized_interaction_values</span><span class="p">[:</span><span class="n">interaction_terms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

    <span class="n">II</span> <span class="o">=</span> <span class="n">argsort_indices_leixographically</span><span class="p">(</span><span class="n">interaction_terms</span><span class="p">)</span>
    <span class="n">unnormalized_sobol_indices</span> <span class="o">=</span> <span class="n">unnormalized_interaction_values</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">sobol_indices_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">II</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">interaction_terms</span><span class="p">[:,</span> <span class="n">II</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span>
        <span class="n">active_vars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">nactive_vars</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">sobol_indices_dict</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">active_vars</span><span class="p">)]</span> <span class="o">=</span> <span class="n">II</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">nactive_vars</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_vars</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="n">active_vars</span><span class="p">,</span> <span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
                    <span class="n">unnormalized_sobol_indices</span><span class="p">[</span><span class="n">II</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span> <span class="o">-=</span> \
                        <span class="n">unnormalized_sobol_indices</span><span class="p">[</span><span class="n">sobol_indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span>

    <span class="c1"># print(unnormalized_sobol_indices.shape)</span>
    <span class="c1"># print(np.sum(unnormalized_sobol_indices, axis=0))</span>
    <span class="c1"># print(expected_random_var)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">unnormalized_sobol_indices</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Some Sobol indices were negative. &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Likely due to ill conditioning &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;of GP kernel. Try increaseing alpha&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">expected_random_var</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Some expected variances were negative. &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Likely due to ill conditioning &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;of GP kernel. Samlpes used to generate GP realization &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;are likely ill conditioned. Try increasing alpha &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;(not used to fit gp) but used to generate realizations&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;or reduce ninterpolation_samples&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">unnormalized_sobol_indices</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">expected_random_var</span><span class="o">+</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;relative max diff&#39;</span><span class="p">,</span>
              <span class="p">((</span><span class="n">unnormalized_sobol_indices</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">expected_random_var</span><span class="p">)</span><span class="o">/</span>
               <span class="n">expected_random_var</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Some Sobol indices were larger than the variance. &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Likely due to ill conditioning &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;of GP kernel. Samlpes used to generate GP realization &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;are likely ill conditioned. Try increasing alpha &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;(not used to fit gp) but used to generate realizations&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;or reduce ninterpolation_samples&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># import warnings</span>
        <span class="c1"># warnings.warn(msg)</span>

    <span class="n">total_effect_indices</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">1</span><span class="o">-</span><span class="n">unnormalized_total_effect_values</span><span class="o">/</span><span class="n">expected_random_var</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">total_effect_indices</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;relative max diff&#39;</span><span class="p">,</span>
              <span class="p">((</span><span class="n">unnormalized_total_effect_values</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span>
                <span class="n">expected_random_var</span><span class="p">)</span><span class="o">/</span><span class="n">expected_random_var</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">total_effect_indices</span><span class="p">)</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Some total effect values were negative. &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Likely due to ill conditioning &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;of GP kernel. Samlpes used to generate GP realization &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;are likely ill conditioned. Try increasing alpha &quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;(not used to fit gp) but used to generate realizations&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;or reduce ninterpolation_samples&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># import warnings</span>
        <span class="c1"># warnings.warn(msg)</span>

    <span class="k">return</span> <span class="n">unnormalized_sobol_indices</span><span class="o">/</span><span class="n">expected_random_var</span><span class="p">,</span> \
        <span class="n">total_effect_indices</span><span class="p">,</span> \
        <span class="n">expected_random_mean</span><span class="p">,</span> <span class="n">expected_random_var</span>


<span class="k">def</span> <span class="nf">generate_gp_realizations</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">ngp_realizations</span><span class="p">,</span> <span class="n">ninterpolation_samples</span><span class="p">,</span>
                             <span class="n">nvalidation_samples</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="p">,</span>
                             <span class="n">variable</span><span class="p">,</span> <span class="n">use_cholesky</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">rand_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">ngp_realizations</span><span class="p">,</span> <span class="n">ninterpolation_samples</span><span class="o">+</span><span class="n">nvalidation_samples</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
    <span class="n">gp_realizations</span> <span class="o">=</span> <span class="n">RandomGaussianProcessRealizations</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">use_cholesky</span><span class="p">,</span>
                                                        <span class="n">alpha</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_cholesky</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">generate_random_samples</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">generate_independent_random_samples</span><span class="p">,</span> <span class="n">variable</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">generate_random_samples</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="kn">from</span> <span class="nn">pyapprox.surrogates.gaussianprocess.gaussian_process</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">generate_gp_candidate_samples</span><span class="p">)</span>
    <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">generate_gp_candidate_samples</span><span class="p">(</span>
        <span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">ncandidate_samples</span><span class="p">,</span> <span class="n">generate_random_samples</span><span class="p">,</span>
        <span class="n">variable</span><span class="p">)</span>
    <span class="n">gp_realizations</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">candidate_samples</span><span class="p">,</span> <span class="n">rand_noise</span><span class="p">,</span> <span class="n">ninterpolation_samples</span><span class="p">,</span>
        <span class="n">nvalidation_samples</span><span class="p">,</span> <span class="n">verbosity</span><span class="p">)</span>
    <span class="n">fun</span> <span class="o">=</span> <span class="n">gp_realizations</span>
    <span class="k">return</span> <span class="n">fun</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>