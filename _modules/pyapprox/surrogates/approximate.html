<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyapprox.surrogates.approximate &mdash; PyApprox 1.0.2 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            PyApprox
              <img src="../../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Software Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pyapprox.surrogates.approximate</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyapprox.surrogates.approximate</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">OptimizeResult</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">LinAlgWarning</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LassoCV</span><span class="p">,</span> <span class="n">LassoLarsCV</span><span class="p">,</span> <span class="n">LarsCV</span><span class="p">,</span> <span class="n">OrthogonalMatchingPursuitCV</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span>
    <span class="n">LassoLars</span><span class="p">,</span> <span class="n">Lars</span><span class="p">,</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">ConvergenceWarning</span>
<span class="kn">from</span> <span class="nn">sklearn.utils._testing</span> <span class="kn">import</span> <span class="n">ignore_warnings</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model._base</span> <span class="kn">import</span> <span class="n">LinearModel</span>

<span class="kn">from</span> <span class="nn">pyapprox.util.utilities</span> <span class="kn">import</span> <span class="n">hash_array</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.indexing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_forward_neighbor</span><span class="p">,</span> <span class="n">get_backward_neighbor</span><span class="p">,</span>
    <span class="n">compute_hyperbolic_indices</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.sampling</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">generate_independent_random_samples</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.polychaos.adaptive_polynomial_chaos</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AdaptiveLejaPCE</span><span class="p">,</span> <span class="n">variance_pce_refinement_indicator</span><span class="p">,</span> <span class="n">AdaptiveInducedPCE</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.orthopoly.leja_sequences</span> <span class="kn">import</span> <span class="n">christoffel_weights</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.marginals</span> <span class="kn">import</span> <span class="n">is_bounded_continuous_variable</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.adaptive_sparse_grid</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">variance_refinement_indicator</span><span class="p">,</span>
    <span class="n">CombinationSparseGrid</span><span class="p">,</span> <span class="n">constant_increment_growth_rule</span><span class="p">,</span>
    <span class="n">get_sparse_grid_univariate_leja_quadrature_rules_economical</span><span class="p">,</span>
    <span class="n">max_level_admissibility_function</span><span class="p">,</span> <span class="n">get_unique_max_level_1d</span><span class="p">,</span>
    <span class="n">get_unique_quadrule_variables</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.joint</span> <span class="kn">import</span> <span class="n">IndependentMarginalsVariable</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AffineTransform</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.expdesign.low_discrepancy_sequences</span> <span class="kn">import</span> <span class="n">halton_sequence</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.gaussianprocess.gaussian_process</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AdaptiveGaussianProcess</span><span class="p">,</span> <span class="n">CholeskySampler</span><span class="p">,</span> <span class="n">GaussianProcess</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.gaussianprocess.kernels</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Matern</span><span class="p">,</span> <span class="n">WhiteKernel</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.polychaos.gpc</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">PolynomialChaosExpansion</span><span class="p">,</span> <span class="n">define_poly_options_from_variable_transformation</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.neural_networks</span> <span class="kn">import</span> <span class="n">NeuralNetwork</span>


<span class="k">class</span> <span class="nc">ApproximateResult</span><span class="p">(</span><span class="n">OptimizeResult</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_sparse_grid</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refinement_indicator</span><span class="o">=</span><span class="n">variance_refinement_indicator</span><span class="p">,</span>
        <span class="n">univariate_quad_rule_info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">config_variables_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config_var_trans</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cost_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_level_1d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_level</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">basis_type</span><span class="o">=</span><span class="s2">&quot;barycentric&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a sparse grid approximation of a function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun : callable</span>
<span class="sd">        The function to be approximated</span>

<span class="sd">        ``fun(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shape (nsamples,nqoi)</span>

<span class="sd">    variables : IndependentMarginalsVariable</span>
<span class="sd">        A set of independent univariate random variables</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Function called after each iteration with the signature</span>

<span class="sd">        ``callback(approx_k)``</span>

<span class="sd">        where approx_k is the current approximation object.</span>

<span class="sd">    refinement_indicator : callable</span>
<span class="sd">        A function that retuns an estimate of the error of a sparse grid</span>
<span class="sd">        subspace with signature</span>

<span class="sd">        ``refinement_indicator(subspace_index,nnew_subspace_samples,sparse_grid) -&gt; float, float``</span>

<span class="sd">        where ``subspace_index`` is 1D np.ndarray of size (nvars),</span>
<span class="sd">        ``nnew_subspace_samples`` is an integer specifying the number</span>
<span class="sd">        of new samples that will be added to the sparse grid by adding the</span>
<span class="sd">        subspace specified by subspace_index and ``sparse_grid`` is the current</span>
<span class="sd">        :class:`pyapprox.adaptive_sparse_grid.CombinationSparseGrid` object.</span>
<span class="sd">        The two outputs are, respectively, the indicator used to control</span>
<span class="sd">        refinement of the sparse grid and the change in error from adding the</span>
<span class="sd">        current subspace. The indicator is typically but now always dependent</span>
<span class="sd">        on the error.</span>

<span class="sd">    univariate_quad_rule_info : list</span>
<span class="sd">        List containing four entries. The first entry is a list</span>
<span class="sd">        (or single callable) of univariate quadrature rules for each variable</span>
<span class="sd">        with signature</span>

<span class="sd">        ``quad_rule(l)-&gt;np.ndarray,np.ndarray``</span>

<span class="sd">        where the integer ``l`` specifies the level of the quadrature rule and</span>
<span class="sd">        ``x`` and ``w`` are 1D np.ndarray of size (nsamples) containing the</span>
<span class="sd">        quadrature rule points and weights, respectively.</span>

<span class="sd">        The second entry is a list (or single callable) of growth rules</span>
<span class="sd">        with signature</span>

<span class="sd">        ``growth_rule(l)-&gt;integer``</span>

<span class="sd">        where the output ``nsamples`` specifies the number of samples in the</span>
<span class="sd">        quadrature rule of level ``l``.</span>

<span class="sd">        If either entry is a callable then the same quad or growth rule is</span>
<span class="sd">        applied to every variable.</span>

<span class="sd">        The third entry is a list of np.ndarray (or single scalar) specifying</span>
<span class="sd">        the variable dimensions that each unique quadrature rule is applied to.</span>

<span class="sd">        The forth entry is a list which specifies the maximum level of each</span>
<span class="sd">        unique quadrature rule. If None then max_level is assumed to be np.inf</span>
<span class="sd">        for each quadrature rule. If a scalar then the same value is applied</span>
<span class="sd">        to all quadrature rules. This entry is useful for certain quadrature</span>
<span class="sd">        rules, e.g. Gauss Patterson, or Leja sequences for bounded discrete</span>
<span class="sd">        variables where there is a limit on the number of levels that can be</span>
<span class="sd">        used</span>

<span class="sd">    max_nsamples : float</span>
<span class="sd">        If ``cost_function==None`` then this argument is the maximum number of</span>
<span class="sd">        evaluations of fun. If fun has configure variables</span>

<span class="sd">        If ``cost_function!=None`` Then max_nsamples is the maximum cost of</span>
<span class="sd">        constructing the sparse grid, i.e. the sum of the cost of evaluating</span>
<span class="sd">        each point in the sparse grid.</span>

<span class="sd">        The ``cost_function!=None` same behavior as ``cost_function==None``</span>
<span class="sd">        can be obtained by setting cost_function = lambda config_sample: 1.</span>

<span class="sd">        This is particularly useful if ``fun`` has configure variables</span>
<span class="sd">        and evaluating ``fun`` at these different values of these configure</span>
<span class="sd">        variables has different cost. For example if there is one configure</span>
<span class="sd">        variable that can take two different values with cost 0.5, and 1</span>
<span class="sd">        then 10 samples of both models will be measured as 15 samples and</span>
<span class="sd">        so if max_nsamples is 19 the algorithm will not terminate because</span>
<span class="sd">        even though the number of samples is the sparse grid is 20.</span>

<span class="sd">    tol : float</span>
<span class="sd">        Tolerance for termination. The construction of the sparse grid is</span>
<span class="sd">        terminated when the estimate error in the sparse grid (determined by</span>
<span class="sd">        ``refinement_indicator`` is below tol.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls messages printed during construction.</span>

<span class="sd">    config_variable_idx : integer</span>
<span class="sd">        The position in a sample array that the configure variables start</span>

<span class="sd">    config_var_trans : pyapprox.adaptive_sparse_grid.ConfigureVariableTransformation</span>
<span class="sd">        An object that takes configure indices in [0,1,2,3...]</span>
<span class="sd">        and maps them to the configure values accepted by ``fun``</span>

<span class="sd">    cost_function : callable</span>
<span class="sd">        A function with signature</span>

<span class="sd">        ``cost_function(config_sample) -&gt; float``</span>

<span class="sd">        where config_sample is a np.ndarray of shape (nconfig_vars). The output</span>
<span class="sd">        is the cost of evaluating ``fun`` at ``config_sample``. The units can</span>
<span class="sd">        be anything but the units must be consistent with the units of</span>
<span class="sd">        max_nsamples which specifies the maximum cost of constructing the</span>
<span class="sd">        sparse grid.</span>

<span class="sd">    max_level_1d : np.ndarray (nvars)</span>
<span class="sd">        The maximum level of the sparse grid in each dimension. If None</span>
<span class="sd">        There is no limit</span>

<span class="sd">    max_level : integer</span>
<span class="sd">        The maximum level l of the sparse grid. Only subspaces with indices</span>
<span class="sd">        i that satisfy : math:`\lvert i \rvert_1\le l` can be added. If None</span>
<span class="sd">        l=np.inf</span>

<span class="sd">    basis_type : string (default=&quot;barycentric&quot;)</span>
<span class="sd">        Specify the basis type to use. Currently the same basis must be used</span>
<span class="sd">        for all dimensions. Options &quot;barycentric&quot;, &quot;linear&quot;, &quot;quadratic&quot;</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx : :class:`pyapprox.adaptive_sparse_grid.CombinationSparseGrid`</span>
<span class="sd">        The sparse grid approximation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">var_trans</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">config_var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nvars</span> <span class="o">+=</span> <span class="n">config_var_trans</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">sparse_grid</span> <span class="o">=</span> <span class="n">CombinationSparseGrid</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">basis_type</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">max_level_1d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_level_1d</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">max_level_1d</span><span class="p">):</span>
        <span class="n">max_level_1d</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_level_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>

    <span class="k">if</span> <span class="n">max_level</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_level</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">if</span> <span class="n">univariate_quad_rule_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">quad_rules</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span> <span class="n">unique_quadrule_indices</span><span class="p">,</span> \
            <span class="n">unique_max_level_1d</span> <span class="o">=</span> \
            <span class="n">get_sparse_grid_univariate_leja_quadrature_rules_economical</span><span class="p">(</span>
                <span class="n">var_trans</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span><span class="p">)</span>
        <span class="c1"># Some quadrature rules have max_level enforce this here</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_quadrule_indices</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">unique_quadrule_indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]:</span>
                <span class="n">max_level_1d</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                    <span class="n">max_level_1d</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">unique_max_level_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">quad_rules</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span> <span class="n">unique_quadrule_indices</span><span class="p">,</span> \
            <span class="n">unique_max_level_1d</span> <span class="o">=</span> <span class="n">univariate_quad_rule_info</span>
        <span class="k">if</span> <span class="n">unique_max_level_1d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_level_1d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span><span class="p">,</span> <span class="n">max_level_1d</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">unique_max_level_1d</span><span class="p">):</span>
            <span class="n">max_level_1d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span>
                <span class="p">[</span><span class="n">unique_max_level_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span><span class="p">,</span> <span class="n">max_level_1d</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nunique_vars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">quad_rules</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_max_level_1d</span><span class="p">)</span> <span class="o">==</span> <span class="n">nunique_vars</span>
            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nunique_vars</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">unique_quadrule_indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]:</span>
                    <span class="n">max_level_1d</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span>
                        <span class="n">unique_max_level_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">max_level_1d</span><span class="p">[</span><span class="n">jj</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">config_var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">cv</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">config_var_trans</span><span class="o">.</span><span class="n">config_values</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_level_1d</span><span class="p">[</span><span class="n">config_variables_idx</span><span class="o">+</span><span class="n">ii</span><span class="p">]:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;maxlevel_1d </span><span class="si">{</span><span class="n">max_level_1d</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;config_var_trans.config_values with shapes </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config_var_trans</span><span class="o">.</span><span class="n">config_values</span><span class="p">])</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot; are inconsistent.&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">max_level_1d</span><span class="p">)</span> <span class="o">==</span> <span class="n">nvars</span>
    <span class="c1"># todo change np.inf to argument that is passed into approximate</span>
    <span class="n">admissibility_function</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">max_level_admissibility_function</span><span class="p">,</span> <span class="n">max_level</span><span class="p">,</span> <span class="n">max_level_1d</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    <span class="n">sparse_grid</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">config_variables_idx</span><span class="p">,</span> <span class="n">refinement_indicator</span><span class="p">,</span>
        <span class="n">admissibility_function</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span> <span class="n">quad_rules</span><span class="p">,</span>
        <span class="n">var_trans</span><span class="p">,</span> <span class="n">unique_quadrule_indices</span><span class="o">=</span><span class="n">unique_quadrule_indices</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">cost_function</span><span class="o">=</span><span class="n">cost_function</span><span class="p">,</span>
        <span class="n">config_var_trans</span><span class="o">=</span><span class="n">config_var_trans</span><span class="p">)</span>
    <span class="n">sparse_grid</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">sparse_grid</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_polynomial_chaos</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;leja&quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{}):</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;leja&quot;</span><span class="p">:</span> <span class="n">adaptive_approximate_polynomial_chaos_leja</span><span class="p">,</span>
               <span class="s2">&quot;induced&quot;</span><span class="p">:</span> <span class="n">adaptive_approximate_polynomial_chaos_induced</span><span class="p">}</span>
    <span class="c1"># &quot;random&quot;: adaptive_approximate_polynomial_chaos_random}</span>

    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Method </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s1"> not found.</span><span class="se">\n</span><span class="s1"> Available methods are:</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">methods</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="n">methods</span><span class="p">[</span><span class="n">method</span><span class="p">](</span><span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">__initialize_leja_pce</span><span class="p">(</span>
        <span class="n">variables</span><span class="p">,</span> <span class="n">generate_candidate_samples</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">rv</span> <span class="ow">in</span> <span class="n">variables</span><span class="o">.</span><span class="n">marginals</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_bounded_continuous_variable</span><span class="p">(</span><span class="n">rv</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;For now leja sampling based PCE is only supported for &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot; bounded continouous random variables when&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot; generate_candidate_samples is not provided.&quot;</span>
            <span class="k">if</span> <span class="n">generate_candidate_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">nvars</span> <span class="o">=</span> <span class="n">variables</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">generate_candidate_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Todo implement default for non-bounded variables that uses induced</span>
        <span class="c1"># sampling</span>
        <span class="c1"># candidate samples must be in canonical domain</span>
        <span class="n">candidate_samples</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">halton_sequence</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">ncandidate_samples</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># candidate_samples = -np.cos(</span>
        <span class="c1">#    np.random.uniform(0,np.pi,(nvars,int(ncandidate_samples))))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">candidate_samples</span> <span class="o">=</span> <span class="n">generate_candidate_samples</span><span class="p">(</span><span class="n">ncandidate_samples</span><span class="p">)</span>

    <span class="n">pce</span> <span class="o">=</span> <span class="n">AdaptiveLejaPCE</span><span class="p">(</span>
        <span class="n">nvars</span><span class="p">,</span> <span class="n">candidate_samples</span><span class="p">,</span> <span class="n">factorization_type</span><span class="o">=</span><span class="s1">&#39;fast&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pce</span>


<span class="k">def</span> <span class="nf">__setup_adaptive_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span>
                         <span class="n">refinement_indicator</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span> <span class="n">callback</span><span class="p">,</span>
                         <span class="n">max_level_1d</span><span class="p">):</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_function</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">growth_rules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">growth_incr</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">growth_rules</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">constant_increment_growth_rule</span><span class="p">,</span> <span class="n">growth_incr</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">callable</span><span class="p">(</span><span class="n">growth_rules</span><span class="p">)</span>
    <span class="n">unique_quadrule_variables</span><span class="p">,</span> <span class="n">unique_quadrule_indices</span> <span class="o">=</span> \
        <span class="n">get_unique_quadrule_variables</span><span class="p">(</span><span class="n">var_trans</span><span class="p">)</span>
    <span class="n">growth_rules</span> <span class="o">=</span> <span class="p">[</span><span class="n">growth_rules</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_quadrule_indices</span><span class="p">)</span>

    <span class="n">admissibility_function</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># provide after growth_rules have been added</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_refinement_functions</span><span class="p">(</span>
        <span class="n">refinement_indicator</span><span class="p">,</span> <span class="n">admissibility_function</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span>
        <span class="n">unique_quadrule_indices</span><span class="o">=</span><span class="n">unique_quadrule_indices</span><span class="p">)</span>

    <span class="n">nvars</span> <span class="o">=</span> <span class="n">var_trans</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">max_level_1d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_level_1d</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">max_level_1d</span><span class="p">):</span>
        <span class="n">max_level_1d</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_level_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span>

    <span class="n">unique_max_level_1d</span> <span class="o">=</span> <span class="n">get_unique_max_level_1d</span><span class="p">(</span>
        <span class="n">var_trans</span><span class="p">,</span> <span class="n">pce</span><span class="o">.</span><span class="n">compact_univariate_growth_rule</span><span class="p">)</span>
    <span class="n">nunique_vars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_quadrule_indices</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_max_level_1d</span><span class="p">)</span> <span class="o">==</span> <span class="n">nunique_vars</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nunique_vars</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">unique_quadrule_indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]:</span>
            <span class="n">max_level_1d</span><span class="p">[</span><span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span>
                <span class="n">unique_max_level_1d</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">max_level_1d</span><span class="p">[</span><span class="n">jj</span><span class="p">])</span>

    <span class="n">admissibility_function</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">max_level_admissibility_function</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">max_level_1d</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">admissibility_function</span> <span class="o">=</span> <span class="n">admissibility_function</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_polynomial_chaos_induced</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span>
        <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refinement_indicator</span><span class="o">=</span><span class="n">variance_pce_refinement_indicator</span><span class="p">,</span>
        <span class="n">growth_rules</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">max_level_1d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">induced_sampling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cond_tol</span><span class="o">=</span><span class="mf">1e6</span><span class="p">,</span>
        <span class="n">fit_opts</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;omp_tol&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute an adaptive Polynomial Chaos Expansion of a function based upon</span>
<span class="sd">    random induced or probability measure sampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun : callable</span>
<span class="sd">        The function to be minimized</span>

<span class="sd">        ``fun(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shape (nsamples,nqoi)</span>

<span class="sd">    variables : IndependentMarginalsVariable</span>
<span class="sd">        A set of independent univariate random variables</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Function called after each iteration with the signature</span>

<span class="sd">        ``callback(approx_k)``</span>

<span class="sd">        where approx_k is the current approximation object.</span>

<span class="sd">    refinement_indicator : callable</span>
<span class="sd">        A function that retuns an estimate of the error of a sparse grid</span>
<span class="sd">        subspace with signature</span>

<span class="sd">        ``refinement_indicator(subspace_index,nnew_subspace_samples,sparse_grid) -&gt; float, float``</span>

<span class="sd">        where ``subspace_index`` is 1D np.ndarray of size (nvars),</span>
<span class="sd">        ``nnew_subspace_samples`` is an integer specifying the number</span>

<span class="sd">        of new samples that will be added to the sparse grid by adding the</span>
<span class="sd">        subspace specified by subspace_index and ``sparse_grid`` is the current</span>
<span class="sd">        :class:`pyapprox.adaptive_sparse_grid.CombinationSparseGrid` object.</span>
<span class="sd">        The two outputs are, respectively, the indicator used to control</span>
<span class="sd">        refinement of the sparse grid and the change in error from adding the</span>
<span class="sd">        current subspace. The indicator is typically but now always dependent</span>
<span class="sd">        on the error.</span>

<span class="sd">    growth_rules : list or callable</span>
<span class="sd">        a list (or single callable) of growth rules with signature</span>

<span class="sd">        ``growth_rule(l)-&gt;integer``</span>

<span class="sd">        where the output ``nsamples`` specifies the number of indices of the</span>
<span class="sd">        univariate basis of level ``l``.</span>

<span class="sd">        If the entry is a callable then the same growth rule is</span>
<span class="sd">        applied to every variable.</span>

<span class="sd">    max_nsamples : integer</span>
<span class="sd">        The maximum number of evaluations of fun.</span>

<span class="sd">    tol : float</span>
<span class="sd">        Tolerance for termination. The construction of the sparse grid is</span>
<span class="sd">        terminated when the estimate error in the sparse grid (determined by</span>
<span class="sd">        ``refinement_indicator`` is below tol.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls messages printed during construction.</span>

<span class="sd">    max_level_1d : np.ndarray (nvars)</span>
<span class="sd">        The maximum level of the sparse grid in each dimension. If None</span>
<span class="sd">        There is no limit</span>

<span class="sd">    induced_sampling : boolean</span>
<span class="sd">        True - use induced sampling</span>
<span class="sd">        False - sample from probability measure</span>

<span class="sd">    cond_tol : float</span>
<span class="sd">        The maximum allowable condition number of the regression problem.</span>
<span class="sd">        If induced_sampling is False and cond_tol &lt; 0 then we do not sample</span>
<span class="sd">        until cond number is below cond_tol but rather simply add</span>
<span class="sd">        nnew_indices*abs(cond_tol) samples. That is we specify an</span>
<span class="sd">        over sampling factor</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx: :class:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion`</span>
<span class="sd">        The PCE approximation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>

    <span class="n">pce</span> <span class="o">=</span> <span class="n">AdaptiveInducedPCE</span><span class="p">(</span>
        <span class="n">var_trans</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">induced_sampling</span><span class="o">=</span><span class="n">induced_sampling</span><span class="p">,</span>
        <span class="n">cond_tol</span><span class="o">=</span><span class="n">cond_tol</span><span class="p">,</span> <span class="n">fit_opts</span><span class="o">=</span><span class="n">fit_opts</span><span class="p">)</span>

    <span class="n">__setup_adaptive_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span>
                         <span class="n">refinement_indicator</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span> <span class="n">callback</span><span class="p">,</span>
                         <span class="n">max_level_1d</span><span class="p">)</span>

    <span class="n">pce</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">pce</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_polynomial_chaos_leja</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span>
        <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refinement_indicator</span><span class="o">=</span><span class="n">variance_pce_refinement_indicator</span><span class="p">,</span>
        <span class="n">growth_rules</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">max_level_1d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ncandidate_samples</span><span class="o">=</span><span class="mf">1e4</span><span class="p">,</span> <span class="n">generate_candidate_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute an adaptive Polynomial Chaos Expansion of a function based upon</span>
<span class="sd">    multivariate Leja sequences.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun : callable</span>
<span class="sd">        The function to be minimized</span>

<span class="sd">        ``fun(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shape (nsamples,nqoi)</span>

<span class="sd">    variables : IndependentMarginalsVariable</span>
<span class="sd">        A set of independent univariate random variables</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Function called after each iteration with the signature</span>

<span class="sd">        ``callback(approx_k)``</span>

<span class="sd">        where approx_k is the current approximation object.</span>

<span class="sd">    refinement_indicator : callable</span>
<span class="sd">        A function that retuns an estimate of the error of a sparse grid</span>
<span class="sd">        subspace with signature</span>

<span class="sd">        ``refinement_indicator(subspace_index,nnew_subspace_samples,sparse_grid) -&gt; float, float``</span>

<span class="sd">        where ``subspace_index`` is 1D np.ndarray of size (nvars),</span>
<span class="sd">        ``nnew_subspace_samples`` is an integer specifying the number</span>

<span class="sd">        of new samples that will be added to the sparse grid by adding the</span>
<span class="sd">        subspace specified by subspace_index and ``sparse_grid`` is the current</span>
<span class="sd">        :class:`pyapprox.adaptive_sparse_grid.CombinationSparseGrid` object.</span>
<span class="sd">        The two outputs are, respectively, the indicator used to control</span>
<span class="sd">        refinement of the sparse grid and the change in error from adding the</span>
<span class="sd">        current subspace. The indicator is typically but now always dependent</span>
<span class="sd">        on the error.</span>

<span class="sd">    growth_rules : list or callable</span>
<span class="sd">        a list (or single callable) of growth rules with signature</span>

<span class="sd">        ``growth_rule(l)-&gt;integer``</span>

<span class="sd">        where the output ``nsamples`` specifies the number of indices of the</span>
<span class="sd">        univariate basis of level ``l``.</span>

<span class="sd">        If the entry is a callable then the same growth rule is</span>
<span class="sd">        applied to every variable.</span>

<span class="sd">    max_nsamples : integer</span>
<span class="sd">        The maximum number of evaluations of fun.</span>

<span class="sd">    tol : float</span>
<span class="sd">        Tolerance for termination. The construction of the sparse grid is</span>
<span class="sd">        terminated when the estimate error in the sparse grid (determined by</span>
<span class="sd">        ``refinement_indicator`` is below tol.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls messages printed during construction.</span>

<span class="sd">    max_level_1d : np.ndarray (nvars)</span>
<span class="sd">        The maximum level of the sparse grid in each dimension. If None</span>
<span class="sd">        There is no limit</span>

<span class="sd">    ncandidate_samples : integer</span>
<span class="sd">        The number of candidate samples used to generate the Leja sequence</span>
<span class="sd">        The Leja sequence will be a subset of these samples.</span>

<span class="sd">    generate_candidate_samples : callable</span>
<span class="sd">        A function that generates the candidate samples used to build the Leja</span>
<span class="sd">        sequence with signature</span>

<span class="sd">        ``generate_candidate_samples(ncandidate_samples) -&gt; np.ndarray``</span>

<span class="sd">        The output is a 2D np.ndarray with size(nvars,ncandidate_samples)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx: :class:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion`</span>
<span class="sd">        The PCE approximation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>

    <span class="n">pce</span> <span class="o">=</span> <span class="n">__initialize_leja_pce</span><span class="p">(</span>
        <span class="n">variables</span><span class="p">,</span> <span class="n">generate_candidate_samples</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="p">)</span>

    <span class="n">__setup_adaptive_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">var_trans</span><span class="p">,</span> <span class="n">growth_rules</span><span class="p">,</span>
                         <span class="n">refinement_indicator</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span> <span class="n">callback</span><span class="p">,</span>
                         <span class="n">max_level_1d</span><span class="p">)</span>

    <span class="n">pce</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">pce</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_gaussian_process</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="o">=</span><span class="mf">1e4</span><span class="p">,</span>
        <span class="n">checkpoints</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">normalize_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">noise_level</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">,</span>
        <span class="n">kernel_variance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">kernel_variance_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">,</span>
        <span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">generate_candidate_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">normalize_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adaptively construct a Gaussian process approximation of a function using</span>
<span class="sd">    weighted-pivoted-Cholesky sampling and the Matern kernel</span>

<span class="sd">    .. math::</span>

<span class="sd">       k(z_i, z_j) =  \frac{1}{\Gamma(\nu)2^{\nu-1}}\Bigg(</span>
<span class="sd">       \frac{\sqrt{2\nu}}{l} \lVert z_i - z_j \rVert_2\Bigg)^\nu K_\nu\Bigg(</span>
<span class="sd">       \frac{\sqrt{2\nu}}{l} \lVert z_i - z_j \rVert_2\Bigg)</span>

<span class="sd">    where :math:`\lVert \cdot \rVert_2` is the Euclidean distance,</span>
<span class="sd">    :math:`\Gamma(\cdot)` is the gamma function, :math:`K_\nu(\cdot)` is the</span>
<span class="sd">    modified Bessel function.</span>

<span class="sd">    Starting from an initial guess, the algorithm learns the kernel length</span>
<span class="sd">    scale as more training data is collected.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun : callable</span>
<span class="sd">        The function to be approximated</span>

<span class="sd">        ``fun(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shape (nsamples,nqoi)</span>

<span class="sd">    variable : IndependentMarginalsVariable</span>
<span class="sd">        A set of independent univariate random variables</span>

<span class="sd">    callback : callable</span>
<span class="sd">        Function called after each iteration with the signature</span>

<span class="sd">        ``callback(approx_k)``</span>

<span class="sd">        where approx_k is the current approximation object.</span>

<span class="sd">    nu : string</span>
<span class="sd">        The parameter :math:`\nu` of the Matern kernel. When :math:`\nu\to\inf`</span>
<span class="sd">        the Matern kernel is equivalent to the squared-exponential kernel.</span>

<span class="sd">    checkpoints : iterable</span>
<span class="sd">        The set of points at which the length scale of the kernel will be</span>
<span class="sd">        recomputed and new training data obtained. If None then</span>
<span class="sd">        ``checkpoints = np.linspace(10, max_nsamples, 10).astype(int)``</span>

<span class="sd">    max_nsamples : float</span>
<span class="sd">        The maximum number of evaluations of fun. If fun has configure</span>
<span class="sd">        variables.</span>

<span class="sd">    ncandidate_samples : integer</span>
<span class="sd">        The number of candidate samples used to select the training samples</span>
<span class="sd">        The final training samples will be a subset of these samples.</span>

<span class="sd">    alpha : float</span>
<span class="sd">        Nugget added to diagonal of the covariance kernel evaluated at</span>
<span class="sd">        the training data. Used to improve numerical conditionining. This</span>
<span class="sd">        parameter is different to noise_level which applies to both training</span>
<span class="sd">        and test data</span>

<span class="sd">    normalize_y : bool</span>
<span class="sd">        True - normalize the training values to have zero mean and unit</span>
<span class="sd">               variance</span>

<span class="sd">    length_scale : float</span>
<span class="sd">        The initial length scale used to generate the first batch of training</span>
<span class="sd">        samples</span>

<span class="sd">    length_scale_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on length_scale used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    noise_level : float</span>
<span class="sd">        The noise_level used when training the GP</span>

<span class="sd">    noise_level_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on noise_level used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    kernel_variance : float</span>
<span class="sd">        The kernel_variance used when training the GP</span>

<span class="sd">    noise_level_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on kernel_variance used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    n_restarts_optimizer : int</span>
<span class="sd">        The number of local optimizeation problems solved to find the</span>
<span class="sd">        GP hyper-parameters</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    generate_candidate_samples : callable</span>
<span class="sd">        A function that generates the candidate samples used to build the Leja</span>
<span class="sd">        sequence with signature</span>

<span class="sd">        ``generate_candidate_samples(ncandidate_samples) -&gt; np.ndarray``</span>

<span class="sd">        The output is a 2D np.ndarray with size(nvars,ncandidate_samples)</span>

<span class="sd">    weight_function : callable</span>
<span class="sd">        Function used to precondition kernel with the signature</span>

<span class="sd">        ``weight_function(samples) -&gt; np.ndarray (num_samples)``</span>

<span class="sd">        where samples is a np.ndarray (num_vars,num_samples)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx : :class:`pyapprox.surrogates.gaussianprocess.gaussian_process.AdaptiveGaussianProcess`</span>
<span class="sd">        The Gaussian process</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">max_nsamples</span> <span class="o">&lt;=</span> <span class="n">ncandidate_samples</span>

    <span class="n">nvars</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">normalize_inputs</span><span class="p">:</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">normalize_y</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;normalize_y=True not currently supported&quot;</span><span class="p">)</span>

    <span class="n">kernel</span> <span class="o">=</span> <span class="n">__setup_gaussian_process_kernel</span><span class="p">(</span>
        <span class="n">nvars</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="p">,</span>
        <span class="n">kernel_variance</span><span class="p">,</span> <span class="n">kernel_variance_bounds</span><span class="p">,</span>
        <span class="n">noise_level</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>

    <span class="n">sampler</span> <span class="o">=</span> <span class="n">CholeskySampler</span><span class="p">(</span>
        <span class="n">nvars</span><span class="p">,</span> <span class="n">ncandidate_samples</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span>
        <span class="n">gen_candidate_samples</span><span class="o">=</span><span class="n">generate_candidate_samples</span><span class="p">,</span>
        <span class="n">var_trans</span><span class="o">=</span><span class="n">var_trans</span><span class="p">)</span>
    <span class="n">sampler_kernel</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
    <span class="n">sampler</span><span class="o">.</span><span class="n">set_kernel</span><span class="p">(</span><span class="n">sampler_kernel</span><span class="p">)</span>
    <span class="n">sampler</span><span class="o">.</span><span class="n">set_weight_function</span><span class="p">(</span><span class="n">weight_function</span><span class="p">)</span>

    <span class="n">gp</span> <span class="o">=</span> <span class="n">AdaptiveGaussianProcess</span><span class="p">(</span>
        <span class="n">kernel</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="n">n_restarts_optimizer</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
        <span class="n">normalize_y</span><span class="o">=</span><span class="n">normalize_y</span><span class="p">)</span>
    <span class="n">gp</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gp</span><span class="o">.</span><span class="n">set_variable_transformation</span><span class="p">(</span><span class="n">var_trans</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nsteps</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="k">if</span> <span class="n">max_nsamples</span><span class="o">-</span><span class="mi">10</span> <span class="o">&lt;</span> <span class="n">nsteps</span><span class="p">:</span>
            <span class="n">nsteps</span> <span class="o">=</span> <span class="n">max_nsamples</span><span class="o">-</span><span class="mi">10</span>
        <span class="n">checkpoints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">,</span> <span class="n">nsteps</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">checkpoints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">checkpoints</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">checkpoints</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_nsamples</span>

    <span class="n">nsteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsteps</span><span class="p">):</span>
        <span class="n">chol_flag</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">refine</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">[</span><span class="n">kk</span><span class="p">])</span>
        <span class="n">gp</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">set_kernel</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback</span><span class="p">(</span><span class="n">gp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">chol_flag</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Cannot add additional samples. &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Kernel is now ill conditioned. &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;If more samples are really required increase alpha or &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;manually fix kernel_length to a smaller value&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Exiting: &#39;</span> <span class="o">+</span> <span class="n">msg</span><span class="p">)</span>
            <span class="c1"># print(gp.kernel_)</span>
            <span class="c1"># print(np.linalg.norm(gp.sampler.candidate_samples))</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">gp</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">compute_l2_error</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the :math:`\ell^2` error of the output of two functions f and g,</span>
<span class="sd">    i.e.</span>

<span class="sd">    .. math:: \lVert f(z)-g(z)\rVert\approx \sum_{m=1}^M f(z^{(m)})</span>

<span class="sd">    from a set of random draws :math:`\mathcal{Z}=\{z^{(m)}\}_{m=1}^M`</span>
<span class="sd">    from the PDF of :math:`z`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``g(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shaoe (nsamples,nqoi)</span>

<span class="sd">    g : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        ``f(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shaoe (nsamples,nqoi)</span>

<span class="sd">    variable : pya.IndependentMarginalsVariable</span>
<span class="sd">        Object containing information of the joint density of the inputs z.</span>
<span class="sd">        This is used to generate random samples from this join density</span>

<span class="sd">    nsamples : integer</span>
<span class="sd">        The number of samples used to compute the :math:`\ell^2` error</span>

<span class="sd">    rel : boolean</span>
<span class="sd">        True - compute relative error</span>
<span class="sd">        False - compute absolute error</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    error : np.ndarray (nqoi)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">validation_samples</span> <span class="o">=</span> <span class="n">generate_independent_random_samples</span><span class="p">(</span>
        <span class="n">variable</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">)</span>
    <span class="n">validation_vals</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">validation_samples</span><span class="p">)</span>
    <span class="n">approx_vals</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">validation_samples</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">validation_vals</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">approx_vals</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">approx_vals</span><span class="o">-</span><span class="n">validation_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">rel</span><span class="p">:</span>
        <span class="n">error</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">validation_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">error</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">validation_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">error</span>


<div class="viewcode-block" id="adaptive_approximate"><a class="viewcode-back" href="../../../api/pyapprox.surrogates.adaptive_approximate.html#pyapprox.surrogates.adaptive_approximate">[docs]</a><span class="k">def</span> <span class="nf">adaptive_approximate</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adaptive approximation of a scalar or vector-valued function of one or</span>
<span class="sd">    more variables. These methods choose the samples to at which to</span>
<span class="sd">    evaluate the function being approximated.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun : callable</span>
<span class="sd">        The function to be minimized</span>

<span class="sd">        ``fun(z) -&gt; np.ndarray``</span>

<span class="sd">        where ``z`` is a 2D np.ndarray with shape (nvars,nsamples) and the</span>
<span class="sd">        output is a 2D np.ndarray with shaoe (nsamples,nqoi)</span>

<span class="sd">    method : string</span>
<span class="sd">        Type of approximation. Should be one of</span>

<span class="sd">        - &#39;sparse_grid&#39;</span>
<span class="sd">        - &#39;polynomial_chaos&#39;</span>
<span class="sd">        - &#39;gaussian_process&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object. For more details see</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.adaptive_approximate_sparse_grid`</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.adaptive_approximate_polynomial_chaos`</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.adaptive_approximate_gaussian_process`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;sparse_grid&#39;</span><span class="p">:</span> <span class="n">adaptive_approximate_sparse_grid</span><span class="p">,</span>
               <span class="s1">&#39;polynomial_chaos&#39;</span><span class="p">:</span> <span class="n">adaptive_approximate_polynomial_chaos</span><span class="p">,</span>
               <span class="s1">&#39;gaussian_process&#39;</span><span class="p">:</span> <span class="n">adaptive_approximate_gaussian_process</span><span class="p">}</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span> <span class="o">!=</span> <span class="n">IndependentMarginalsVariable</span><span class="p">:</span>
        <span class="n">variable</span> <span class="o">=</span> <span class="n">IndependentMarginalsVariable</span><span class="p">(</span>
            <span class="n">variable</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Method </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s1"> not found.</span><span class="se">\n</span><span class="s1"> Available methods are:</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">methods</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="n">methods</span><span class="p">[</span><span class="n">method</span><span class="p">](</span><span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">approximate_polynomial_chaos</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">basis_type</span><span class="o">=</span><span class="s1">&#39;expanding_basis&#39;</span><span class="p">,</span>
                                 <span class="n">variable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">poly_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a Polynomial Chaos Expansion of a function from a fixed data set.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    basis_type : string</span>
<span class="sd">        Type of approximation. Should be one of</span>

<span class="sd">        - &#39;hyperbolic_cross&#39; see :func:`pyapprox.surrogates.approximate.cross_validate_pce_degree`</span>
<span class="sd">        - &#39;expanding_basis&#39; see :func:`pyapprox.surrogates.approximate.expanding_basis_pce`</span>
<span class="sd">        - &#39;fixed&#39; see :func:`pyapprox.surrogates.approximate.approximate_fixed_pce`</span>

<span class="sd">    variable : pya.IndependentMarginalsVariable</span>
<span class="sd">        Object containing information of the joint density of the inputs z.</span>
<span class="sd">        This is used to generate random samples from this join density</span>

<span class="sd">    verbosity : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    poly_opts : dictionary</span>
<span class="sd">        Dictionary definining the custom configuration of the polynomial</span>
<span class="sd">        chaos expansion basis. See :func:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion.configure`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object. For more details see</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.cross_validate_pce_degree`</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.expanding_basis_pce`</span>

<span class="sd">         - :func:`pyapprox.surrogates.approximate.approximate_fixed_pce`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">funcs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;expanding_basis&#39;</span><span class="p">:</span> <span class="n">expanding_basis_pce</span><span class="p">,</span>
             <span class="s1">&#39;hyperbolic_cross&#39;</span><span class="p">:</span> <span class="n">cross_validate_pce_degree</span><span class="p">,</span>
             <span class="s1">&#39;fixed&#39;</span><span class="p">:</span> <span class="n">approximate_fixed_pce</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">variable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;pce requires that variable be defined&#39;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">basis_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">funcs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Basis type </span><span class="si">{</span><span class="n">basis_type</span><span class="si">}</span><span class="s1"> not found.</span><span class="se">\n</span><span class="s1"> Available types are:</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">funcs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialChaosExpansion</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">poly_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
        <span class="n">poly_opts</span> <span class="o">=</span> <span class="n">define_poly_options_from_variable_transformation</span><span class="p">(</span>
            <span class="n">var_trans</span><span class="p">)</span>
    <span class="n">poly</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">poly_opts</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">funcs</span><span class="p">[</span><span class="n">basis_type</span><span class="p">](</span><span class="n">poly</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">approximate_neural_network</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span>
                               <span class="n">network_opts</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                               <span class="n">variable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">network_opts</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">network_opts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nrestarts</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">nparams</span><span class="p">,</span> <span class="n">nrestarts</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">optimizer_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">optimizer_opts</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;options&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">}}</span>
    <span class="n">network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbosity</span><span class="p">,</span>
                <span class="n">opts</span><span class="o">=</span><span class="n">optimizer_opts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">network</span><span class="p">})</span>


<div class="viewcode-block" id="approximate"><a class="viewcode-back" href="../../../api/pyapprox.surrogates.approximate.html#pyapprox.surrogates.approximate">[docs]</a><span class="k">def</span> <span class="nf">approximate</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Approximate a scalar or vector-valued function of one or</span>
<span class="sd">    more variables from a set of points provided by the user</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    method : string</span>
<span class="sd">        Type of approximation. Should be one of</span>

<span class="sd">        - &#39;polynomial_chaos&#39;</span>
<span class="sd">        - &#39;gaussian_process&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;polynomial_chaos&#39;</span><span class="p">:</span> <span class="n">approximate_polynomial_chaos</span><span class="p">,</span>
               <span class="s1">&#39;gaussian_process&#39;</span><span class="p">:</span> <span class="n">approximate_gaussian_process</span><span class="p">,</span>
               <span class="s1">&#39;neural_network&#39;</span><span class="p">:</span> <span class="n">approximate_neural_network</span><span class="p">}</span>
    <span class="c1"># &#39;tensor-train&#39;:approximate_tensor_train,</span>

    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Method </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s1"> not found.</span><span class="se">\n</span><span class="s1"> Available methods are:</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">methods</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="n">methods</span><span class="p">[</span><span class="n">method</span><span class="p">](</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">LinearLeastSquares</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">gram_mat</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">gram_mat</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">gram_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span>
            <span class="n">gram_mat</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Do not current support fit_intercept = True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>


<span class="k">class</span> <span class="nc">LinearLeastSquaresCV</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    - None, to use the default 5-fold cross-validation</span>
<span class="sd">    - integer to specify the number of folds</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_folds</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">cv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># sklearn RidgeCV can only be applied with leave one out cross</span>
            <span class="c1"># validation. Use this as the default here</span>
            <span class="n">cv</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_folds</span> <span class="o">=</span> <span class="n">random_folds</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">fold_sample_indices</span> <span class="o">=</span> <span class="n">get_random_k_fold_sample_indices</span><span class="p">(</span>
                <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_folds</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">leave_many_out_lsq_cross_validation</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fold_sample_indices</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">leave_one_out_lsq_cross_validation</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">]</span>
        <span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
        <span class="n">ii_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cv_score_</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="p">[</span><span class="n">ii_best_alpha</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">ii_best_alpha</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">ii_best_alpha</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
        <span class="c1"># Do not current support fit_intercept = True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>


<span class="nd">@ignore_warnings</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">ConvergenceWarning</span><span class="p">)</span>
<span class="nd">@ignore_warnings</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">LinAlgWarning</span><span class="p">)</span>
<span class="nd">@ignore_warnings</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="ne">RuntimeWarning</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fit_linear_model</span><span class="p">(</span><span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">solver_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># verbose=1 will display lars path on entire data setUp</span>
    <span class="c1"># verbose&gt;1 will also show this plus paths on each cross validation set</span>
    <span class="n">solvers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lasso&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">LassoLarsCV</span><span class="p">,</span> <span class="n">LassoLars</span><span class="p">],</span>
               <span class="s1">&#39;lasso_grad&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">LassoCV</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">],</span>
               <span class="s1">&#39;lars&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">LarsCV</span><span class="p">,</span> <span class="n">Lars</span><span class="p">],</span>
               <span class="s1">&#39;omp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">OrthogonalMatchingPursuitCV</span><span class="p">,</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">],</span>
               <span class="s1">&#39;lstsq&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">LinearLeastSquaresCV</span><span class="p">,</span> <span class="n">LinearLeastSquares</span><span class="p">]}</span>

    <span class="k">if</span> <span class="n">solver_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">solvers</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Solver type </span><span class="si">{</span><span class="n">solver_type</span><span class="si">}</span><span class="s1"> not supported</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;Supported solvers are:</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">solvers</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">solver_type</span> <span class="o">==</span> <span class="s1">&#39;lars&#39;</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Currently lars does not exit when alpha starts to grow &#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;this causes problems with cross validation. The lasso variant &#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;lars does work because this exit condition is implemented&#39;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="c1"># The following comment and two conditional statements are only true</span>
    <span class="c1"># for lars which I have switched off.</span>

    <span class="c1"># cv interpolates each residual onto a common set of alphas</span>
    <span class="c1"># This is problematic if the alpha path is not monotonically decreasing</span>
    <span class="c1"># For some problems alpha will increase for last few sample sizes. This</span>
    <span class="c1"># messes up interpolation and causes the best_alpha to be estimated</span>
    <span class="c1"># very poorly in some cases. I belive all_alphas = np.unique(all_alphas)</span>
    <span class="c1"># is the culprit. To avoid the aforementioned issue set max_iter to</span>
    <span class="c1"># ntrain_samples//2 This is typically stops the algorithm after</span>
    <span class="c1"># what would have been chosen as the best_alpha but before</span>
    <span class="c1"># alphas start increasing. Ideally sklearn should exit when</span>
    <span class="c1"># alphas increase.</span>
    <span class="c1"># if solver_type != &#39;lstsq&#39; and &#39;max_iter&#39; not in kwargs:</span>
    <span class="c1">#    kwargs[&#39;max_iter&#39;] = basis_matrix.shape[0]//2</span>

    <span class="c1"># if &#39;max_iter&#39; in kwargs and kwargs[&#39;max_iter&#39;] &gt; basis_matrix.shape[0]//2:</span>
    <span class="c1">#     msg = &quot;Warning: max_iter is set large this can effect not just &quot;</span>
    <span class="c1">#     msg += &quot;Computational cost but also final accuracy&quot;</span>
    <span class="c1">#     print(msg)</span>

    <span class="k">if</span> <span class="n">solver_type</span> <span class="o">==</span> <span class="s1">&#39;omp&#39;</span> <span class="ow">and</span> <span class="s1">&#39;max_iter&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="c1"># unlike lasso/lars max iter is not allowed to be greater than</span>
        <span class="c1"># number of columns (features/bases)</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">],</span> <span class="n">basis_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># for omp to work sklean must be patched to store mse_path_.</span>
        <span class="c1"># Add the line         self.mse_path_ = mse_folds.T</span>
        <span class="c1"># as the last line (913) before return self in the function fit of</span>
        <span class="c1"># OrthogonalMatchingPursuitCV in</span>
        <span class="c1"># site-packages/sklearn/linear_model/_omp.py</span>

    <span class="k">if</span> <span class="s1">&#39;cv&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;cv&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="n">solver_idx</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">solver_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;precondition&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">christoffel_weights</span><span class="p">(</span><span class="n">basis_matrix</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">basis_matrix</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">*</span><span class="n">weights</span>
        <span class="n">train_vals</span> <span class="o">=</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">*</span><span class="n">weights</span>

    <span class="k">if</span> <span class="s1">&#39;precondition&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;precondition&#39;</span><span class="p">]</span>

    <span class="n">fit</span> <span class="o">=</span> <span class="n">solvers</span><span class="p">[</span><span class="n">solver_type</span><span class="p">][</span><span class="n">solver_idx</span><span class="p">](</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">coef</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">coef_</span>
    <span class="k">if</span> <span class="n">coef</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="c1"># some methods allow fit_intercept to be set. If True this method</span>
        <span class="c1"># extracts of mean of data before computing coefficients.</span>
        <span class="c1"># res.predict then makes predictions as X.dot(coef_) + res.intercept_</span>
        <span class="c1"># I assume first coefficient is constant basis and want to be able</span>
        <span class="c1"># to simply return X.dot(coef_) (e.g. as done be Polynomial Chaos</span>
        <span class="c1"># Expansion). Thus add res.intercept_ to first coefficient, i.e.</span>
    <span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">res</span><span class="o">.</span><span class="n">intercept_</span>
    <span class="k">if</span> <span class="s1">&#39;cv&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">cv_score</span> <span class="o">=</span> <span class="n">extract_cross_validation_score</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="n">best_regularization_param</span> <span class="o">=</span> <span class="n">extract_best_regularization_parameters</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cv_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">best_regularization_param</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">coef</span><span class="p">,</span> <span class="n">cv_score</span><span class="p">,</span> <span class="n">best_regularization_param</span>


<span class="k">def</span> <span class="nf">extract_best_regularization_parameters</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="n">LassoLarsCV</span> <span class="ow">or</span> <span class="nb">type</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="n">LinearLeastSquaresCV</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">alpha_</span>
    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="n">LarsCV</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="c1"># The Lars (not LarsCV) model takes max_iters as regularization</span>
        <span class="c1"># parameter so return it here as well as the alpha. Sklearn</span>
        <span class="c1"># has an inconsistency alpha is used to choose best cv score but Lars</span>
        <span class="c1"># uses max_iters to stop algorithm early.</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">alpha_</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="n">OrthogonalMatchingPursuitCV</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">n_nonzero_coefs_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">extract_cross_validation_score</span><span class="p">(</span><span class="n">linear_model</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="s1">&#39;cv_score_&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">cv_score_</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="s1">&#39;mse_path_&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;attribute mse_path_ not found&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cross_validate_pce_degree</span><span class="p">(</span>
        <span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">min_degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">hcross_strength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cv&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use cross validation to find the polynomial degree which best fits the</span>
<span class="sd">    data.</span>
<span class="sd">    A polynomial is constructed for each degree and the degree with the highest</span>
<span class="sd">    cross validation score is returned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    min_degree : integer</span>
<span class="sd">        The minimum degree to consider</span>

<span class="sd">    max_degree : integer</span>
<span class="sd">        The maximum degree to consider.</span>
<span class="sd">        All degrees in ``range(min_degree,max_deree+1)`` are considered</span>

<span class="sd">    hcross_strength : float</span>
<span class="sd">       The strength of the hyperbolic cross index set. hcross_strength must be</span>
<span class="sd">       in (0,1]. A value of 1 produces total degree polynomials</span>

<span class="sd">    cv : integer</span>
<span class="sd">        The number of cross validation folds used to compute the cross</span>
<span class="sd">        validation error</span>

<span class="sd">    solver_type : string</span>
<span class="sd">        The type of regression used to train the polynomial</span>

<span class="sd">        - &#39;lasso&#39;</span>
<span class="sd">        - &#39;lars&#39;</span>
<span class="sd">        - &#39;lasso_grad&#39;</span>
<span class="sd">        - &#39;omp&#39;</span>
<span class="sd">        - &#39;lstsq&#39;</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx: :class:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion`</span>
<span class="sd">        The PCE approximation</span>

<span class="sd">    scores : np.ndarray (nqoi)</span>
<span class="sd">        The best cross validation score for each QoI</span>

<span class="sd">    degrees : np.ndarray (nqoi)</span>
<span class="sd">        The best degree for each QoI</span>

<span class="sd">    reg_params : np.ndarray (nqoi)</span>
<span class="sd">        The best regularization parameters for each QoI chosen by cross</span>
<span class="sd">        validation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">degrees</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reg_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">indices_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">unique_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nqoi</span> <span class="o">=</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Approximating QoI: </span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">pce_ii</span><span class="p">,</span> <span class="n">score_ii</span><span class="p">,</span> <span class="n">degree_ii</span><span class="p">,</span> <span class="n">reg_param_ii</span> <span class="o">=</span> <span class="n">_cross_validate_pce_degree</span><span class="p">(</span>
            <span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">min_degree</span><span class="p">,</span>
            <span class="n">max_degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">,</span> <span class="n">linear_solver_options</span><span class="p">,</span>
            <span class="n">solver_type</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>
        <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pce_ii</span><span class="o">.</span><span class="n">get_coefficients</span><span class="p">())</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_ii</span><span class="p">)</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pce_ii</span><span class="o">.</span><span class="n">get_indices</span><span class="p">())</span>
        <span class="n">degrees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">degree_ii</span><span class="p">)</span>
        <span class="n">reg_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg_param_ii</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">indices_dict</span><span class="p">:</span>
                <span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

    <span class="n">unique_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">all_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">unique_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nqoi</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">jj</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="n">all_coefs</span><span class="p">[</span><span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">all_coefs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">pce</span><span class="p">,</span> <span class="s1">&#39;scores&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
                              <span class="s1">&#39;degrees&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">degrees</span><span class="p">),</span>
                              <span class="s1">&#39;reg_params&#39;</span><span class="p">:</span> <span class="n">reg_params</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">_cross_validate_pce_degree</span><span class="p">(</span>
        <span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">min_degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">hcross_strength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cv&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
        <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">min_degree</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">min_degree</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">max_degree</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_degree</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="o">-</span><span class="mi">1</span>

    <span class="n">best_coef</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">best_cv_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
    <span class="n">best_degree</span> <span class="o">=</span> <span class="n">min_degree</span>
    <span class="n">prev_num_terms</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;8}</span><span class="s2"> </span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;18}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;degree&#39;</span><span class="p">,</span> <span class="s1">&#39;num_terms&#39;</span><span class="p">,</span> <span class="s1">&#39;cv score&#39;</span><span class="p">,))</span>

    <span class="n">rng_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">min_degree</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">compute_hyperbolic_indices</span><span class="p">(</span>
            <span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">)</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">100000</span><span class="p">)</span> <span class="ow">and</span>
                <span class="p">(</span><span class="mi">100000</span><span class="o">-</span><span class="n">prev_num_terms</span> <span class="o">&lt;</span> <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span><span class="o">-</span><span class="mi">100000</span><span class="p">)):</span>
            <span class="k">break</span>

        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>

        <span class="c1"># use the same state (thus cross validation folds) for each degree</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>
        <span class="n">coef</span><span class="p">,</span> <span class="n">cv_score</span><span class="p">,</span> <span class="n">reg_param</span> <span class="o">=</span> <span class="n">fit_linear_model</span><span class="p">(</span>
            <span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">solver_type</span><span class="p">,</span> <span class="o">**</span><span class="n">linear_solver_options</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;8}</span><span class="s2"> </span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;18}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">degree</span><span class="p">,</span> <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">(),</span> <span class="n">cv_score</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">cv_score</span> <span class="o">&gt;=</span> <span class="n">best_cv_score</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">degree</span><span class="o">-</span><span class="n">best_degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cv_score</span> <span class="o">&lt;</span> <span class="n">best_cv_score</span><span class="p">):</span>
            <span class="n">best_cv_score</span> <span class="o">=</span> <span class="n">cv_score</span>
            <span class="n">best_coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">best_degree</span> <span class="o">=</span> <span class="n">degree</span>
            <span class="n">best_reg_param</span> <span class="o">=</span> <span class="n">reg_param</span>
        <span class="n">prev_num_terms</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span>

    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">compute_hyperbolic_indices</span><span class="p">(</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">best_degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">))</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">best_coef</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best degree:&#39;</span><span class="p">,</span> <span class="n">best_degree</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pce</span><span class="p">,</span> <span class="n">best_cv_score</span><span class="p">,</span> <span class="n">best_degree</span><span class="p">,</span> <span class="n">best_reg_param</span>


<span class="k">def</span> <span class="nf">restrict_basis</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">tol</span><span class="p">):</span>
    <span class="n">II</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">coefficients</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">restricted_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="n">II</span><span class="p">]</span>
    <span class="n">degrees</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">JJ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">degrees</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">JJ</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">JJ</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">II</span><span class="p">:</span>
        <span class="c1"># always include zero degree polynomial in restricted_indices</span>
        <span class="n">restricted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span><span class="n">indices</span><span class="p">[:</span><span class="n">JJ</span><span class="p">],</span> <span class="n">restricted_indices</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">restricted_indices</span>


<span class="k">def</span> <span class="nf">expand_basis</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
    <span class="n">nvars</span><span class="p">,</span> <span class="n">nindices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">indices_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nindices</span><span class="p">):</span>
        <span class="n">indices_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hash_array</span><span class="p">(</span><span class="n">indices</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">]))</span>

    <span class="n">new_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nindices</span><span class="p">):</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">forward_index</span> <span class="o">=</span> <span class="n">get_forward_neighbor</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dd</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">forward_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">indices_set</span><span class="p">:</span>
                <span class="n">admissible</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">active_vars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">forward_index</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="n">active_vars</span><span class="p">:</span>
                    <span class="n">backward_index</span> <span class="o">=</span> <span class="n">get_backward_neighbor</span><span class="p">(</span><span class="n">forward_index</span><span class="p">,</span> <span class="n">kk</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">backward_index</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">indices_set</span><span class="p">:</span>
                        <span class="n">admissible</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="n">admissible</span><span class="p">:</span>
                    <span class="n">indices_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="n">new_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">forward_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_indices</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">expanding_basis_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_num_init_terms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_num_terms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                        <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cv&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
                        <span class="n">restriction_tol</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">max_num_expansion_steps_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">max_iters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                        <span class="n">max_num_step_increases</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Iteratively expand and restrict the polynomial basis and use</span>
<span class="sd">    cross validation to find the best basis [JESJCP2015]_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars,nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars,nqoi)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    hcross_strength : float</span>
<span class="sd">       The strength of the hyperbolic cross index set. hcross_strength must be</span>
<span class="sd">       in (0,1]. A value of 1 produces total degree polynomials</span>

<span class="sd">    cv : integer</span>
<span class="sd">        The number of cross validation folds used to compute the cross</span>
<span class="sd">        validation error</span>

<span class="sd">    solver_type : string</span>
<span class="sd">        The type of regression used to train the polynomial</span>

<span class="sd">        - &#39;lasso&#39;</span>
<span class="sd">        - &#39;lars&#39;</span>
<span class="sd">        - &#39;lasso_grad&#39;</span>
<span class="sd">        - &#39;omp&#39;</span>
<span class="sd">        - &#39;lstsq&#39;</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    restriction_tol : float</span>
<span class="sd">        The tolerance used to prune inactive indices</span>

<span class="sd">    max_num_init_terms : integer</span>
<span class="sd">        The number of terms used to initialize the algorithm</span>

<span class="sd">    max_num_terms : integer</span>
<span class="sd">        The maximum number of terms allowed</span>

<span class="sd">    max_iters : integer</span>
<span class="sd">        The number of expansion/restriction iterations</span>

<span class="sd">    max_num_expansion_steps_iter : integer (1,2,3)</span>
<span class="sd">        The number of times a basis can expanded after</span>
<span class="sd">        the last restriction step</span>

<span class="sd">    max_num_expansion_steps_iter : integer</span>
<span class="sd">        The number of iterations error does not decrease before</span>
<span class="sd">        terminating</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx: :class:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion`</span>
<span class="sd">        The PCE approximation</span>

<span class="sd">    scores : np.ndarray (nqoi)</span>
<span class="sd">        The best cross validation score for each QoI</span>

<span class="sd">    reg_params : np.ndarray (nqoi)</span>
<span class="sd">        The best regularization parameters for each QoI chosen by cross</span>
<span class="sd">        validation.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [JESJCP2015] `J.D. Jakeman, M.S. Eldred, and K. Sargsyan. Enhancing l1-minimization estimates of polynomial chaos expansions using basis selection. Journal of Computational Physics, 289(0):18 – 34, 2015 &lt;https://doi.org/10.1016/j.jcp.2015.02.025&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reg_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">indices_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">unique_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nqoi</span> <span class="o">=</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Approximating QoI: </span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">pce_ii</span><span class="p">,</span> <span class="n">score_ii</span><span class="p">,</span> <span class="n">reg_param_ii</span> <span class="o">=</span> <span class="n">_expanding_basis_pce</span><span class="p">(</span>
            <span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">hcross_strength</span><span class="p">,</span>
            <span class="n">verbose</span><span class="p">,</span> <span class="n">max_num_init_terms</span><span class="p">,</span> <span class="n">max_num_terms</span><span class="p">,</span> <span class="n">solver_type</span><span class="p">,</span>
            <span class="n">linear_solver_options</span><span class="p">,</span> <span class="n">restriction_tol</span><span class="p">,</span>
            <span class="n">max_num_expansion_steps_iter</span><span class="p">,</span> <span class="n">max_iters</span><span class="p">,</span> <span class="n">max_num_step_increases</span><span class="p">)</span>
        <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pce_ii</span><span class="o">.</span><span class="n">get_coefficients</span><span class="p">())</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_ii</span><span class="p">)</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pce_ii</span><span class="o">.</span><span class="n">get_indices</span><span class="p">())</span>
        <span class="n">reg_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg_param_ii</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">indices_dict</span><span class="p">:</span>
                <span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

    <span class="n">unique_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">all_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">unique_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nqoi</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">jj</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="n">all_coefs</span><span class="p">[</span><span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">all_coefs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">pce</span><span class="p">,</span> <span class="s1">&#39;scores&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
                              <span class="s1">&#39;reg_params&#39;</span><span class="p">:</span> <span class="n">reg_params</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">_expanding_basis_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_num_init_terms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">max_num_terms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                         <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cv&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
                         <span class="n">restriction_tol</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">max_num_expansion_steps_iter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                         <span class="n">max_iters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                         <span class="n">max_num_step_increases</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">num_vars</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">max_num_init_terms</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_num_init_terms</span> <span class="o">=</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_num_terms</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_num_terms</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">prev_num_terms</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">compute_hyperbolic_indices</span><span class="p">(</span><span class="n">num_vars</span><span class="p">,</span> <span class="n">degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">)</span>
        <span class="n">num_terms</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">num_terms</span> <span class="o">&gt;</span> <span class="n">max_num_init_terms</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="n">degree</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">prev_num_terms</span> <span class="o">=</span> <span class="n">num_terms</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">num_terms</span> <span class="o">-</span> <span class="n">max_num_init_terms</span><span class="p">)</span> <span class="o">&gt;</span>
            <span class="nb">abs</span><span class="p">(</span><span class="n">prev_num_terms</span> <span class="o">-</span> <span class="n">max_num_init_terms</span><span class="p">)):</span>
        <span class="n">degree</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span>
        <span class="n">compute_hyperbolic_indices</span><span class="p">(</span><span class="n">num_vars</span><span class="p">,</span> <span class="n">degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Initializing basis with hyperbolic cross of degree </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1"> &#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;and strength </span><span class="si">{</span><span class="n">hcross_strength</span><span class="si">}</span><span class="s1"> with </span><span class="si">{</span><span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span><span class="si">}</span><span class="s1"> terms&#39;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">rng_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
    <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
    <span class="n">best_coef</span><span class="p">,</span> <span class="n">best_cv_score</span><span class="p">,</span> <span class="n">best_reg_param</span> <span class="o">=</span> <span class="n">fit_linear_model</span><span class="p">(</span>
        <span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">solver_type</span><span class="p">,</span> <span class="o">**</span><span class="n">linear_solver_options</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">best_coef</span><span class="p">)</span>
    <span class="n">best_indices</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">get_indices</span><span class="p">()</span>
    <span class="n">best_cv_score_iter</span> <span class="o">=</span> <span class="n">best_cv_score</span>
    <span class="n">best_indices_iter</span> <span class="o">=</span> <span class="n">best_indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">best_coef_iter</span> <span class="o">=</span> <span class="n">best_coef</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">best_reg_param_iter</span> <span class="o">=</span> <span class="n">best_reg_param</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;18}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;nterms&#39;</span><span class="p">,</span> <span class="s1">&#39;nnz terms&#39;</span><span class="p">,</span> <span class="s1">&#39;cv score&#39;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;18}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">pce</span><span class="o">.</span><span class="n">coefficients</span><span class="p">),</span>
            <span class="n">best_cv_score</span><span class="p">))</span>

    <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_it</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">current_max_num_expansion_steps_iter</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">best_cv_score_iter</span> <span class="o">=</span> <span class="n">best_cv_score</span>
        <span class="n">indices_iter</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">coef_iter</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">coefficients</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># -------------- #</span>
            <span class="c1">#  Expand basis  #</span>
            <span class="c1"># -------------- #</span>
            <span class="n">num_expansion_steps_iter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">restrict_basis</span><span class="p">(</span>
                <span class="c1"># pce.indices, pce.coefficients, restriction_tol)</span>
                <span class="n">indices_iter</span><span class="p">,</span> <span class="n">coef_iter</span><span class="p">,</span> <span class="n">restriction_tol</span><span class="p">)</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Expanding </span><span class="si">{</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> restricted from &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">pce</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> terms&#39;</span>
            <span class="k">while</span> <span class="p">(</span><span class="n">num_expansion_steps_iter</span> <span class="o">&lt;</span>
                   <span class="n">current_max_num_expansion_steps_iter</span><span class="p">):</span>
                <span class="n">new_indices</span> <span class="o">=</span> <span class="n">expand_basis</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">indices</span><span class="p">,</span> <span class="n">new_indices</span><span class="p">])</span>
                <span class="n">num_expansion_steps_iter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">num_terms</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39; New number of terms </span><span class="si">{</span><span class="n">pce</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

            <span class="c1"># -----------------#</span>
            <span class="c1"># Compute solution #</span>
            <span class="c1"># -----------------#</span>
            <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>
            <span class="n">coef</span><span class="p">,</span> <span class="n">cv_score</span><span class="p">,</span> <span class="n">reg_param</span> <span class="o">=</span> <span class="n">fit_linear_model</span><span class="p">(</span>
                <span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">solver_type</span><span class="p">,</span> <span class="o">**</span><span class="n">linear_solver_options</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>
            <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;10}</span><span class="s2"> </span><span class="si">{:&lt;18}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">pce</span><span class="o">.</span><span class="n">coefficients</span><span class="p">),</span>
                    <span class="n">cv_score</span><span class="p">))</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">cv_score</span> <span class="o">&lt;</span> <span class="n">best_cv_score_iter</span><span class="p">):</span>
                <span class="n">best_cv_score_iter</span> <span class="o">=</span> <span class="n">cv_score</span>
                <span class="n">best_indices_iter</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">best_coef_iter</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">coefficients</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">best_reg_param_iter</span> <span class="o">=</span> <span class="n">reg_param</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">num_terms</span> <span class="o">&gt;=</span> <span class="n">max_num_terms</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Max number of terms </span><span class="si">{</span><span class="n">max_num_terms</span><span class="si">}</span><span class="s1"> reached&#39;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">current_max_num_expansion_steps_iter</span> <span class="o">&gt;=</span>
                    <span class="n">max_num_expansion_steps_iter</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Max number of inner expansion steps &#39;</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="n">max_num_expansion_steps_iter</span><span class="si">}</span><span class="s1">) reached&#39;</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="n">current_max_num_expansion_steps_iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">best_indices_iter</span><span class="p">)</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">best_coef_iter</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">best_cv_score_iter</span> <span class="o">&lt;</span> <span class="n">best_cv_score</span><span class="p">):</span>
            <span class="n">best_cv_score</span> <span class="o">=</span> <span class="n">best_cv_score_iter</span>
            <span class="n">best_coef</span> <span class="o">=</span> <span class="n">best_coef_iter</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">best_indices</span> <span class="o">=</span> <span class="n">best_indices_iter</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">best_reg_param</span> <span class="o">=</span> <span class="n">best_reg_param_iter</span>
            <span class="n">best_it</span> <span class="o">=</span> <span class="n">it</span>

        <span class="k">elif</span> <span class="p">(</span><span class="n">it</span> <span class="o">-</span> <span class="n">best_it</span> <span class="o">&gt;=</span> <span class="n">max_num_step_increases</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Terminating: error did not decrease&#39;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39; in last </span><span class="si">{</span><span class="n">max_num_step_increases</span><span class="si">}</span><span class="s1"> iterations&#39;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;best error: </span><span class="si">{</span><span class="n">best_cv_score</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;=</span> <span class="n">max_iters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Terminating: max iterations reached&#39;</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="n">nindices</span> <span class="o">=</span> <span class="n">best_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">II</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">best_coef</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">best_indices</span><span class="p">[:,</span> <span class="n">II</span><span class="p">])</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">best_coef</span><span class="p">[</span><span class="n">II</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Final basis has </span><span class="si">{</span><span class="n">pce</span><span class="o">.</span><span class="n">num_terms</span><span class="p">()</span><span class="si">}</span><span class="s1"> terms selected from &#39;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">nindices</span><span class="si">}</span><span class="s1"> using </span><span class="si">{</span><span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> samples&#39;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pce</span><span class="p">,</span> <span class="n">best_cv_score</span><span class="p">,</span> <span class="n">best_reg_param</span>


<span class="k">def</span> <span class="nf">approximate_fixed_pce</span><span class="p">(</span><span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                          <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{}):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate the coefficients of a polynomial chaos using regression methods</span>
<span class="sd">    and pre-specified (fixed) basis and regularization parameters</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars, nqoi)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    indices : np.ndarray (nvars, nindices)</span>
<span class="sd">        The multivariate indices representing each basis in the expansion.</span>

<span class="sd">    solver_type : string</span>
<span class="sd">        The type of regression used to train the polynomial</span>

<span class="sd">        - &#39;lasso&#39;</span>
<span class="sd">        - &#39;lars&#39;</span>
<span class="sd">        - &#39;lasso_grad&#39;</span>
<span class="sd">        - &#39;omp&#39;</span>
<span class="sd">        - &#39;lstsq&#39;</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx: :class:`pyapprox.surrogates.polychaos.gpc.PolynomialChaosExpansion`</span>
<span class="sd">        The PCE approximation</span>

<span class="sd">    reg_params : np.ndarray (nqoi)</span>
<span class="sd">        The regularization parameters for each QoI.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nqoi</span> <span class="o">=</span> <span class="n">train_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">linear_solver_options</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">linear_solver_options</span> <span class="o">=</span> <span class="p">[</span><span class="n">linear_solver_options</span><span class="p">]</span><span class="o">*</span><span class="n">nqoi</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">)]</span>
    <span class="n">unique_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">indices_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
        <span class="n">coef_ii</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">reg_param_ii</span> <span class="o">=</span> <span class="n">fit_linear_model</span><span class="p">(</span>
            <span class="n">basis_matrix</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">solver_type</span><span class="p">,</span>
            <span class="o">**</span><span class="n">linear_solver_options</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
        <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coef_ii</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">indices_dict</span><span class="p">:</span>
                <span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
                <span class="n">unique_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

    <span class="n">unique_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">all_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">unique_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nqoi</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqoi</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">jj</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">hash_array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="n">all_coefs</span><span class="p">[</span><span class="n">indices_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">unique_indices</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_coefficients</span><span class="p">(</span><span class="n">all_coefs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">pce</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">__setup_gaussian_process_kernel</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="p">,</span>
                                    <span class="n">kernel_variance</span><span class="p">,</span> <span class="n">kernel_variance_bounds</span><span class="p">,</span>
                                    <span class="n">noise_level</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">length_scale</span><span class="p">):</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">length_scale</span><span class="p">]</span><span class="o">*</span><span class="n">nvars</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">length_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">nvars</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="n">length_scale_bounds</span><span class="p">,</span>
                    <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">)</span>
    <span class="c1"># optimize variance</span>
    <span class="k">if</span> <span class="n">kernel_variance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span>
            <span class="n">constant_value</span><span class="o">=</span><span class="n">kernel_variance</span><span class="p">,</span>
            <span class="n">constant_value_bounds</span><span class="o">=</span><span class="n">kernel_variance_bounds</span><span class="p">)</span><span class="o">*</span><span class="n">kernel</span>
    <span class="c1"># optimize gp noise</span>
    <span class="k">if</span> <span class="n">noise_level</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kernel</span> <span class="o">+=</span> <span class="n">WhiteKernel</span><span class="p">(</span>
            <span class="n">noise_level</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="o">=</span><span class="n">noise_level_bounds</span><span class="p">)</span>
    <span class="c1"># Note noise_level is different to alpha</span>
    <span class="c1"># noise_kernel applies nugget to both training and test data</span>
    <span class="c1"># alpha only applies it to training data</span>
    <span class="k">return</span> <span class="n">kernel</span>


<span class="k">def</span> <span class="nf">approximate_gaussian_process</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
                                 <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">normalize_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">noise_level</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">,</span>
                                 <span class="n">kernel_variance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                 <span class="n">kernel_variance_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">,</span>
                                 <span class="n">var_trans</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                 <span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a Gaussian process approximation of a function from a fixed data</span>
<span class="sd">    set using the Matern kernel</span>

<span class="sd">    .. math::</span>

<span class="sd">       k(z_i, z_j) =  \frac{1}{\Gamma(\nu)2^{\nu-1}}\Bigg(</span>
<span class="sd">       \frac{\sqrt{2\nu}}{l} \lVert z_i - z_j \rVert_2\Bigg)^\nu K_\nu\Bigg(</span>
<span class="sd">       \frac{\sqrt{2\nu}}{l} \lVert z_i - z_j \rVert_2\Bigg)</span>

<span class="sd">    where :math:`\lVert \cdot \rVert_2` is the Euclidean distance,</span>
<span class="sd">    :math:`\Gamma(\cdot)` is the gamma function, :math:`K_\nu(\cdot)` is the</span>
<span class="sd">    modified Bessel function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_samples : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The inputs of the function used to train the approximation</span>

<span class="sd">    train_vals : np.ndarray (nvars, 1)</span>
<span class="sd">        The values of the function at ``train_samples``</span>

<span class="sd">    nu : string</span>
<span class="sd">        The parameter :math:`\nu` of the Matern kernel. When :math:`\nu\to\inf`</span>
<span class="sd">        the Matern kernel is equivalent to the squared-exponential kernel.</span>

<span class="sd">    alpha : float</span>
<span class="sd">        Nugget added to diagonal of the covariance kernel evaluated at</span>
<span class="sd">        the training data. Used to improve numerical conditionining. This</span>
<span class="sd">        parameter is different to noise_level which applies to both training</span>
<span class="sd">        and test data</span>

<span class="sd">    normalize_y : bool</span>
<span class="sd">        True - normalize the training values to have zero mean and unit</span>
<span class="sd">        variance</span>

<span class="sd">    length_scale : float</span>
<span class="sd">        The initial length scale used to generate the first batch of training</span>
<span class="sd">        samples</span>

<span class="sd">    length_scale_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on length_scale used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    noise_level : float</span>
<span class="sd">        The noise_level used when training the GP</span>

<span class="sd">    noise_level_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on noise_level used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    kernel_variance : float</span>
<span class="sd">        The kernel_variance used when training the GP</span>

<span class="sd">    noise_level_bounds : tuple (2)</span>
<span class="sd">        The lower and upper bound on kernel_variance used in optimization of</span>
<span class="sd">        the Gaussian process hyper-parameters</span>

<span class="sd">    n_restarts_optimizer : int</span>
<span class="sd">        The number of local optimizeation problems solved to find the</span>
<span class="sd">        GP hyper-parameters</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the amount of information printed to screen</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : :class:`pyapprox.surrogates.approximate.ApproximateResult`</span>
<span class="sd">         Result object with the following attributes</span>

<span class="sd">    approx : :class:`pyapprox.surrogates.gaussianprocess.gaussian_process.GaussianProcess`</span>
<span class="sd">        The Gaussian process</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">__setup_gaussian_process_kernel</span><span class="p">(</span>
        <span class="n">nvars</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="p">,</span>
        <span class="n">kernel_variance</span><span class="p">,</span> <span class="n">kernel_variance_bounds</span><span class="p">,</span>
        <span class="n">noise_level</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>

    <span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcess</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="n">n_restarts_optimizer</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="n">normalize_y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gp</span><span class="o">.</span><span class="n">set_variable_transformation</span><span class="p">(</span><span class="n">var_trans</span><span class="p">)</span>
    <span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ApproximateResult</span><span class="p">({</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">gp</span><span class="p">})</span>


<span class="kn">from</span> <span class="nn">pyapprox.util.utilities</span> <span class="kn">import</span> <span class="n">get_random_k_fold_sample_indices</span><span class="p">,</span> \
    <span class="n">leave_many_out_lsq_cross_validation</span><span class="p">,</span> <span class="n">leave_one_out_lsq_cross_validation</span>
<span class="k">def</span> <span class="nf">cross_validate_approximation</span><span class="p">(</span>
        <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">nfolds</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">random_folds</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">ntrain_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">random_folds</span> <span class="o">!=</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">:</span>
        <span class="n">fold_sample_indices</span> <span class="o">=</span> <span class="n">get_random_k_fold_sample_indices</span><span class="p">(</span>
            <span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">nfolds</span><span class="p">,</span> <span class="n">random_folds</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">sklearn.model_selection._split</span> <span class="kn">import</span> <span class="n">KFold</span>
        <span class="n">sklearn_cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">nfolds</span><span class="p">)</span>
        <span class="c1"># indices = np.arange(train_samples.shape[1])</span>
        <span class="n">fold_sample_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">te</span> <span class="k">for</span> <span class="n">tr</span><span class="p">,</span> <span class="n">te</span> <span class="ow">in</span> <span class="n">sklearn_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train_vals</span><span class="p">,</span> <span class="n">train_vals</span><span class="p">)]</span>

    <span class="n">approx_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">residues_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cv_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">fold_sample_indices</span><span class="p">)):</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ntrain_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">K</span><span class="p">[</span><span class="n">fold_sample_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">train_samples_kk</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span>
        <span class="n">train_vals_kk</span> <span class="o">=</span> <span class="n">train_vals</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">test_samples_kk</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[:,</span> <span class="n">fold_sample_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span>
        <span class="n">test_vals_kk</span> <span class="o">=</span> <span class="n">train_vals</span><span class="p">[</span><span class="n">fold_sample_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span>
        <span class="n">approx_kk</span> <span class="o">=</span> <span class="n">approximate</span><span class="p">(</span>
            <span class="n">train_samples_kk</span><span class="p">,</span> <span class="n">train_vals_kk</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span><span class="o">.</span><span class="n">approx</span>
        <span class="n">residues</span> <span class="o">=</span> <span class="n">approx_kk</span><span class="p">(</span><span class="n">test_samples_kk</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_vals_kk</span>
        <span class="n">approx_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">approx_kk</span><span class="p">)</span>
        <span class="n">residues_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">residues</span><span class="p">)</span>
        <span class="n">cv_score</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residues</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cv_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cv_score</span><span class="o">/</span><span class="n">ntrain_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">approx_list</span><span class="p">,</span> <span class="n">residues_list</span><span class="p">,</span> <span class="n">cv_score</span>


<span class="k">def</span> <span class="nf">quadratic_oversampling_ratio</span><span class="p">(</span><span class="n">nindices</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nindices</span><span class="o">**</span><span class="mi">2</span>


<span class="k">def</span> <span class="nf">increment_samples_using_oversampling_ratio</span><span class="p">(</span>
        <span class="n">train_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">oversampling_ratio</span><span class="p">,</span> <span class="n">generate_samples</span><span class="p">):</span>
    <span class="n">ndesired_samples</span> <span class="o">=</span> <span class="n">oversampling_ratio</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">nnew_samples</span> <span class="o">=</span> <span class="n">ndesired_samples</span><span class="o">-</span><span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">new_train_samples</span> <span class="o">=</span> <span class="n">generate_samples</span><span class="p">(</span><span class="n">nnew_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_train_samples</span>


<span class="k">def</span> <span class="nf">increment_samples_using_condition_number</span><span class="p">(</span>
        <span class="n">train_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">pce</span><span class="p">,</span> <span class="n">generate_samples</span><span class="p">,</span> <span class="n">sample_growth_factor</span><span class="p">,</span>
        <span class="n">cond_tol</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">):</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">set_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">ndesired_samples</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">cond_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">ncurrent_samples</span> <span class="o">=</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">new_train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">ndesired_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">ndesired_samples</span><span class="o">*</span><span class="n">sample_growth_factor</span><span class="p">),</span> <span class="n">max_nsamples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ndesired_samples</span> <span class="o">&lt;</span> <span class="n">ncurrent_samples</span><span class="p">:</span>
            <span class="n">ndesired_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ncurrent_samples</span><span class="o">*</span><span class="n">sample_growth_factor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">ndesired_samples</span> <span class="o">&gt;</span> <span class="n">ncurrent_samples</span>
        <span class="c1"># generate a new increment of samples</span>
        <span class="n">nsample_incr</span> <span class="o">=</span> <span class="n">ndesired_samples</span><span class="o">-</span><span class="p">(</span>
            <span class="n">ncurrent_samples</span><span class="o">+</span><span class="n">new_train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># print(ncurrent_samples, nsample_incr, train_samples.shape,</span>
        <span class="c1">#       ndesired_samples, indices.shape)</span>
        <span class="n">samples_incr</span> <span class="o">=</span> <span class="n">generate_samples</span><span class="p">(</span><span class="n">nsample_incr</span><span class="p">)</span>
        <span class="c1"># add increment to total set of new samples</span>
        <span class="n">new_train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
            <span class="n">new_train_samples</span><span class="p">,</span> <span class="n">samples_incr</span><span class="p">))</span>
        <span class="c1"># compute basis matrix for sample increment</span>
        <span class="n">basis_matrix_incr</span> <span class="o">=</span> <span class="n">pce</span><span class="o">.</span><span class="n">basis_matrix</span><span class="p">(</span><span class="n">samples_incr</span><span class="p">)</span>
        <span class="c1"># compute condition number of entire sample set</span>
        <span class="n">basis_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">basis_matrix</span><span class="p">,</span> <span class="n">basis_matrix_incr</span><span class="p">))</span>
        <span class="n">cond_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">basis_matrix</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cond_num</span> <span class="o">&lt;=</span> <span class="n">cond_tol</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">ncurrent_samples</span> <span class="o">+</span> <span class="n">new_train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">max_nsamples</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">new_train_samples</span>


<span class="k">def</span> <span class="nf">adaptive_approximate_polynomial_chaos_increment_degree</span><span class="p">(</span>
        <span class="n">fun</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">max_degree</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cond_tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_growth_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">oversampling_ratio</span><span class="o">=</span><span class="n">quadratic_oversampling_ratio</span><span class="p">,</span>
        <span class="n">solver_type</span><span class="o">=</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">linear_solver_options</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
    <span class="n">pce</span> <span class="o">=</span> <span class="n">PolynomialChaosExpansion</span><span class="p">()</span>
    <span class="n">pce_opts</span> <span class="o">=</span> <span class="n">define_poly_options_from_variable_transformation</span><span class="p">(</span><span class="n">var_trans</span><span class="p">)</span>
    <span class="n">pce</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">pce_opts</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cond_tol</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">oversampling_ratio</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cond_tol or over_sampling_ratio must be None&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cond_tol</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">oversampling_ratio</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cond_tol or over_sampling_ratio must be None&quot;</span><span class="p">)</span>

    <span class="n">degree</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">generate_samples</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">generate_independent_random_samples</span><span class="p">,</span> <span class="n">pce</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">variable</span><span class="p">)</span>
    <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">degree</span> <span class="o">&gt;</span> <span class="n">max_degree</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_nsamples</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">compute_hyperbolic_indices</span><span class="p">(</span>
            <span class="n">pce</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">degree</span><span class="p">,</span> <span class="n">hcross_strength</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cond_tol</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_train_samples</span> <span class="o">=</span> <span class="n">increment_samples_using_condition_number</span><span class="p">(</span>
                <span class="n">train_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">pce</span><span class="p">,</span> <span class="n">generate_samples</span><span class="p">,</span>
                <span class="n">sample_growth_factor</span><span class="p">,</span> <span class="n">cond_tol</span><span class="p">,</span> <span class="n">max_nsamples</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_train_samples</span> <span class="o">=</span> <span class="n">increment_samples_using_oversampling_ratio</span><span class="p">(</span>
                <span class="n">train_samples</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">oversampling_ratio</span><span class="p">,</span> <span class="n">generate_samples</span><span class="p">)</span>
        <span class="n">new_train_values</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">new_train_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">train_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_values</span> <span class="o">=</span> <span class="n">new_train_values</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">train_values</span><span class="p">,</span> <span class="n">new_train_values</span><span class="p">))</span>
        <span class="n">train_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">new_train_samples</span><span class="p">))</span>
        <span class="c1"># Todo allow expanding basis as well</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">approximate_fixed_pce</span><span class="p">(</span>
            <span class="n">pce</span><span class="p">,</span> <span class="n">train_samples</span><span class="p">,</span> <span class="n">train_values</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span>
            <span class="n">solver_type</span><span class="p">,</span> <span class="n">linear_solver_options</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">approx</span><span class="p">)</span>
        <span class="c1"># TODO: if requested add exit condition that checks cross validation</span>
        <span class="c1"># error. For now if want to print cross validation error</span>
        <span class="c1"># implement that inside a callback</span>
        <span class="c1"># if nfolds &gt; 0:</span>
        <span class="c1">#     method_opts = {&quot;basis_type&quot;: &quot;fixed&quot;, &quot;verbose&quot;: verbose}</span>
        <span class="c1">#     method = approximate_polynomial_chaos()</span>
        <span class="c1">#     cv_score = cross_validate_approximation(</span>
        <span class="c1">#         train_samples, train_values, method_options, nfolds, method)</span>

        <span class="n">degree</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">ApproximateResult</span><span class="p">(</span>
        <span class="p">{</span><span class="s1">&#39;approx&#39;</span><span class="p">:</span> <span class="n">result</span><span class="o">.</span><span class="n">approx</span><span class="p">,</span> <span class="s1">&#39;train_samples&#39;</span><span class="p">:</span> <span class="n">train_samples</span><span class="p">,</span>
         <span class="s1">&#39;train_values&#39;</span><span class="p">:</span> <span class="n">train_values</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>