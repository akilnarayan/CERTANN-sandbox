
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_interface.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_interface.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_interface.py:


Model interfacing
-----------------
This tutorial demonstrats how to use model wrappers to time function calls and evaluate a function at multiple samples in parallel.

.. GENERATED FROM PYTHON SOURCE LINES 8-22

Timing function evaluations
^^^^^^^^^^^^^^^^^^^^^^^^^^^
It is often useful to be able to track the time needed to evaluate a function. We can track this using the :class:`pyapprox.interface.wrappers.TimerModel` and :class:`pyapprox.interface.wrappers.WorkTrackingModel` objects which are designed to work together. The former times each evaluation of a function that returns output of shape (nsamples,nqoi) and appends the time to the quantities of interest returned by the function, i.e returns a 2D np.ndarray with shape (nsamples,nqoi+1). The second extracts the time and removes it from the quantities of interest and returns output with the original shape  (nsamples,nqoi) of the user function.

Lets use the class with a function that takes a random amount of time. We will use the previous function but add a random pause between 0 and .1 seconds. Lets import some functions and define a multi-variate random variable

.. literalinclude:: ../../../examples/__util.py
  :language: python
  :start-at: def fun_pause_1
  :end-before: def fun_pause_2

.. Note for some reason text like this is needed after the literalinclude
.. Also note that path above is relative to source/auto_examples


.. GENERATED FROM PYTHON SOURCE LINES 22-44

.. code-block:: default


    import os
    import time
    import numpy as np
    from scipy import stats

    from pyapprox.variables import IndependentMarginalsVariable
    from pyapprox.interface.wrappers import (
        TimerModel, WorkTrackingModel, PoolModel, ModelEnsemble
    )

    univariate_variables = [stats.uniform(-2, 4), stats.uniform(-2, 4)]
    variable = IndependentMarginalsVariable(univariate_variables)

    from __util import pyapprox_fun_1, fun_pause_1
    timer_fun = TimerModel(pyapprox_fun_1)
    worktracking_fun = WorkTrackingModel(timer_fun)

    nsamples = 10
    samples = variable.rvs(nsamples)
    values = worktracking_fun(samples)








.. GENERATED FROM PYTHON SOURCE LINES 45-46

The :class:`pyapprox.interface.wrappers.WorkTrackingModel` has an attribute :class:`pyapprox.interface.wrappers.WorkTracker` which stores the execution time of each function evaluation as a dictionary. The key corresponds is the model id. For this example the id will always be the same, but the id can vary and this is useful when evaluating mutiple models, e.g. when using multi-fidelity methods. To print the dictionary use

.. GENERATED FROM PYTHON SOURCE LINES 46-49

.. code-block:: default

    costs = worktracking_fun.work_tracker.costs
    print(costs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {(0.0,): [0.021309852600097656, 0.022834300994873047, 0.01922321319580078, 0.03530120849609375, 0.014723777770996094, 0.018468141555786133, 0.017929792404174805, 0.0005068778991699219, 0.023463010787963867, 0.0032320022583007812]}




.. GENERATED FROM PYTHON SOURCE LINES 50-51

We can also call the work tracker to query the median cost for a model with a given id. The default id is 0.

.. GENERATED FROM PYTHON SOURCE LINES 51-55

.. code-block:: default

    fun_id = np.atleast_2d([0])
    print(worktracking_fun.work_tracker(fun_id))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [0.01884568]




.. GENERATED FROM PYTHON SOURCE LINES 56-67

Evaluating multiple models
^^^^^^^^^^^^^^^^^^^^^^^^^^
Now let apply this two an ensemble of models to explore the use of model ids. First create a second function which we import.

.. literalinclude:: ../../../examples/__util.py
  :language: python
  :start-at: def fun_pause_2

.. Note for some reason text like this is needed after the literalinclude
.. Also note that path above is relative to source/auto_examples


.. GENERATED FROM PYTHON SOURCE LINES 67-69

.. code-block:: default

    from __util import pyapprox_fun_2








.. GENERATED FROM PYTHON SOURCE LINES 70-71

Now using :class:`pyapprox.interface.ModelEnsemble` we can create a function which takes the random samples plus an additional configure variable which defines which model to evaluate. Lets use half the samples to evaluate the first model and evaluate the second model at the remaining samples

.. GENERATED FROM PYTHON SOURCE LINES 71-81

.. code-block:: default

    model_ensemble = ModelEnsemble([pyapprox_fun_1, pyapprox_fun_2])
    timer_fun_ensemble = TimerModel(model_ensemble)
    worktracking_fun_ensemble = WorkTrackingModel(
        timer_fun_ensemble, num_config_vars=1)

    fun_ids = np.ones(nsamples)
    fun_ids[:nsamples//2] = 0
    ensemble_samples = np.vstack([samples, fun_ids])
    values = worktracking_fun_ensemble(ensemble_samples)








.. GENERATED FROM PYTHON SOURCE LINES 82-86

Here we had to pass the number (1) of configure variables to the
WorkTrackingModel. PyApprox assumes that the configure variables are the last rows of the samples 2D array

Now check that the new values are the same as when using the individual functions directly

.. GENERATED FROM PYTHON SOURCE LINES 86-91

.. code-block:: default

    assert np.allclose(values[:nsamples//2],
                       pyapprox_fun_1(samples[:, :nsamples//2]))
    assert np.allclose(values[nsamples//2:],
                       pyapprox_fun_2(samples[:, nsamples//2:]))








.. GENERATED FROM PYTHON SOURCE LINES 92-93

Again we can query the execution times of each model

.. GENERATED FROM PYTHON SOURCE LINES 93-99

.. code-block:: default

    costs = worktracking_fun_ensemble.work_tracker.costs
    print(costs)

    query_fun_ids = np.atleast_2d([0, 1])
    print(worktracking_fun_ensemble.work_tracker(query_fun_ids))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {(0.0,): [0.04897189140319824, 0.04144620895385742, 0.035201072692871094, 0.0427098274230957, 0.04759788513183594], (1.0,): [0.08864402770996094, 0.08164477348327637, 0.061695098876953125, 0.07576799392700195, 0.08119797706604004]}
    [0.04270983 0.08119798]




.. GENERATED FROM PYTHON SOURCE LINES 100-101

As expected there are 5 samples tracked for each model and the median evaluation time of the second function is about twice as large as for the first function.

.. GENERATED FROM PYTHON SOURCE LINES 103-109

Evaluating functions at multiple samples in parallel
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For expensive models it is often useful to be able to evaluate each model concurrently. This can be achieved using :class:`pyapprox.interface.wrappers.PoolModel`. Note this function is not intended for use with distributed memory systems, but rather is intended to use all the threads of a personal computer or compute node. See :class:`pyapprox.interface.async_model.AynchModel` if you are interested in running multiple simulations in parallel on a distributed memory system.

PoolModel cannot be used to wrap WorkTrackingModel. However it can still
be used with WorkTrackingModel using the sequence of wrappers below.

.. GENERATED FROM PYTHON SOURCE LINES 109-141

.. code-block:: default


    max_eval_concurrency = 1  # set higher
    # clear WorkTracker counters
    pool_model = PoolModel(
        timer_fun_ensemble, max_eval_concurrency, assert_omp=False)
    worktracking_fun_ensemble.work_tracker.costs = dict()
    worktracking_fun_ensemble = WorkTrackingModel(
        pool_model, num_config_vars=1)

    # create more samples to notice improvement in wall time
    nsamples = 10
    samples = variable.rvs(nsamples)
    fun_ids = np.ones(nsamples)
    fun_ids[:nsamples//2] = 0
    ensemble_samples = np.vstack([samples, fun_ids])

    t0 = time.time()
    values = worktracking_fun_ensemble(ensemble_samples)
    t1 = time.time()
    print(f'With {max_eval_concurrency} threads that took {t1-t0} seconds')

    if ('OMP_NUM_THREADS' not in os.environ or
        int(os.environ['OMP_NUM_THREADS']) != 1):
        # make sure to set OMP_NUM_THREADS=1 to maximize benefit of pool model
        print('Warning set OMP_NUM_THREADS=1 for best performance')
    max_eval_concurrency = 4
    pool_model.set_max_eval_concurrency(max_eval_concurrency)
    t0 = time.time()
    values = worktracking_fun_ensemble(ensemble_samples)
    t1 = time.time()
    print(f'With {max_eval_concurrency} threads that took {t1-t0} seconds')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    With 1 threads that took 0.4975900650024414 seconds
    Warning set OMP_NUM_THREADS=1 for best performance
    With 4 threads that took 1.147495985031128 seconds




.. GENERATED FROM PYTHON SOURCE LINES 142-144

Lets print a summary of the costs to make sure individual function evaluation
costs are still being recorded correctly

.. GENERATED FROM PYTHON SOURCE LINES 144-147

.. code-block:: default


    print(worktracking_fun_ensemble.work_tracker)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    WorkTracker Cost Summary
    Funtion ID Median Cost
    (0.0,)     0.022763609886169434
    (1.0,)     0.07447099685668945





.. GENERATED FROM PYTHON SOURCE LINES 148-151

Note
^^^^
PoolModel cannot be used with lambda functions. You will get error similar to pickle.PicklingError: Can't pickle <function <lambda> at 0x12b4e6440>: attribute lookup <lambda> on __main__ failed

.. GENERATED FROM PYTHON SOURCE LINES 151-154

.. code-block:: default


    # sphinx_gallery_thumbnail_path = './figures/cantilever-beam.png'








.. GENERATED FROM PYTHON SOURCE LINES 155-157

.. gallery thumbnail will say broken if no plots are made in this file so
.. specify a default file as above. Must start with a #


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  2.997 seconds)


.. _sphx_glr_download_auto_examples_plot_interface.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_interface.py <plot_interface.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_interface.ipynb <plot_interface.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
